{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Mask-R-CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "16I9upKzPxOlbkIpuCUXXG-dlKrqaXpo0",
      "authorship_tag": "ABX9TyPPIOFNLQbJqqdybAi/7UPp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juliuserbach/Semantic-Features/blob/master/Mask_R_CNN_Inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqs13ramKg_K",
        "colab_type": "code",
        "outputId": "de6d305e-92d0-49d0-c2f7-50ee1a0a15de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "!git clone https://github.com/ftaubner/semantic_features_detection.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'semantic_features_detection'...\n",
            "remote: Enumerating objects: 111, done.\u001b[K\n",
            "remote: Counting objects: 100% (111/111), done.\u001b[K\n",
            "remote: Compressing objects: 100% (85/85), done.\u001b[K\n",
            "remote: Total 1503 (delta 77), reused 44 (delta 26), pack-reused 1392\u001b[K\n",
            "Receiving objects: 100% (1503/1503), 114.24 MiB | 30.41 MiB/s, done.\n",
            "Resolving deltas: 100% (929/929), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMkSQoH1ZGYA",
        "colab_type": "code",
        "outputId": "57792758-09cb-435d-cb7f-2eaa04de4c61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "!wget --no-check-certificate \"https://onedrive.live.com/download?cid=EA356294C6263A37&resid=EA356294C6263A37%21100433&authkey=APrMUGQyaB4np4Q\" -O kitti.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-28 11:22:44--  https://onedrive.live.com/download?cid=EA356294C6263A37&resid=EA356294C6263A37%21100433&authkey=APrMUGQyaB4np4Q\n",
            "Resolving onedrive.live.com (onedrive.live.com)... 13.107.43.13\n",
            "Connecting to onedrive.live.com (onedrive.live.com)|13.107.43.13|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://xwp44a.am.files.1drv.com/y4myTRfFPSSVMd51Mg3reoLK2qEoIv8k3I2b5bzHKoe-ZRUe_hW_ErGMr9_lvACKqkaD33ZnF884_eDjXIKDdl4CexmHNAAScQq5BjQq-uMxqY3L0bDyhnlLt8ua8yr5JwxfdJSuaaH_6BcEVp2-JKkDVQwlhMqTbeqMBztUrxMXofst1MiAh4SeAWlwZPTwxadBZRYfREgexbZ3FVCTaWCHg/kitti_dataset.zip?download&psid=1 [following]\n",
            "--2020-04-28 11:22:45--  https://xwp44a.am.files.1drv.com/y4myTRfFPSSVMd51Mg3reoLK2qEoIv8k3I2b5bzHKoe-ZRUe_hW_ErGMr9_lvACKqkaD33ZnF884_eDjXIKDdl4CexmHNAAScQq5BjQq-uMxqY3L0bDyhnlLt8ua8yr5JwxfdJSuaaH_6BcEVp2-JKkDVQwlhMqTbeqMBztUrxMXofst1MiAh4SeAWlwZPTwxadBZRYfREgexbZ3FVCTaWCHg/kitti_dataset.zip?download&psid=1\n",
            "Resolving xwp44a.am.files.1drv.com (xwp44a.am.files.1drv.com)... 13.107.43.12\n",
            "Connecting to xwp44a.am.files.1drv.com (xwp44a.am.files.1drv.com)|13.107.43.12|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1099720129 (1.0G) [application/zip]\n",
            "Saving to: ‘kitti.zip’\n",
            "\n",
            "kitti.zip           100%[===================>]   1.02G  18.8MB/s    in 50s     \n",
            "\n",
            "2020-04-28 11:23:35 (20.9 MB/s) - ‘kitti.zip’ saved [1099720129/1099720129]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrMxy5HqSm-f",
        "colab_type": "code",
        "outputId": "dd2f84bc-ed76-446e-8459-016f7f0c519a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "!wget --no-check-certificate \"https://onedrive.live.com/download?cid=EA356294C6263A37&resid=EA356294C6263A37%21101634&authkey=ABTiTiHVXMI06vU\"  -O mapillary_prelim.h5"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-28 11:23:37--  https://onedrive.live.com/download?cid=EA356294C6263A37&resid=EA356294C6263A37%21101367&authkey=APvrKcWlPo0_7ck\n",
            "Resolving onedrive.live.com (onedrive.live.com)... 13.107.43.13\n",
            "Connecting to onedrive.live.com (onedrive.live.com)|13.107.43.13|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ydwucw.am.files.1drv.com/y4mj-9vKQm_ZhieP0N5Hq4x4K_Scpe836lZ8_7UAutfgsdD2zN7J0mYxBOEbtbkxa7J6h68Zg9eQhqrZX-XySHUYKePjDp_nCsud42U1IibTH24LgxhTAgglNg7fzdqeF0BJb4-qIO_oQCS9DHXZ6XikMBRUEDhga66GvGBSJ4URtWwRAH1-QwYqDzuScYSXnjD-b-GKkFPEaiR0IXFQggECA/mask_rcnn_mapvistas_0061.h5?download&psid=1 [following]\n",
            "--2020-04-28 11:23:38--  https://ydwucw.am.files.1drv.com/y4mj-9vKQm_ZhieP0N5Hq4x4K_Scpe836lZ8_7UAutfgsdD2zN7J0mYxBOEbtbkxa7J6h68Zg9eQhqrZX-XySHUYKePjDp_nCsud42U1IibTH24LgxhTAgglNg7fzdqeF0BJb4-qIO_oQCS9DHXZ6XikMBRUEDhga66GvGBSJ4URtWwRAH1-QwYqDzuScYSXnjD-b-GKkFPEaiR0IXFQggECA/mask_rcnn_mapvistas_0061.h5?download&psid=1\n",
            "Resolving ydwucw.am.files.1drv.com (ydwucw.am.files.1drv.com)... 13.107.43.12\n",
            "Connecting to ydwucw.am.files.1drv.com (ydwucw.am.files.1drv.com)|13.107.43.12|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 256204312 (244M) [application/octet-stream]\n",
            "Saving to: ‘mapillary_prelim.h5’\n",
            "\n",
            "mapillary_prelim.h5 100%[===================>] 244.33M  32.8MB/s    in 7.6s    \n",
            "\n",
            "2020-04-28 11:23:46 (32.3 MB/s) - ‘mapillary_prelim.h5’ saved [256204312/256204312]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nhJZTIzZpRW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -qq /content/kitti.zip -d /content"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdvT1vzBK6hV",
        "colab_type": "code",
        "outputId": "bb0b19b5-08c3-4108-c1ba-1260029778ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "!pip install imgaug\n",
        "!pip install Cython\n",
        "!pip install pycocotools\n",
        "!pip install wget"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: imgaug in /usr/local/lib/python3.6/dist-packages (0.2.9)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from imgaug) (1.18.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from imgaug) (1.4.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from imgaug) (7.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from imgaug) (1.12.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from imgaug) (3.2.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from imgaug) (4.1.2.30)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.6/dist-packages (from imgaug) (1.7.0)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.6/dist-packages (from imgaug) (2.4.1)\n",
            "Requirement already satisfied: scikit-image>=0.11.0 in /usr/local/lib/python3.6/dist-packages (from imgaug) (0.16.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug) (1.2.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug) (2.4)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug) (1.1.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.11.0->imgaug) (4.4.2)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (0.29.16)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9682 sha256=ce8b1f2dcb620f6b2651019268655b3f145af5e0826cf1fdb876a83533fcc6a4\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOH72UGWVX4r",
        "colab_type": "code",
        "outputId": "96ab8efd-4c4f-4612-8709-9a8b355e0ed8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "%matplotlib inline\n",
        "import os\n",
        "import sys\n",
        "os.chdir('/content/semantic_features_detection/Notebook')\n",
        "ROOT_DIR = os.path.abspath('../')\n",
        "sys.path.append(os.path.join(ROOT_DIR, 'samples'))\n",
        "import inference"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading pretrained model to /content/mask_rcnn_coco.h5 ...\n",
            "... done downloading pretrained model!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZVRk8iZWn7h",
        "colab_type": "code",
        "outputId": "dfdfbc10-22c5-4af5-f7af-856e3d45ea79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        }
      },
      "source": [
        "inf_model = inference.Inference(os.path.join(ROOT_DIR, 'mapillary_prelim.h5'))\n",
        "# features, masks = inf_model.predict('/content/dataset/sequences/04/image_2/000001.png')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/semantic_features_detection/mrcnn/model.py:341: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/semantic_features_detection/mrcnn/model.py:399: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/semantic_features_detection/mrcnn/model.py:423: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "WARNING:tensorflow:From /content/semantic_features_detection/mrcnn/model.py:758: The name tf.sets.set_intersection is deprecated. Please use tf.sets.intersection instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/semantic_features_detection/mrcnn/model.py:760: The name tf.sparse_tensor_to_dense is deprecated. Please use tf.sparse.to_dense instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/semantic_features_detection/mrcnn/model.py:772: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "/content/dataset/sequences/04/image_2/000001.png\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-0ef63c56e8fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minf_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mROOT_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mapillary_prelim.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minf_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/dataset/sequences/04/image_2/000001.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/semantic_features_detection/samples/inference.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, image_path, save_vis, save_dir)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mimage_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/semantic_features_detection/mrcnn/model.py\u001b[0m in \u001b[0;36mdetect\u001b[0;34m(self, images, verbose)\u001b[0m\n\u001b[1;32m   2503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2504\u001b[0m         \u001b[0;31m# Mold inputs to format expected by the neural network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2505\u001b[0;31m         \u001b[0mmolded_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_metas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmold_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2507\u001b[0m         \u001b[0;31m# Validate image sizes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/semantic_features_detection/mrcnn/model.py\u001b[0m in \u001b[0;36mmold_inputs\u001b[0;34m(self, images)\u001b[0m\n\u001b[1;32m   2401\u001b[0m                 \u001b[0mmin_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMAGE_MIN_SCALE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2402\u001b[0m                 \u001b[0mmax_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMAGE_MAX_DIM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2403\u001b[0;31m                 mode=self.config.IMAGE_RESIZE_MODE)\n\u001b[0m\u001b[1;32m   2404\u001b[0m             \u001b[0mmolded_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmold_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmolded_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2405\u001b[0m             \u001b[0;31m# Build image_meta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/semantic_features_detection/mrcnn/utils.py\u001b[0m in \u001b[0;36mresize_image\u001b[0;34m(image, min_dim, max_dim, min_scale, mode)\u001b[0m\n\u001b[1;32m    419\u001b[0m     \"\"\"\n\u001b[1;32m    420\u001b[0m     \u001b[0;31m# Keep track of image dtype and return results in the same dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m     \u001b[0mimage_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m     \u001b[0;31m# Default window (y1, x1, y2, x2) and default scale == 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'dtype'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Scu35PA6PzYg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "def masks2instance_im(masks):\n",
        "    instance_im = np.zeros(shape=[masks.shape[0], masks.shape[1]])\n",
        "    for i in range(masks.shape[-1]):\n",
        "        instance_im[masks[...,i]] = (i + 1)\n",
        "    return instance_im"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0RMH64mbLQr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "import cv2\n",
        "IMAGE_DIR_LEFT = '/content/kitti_dataset/dataset/sequences/04/image_2'\n",
        "IMAGE_DIR_RIGHT = '/content/kitti_dataset/dataset/sequences/04/image_3'\n",
        "SAVE_DIR = '/content/Results/Instances'\n",
        "!mkdir /content/Results/Instances\n",
        "!mkdir /content/Results/Visualization\n",
        "\n",
        "features = {}\n",
        "features['results'] = []\n",
        "image_paths = glob.iglob(os.path.join(IMAGE_DIR_LEFT, '*.*'))\n",
        "for image_path in image_paths:\n",
        "    feature, masks = inf_model.predict(image_path,save_vis=True, save_dir='/content/Results/Visualization')\n",
        "    features['results'].append(feature)\n",
        "    # save instance images\n",
        "    instance_im =  masks2instance_im(masks)\n",
        "    image_id=os.path.split(image_path)[1][0:-4]\n",
        "    cv2.imwrite(os.path.join(SAVE_DIR, 'L' + image_id + '.png'), instance_im)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ur6nR6f4RwKQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "FEATURE_FILE = '/content/results.json'\n",
        "with open(FEATURE_FILE, 'w') as outfile:\n",
        "    json.dump(features, outfile)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}