{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mask-R-CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "https://github.com/juliuserbach/Semantic-Features/blob/master/Mask_R_CNN_testing.ipynb",
      "authorship_tag": "ABX9TyPJT0gXzkJQe32CxZKYBBIF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juliuserbach/Semantic-Features/blob/master/Mask_R_CNN_testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqs13ramKg_K",
        "colab_type": "code",
        "outputId": "9e54504c-88ce-40c1-bc09-42141ac3d09c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!git clone https://github.com/ftaubner/semantic_features_detection.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'semantic_features_detection' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMkSQoH1ZGYA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!wget --no-check-certificate \"https://onedrive.live.com/download?cid=EA356294C6263A37&resid=EA356294C6263A37%21100024&authkey=ADLJzehr2ENRggw\" -O mapillary_vistas.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrMxy5HqSm-f",
        "colab_type": "code",
        "outputId": "5723c880-e3b5-4a18-fa3e-29026570501c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "!wget --no-check-certificate \"https://onedrive.live.com/download?cid=EA356294C6263A37&resid=EA356294C6263A37%21101634&authkey=ABTiTiHVXMI06vU\"  -O mapillary_prelim.h5"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-24 12:56:23--  https://onedrive.live.com/download?cid=EA356294C6263A37&resid=EA356294C6263A37%21101634&authkey=ABTiTiHVXMI06vU\n",
            "Resolving onedrive.live.com (onedrive.live.com)... 13.107.42.13\n",
            "Connecting to onedrive.live.com (onedrive.live.com)|13.107.42.13|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://mmhp0a.am.files.1drv.com/y4m2Y0MS0VbG4QBeaf_vSDk6P-Nu-wBOwtrdEtkLtd7NP7G_2INQ28DZ_lNX4ewOmpoqvpagLc8b69pbQPrUyYihlKvTi6SJx9Vb5rnFfb4Crx9oUdifJIaXsSLgJhx4ehT4nOq9TrJ36skVLIgcoGERlZO1QDoyTBunhexJocGH9F0z_3wdHY9OzmAWamWa1DAm-jHHNVh7My87qKmkUgi1A/mask_rcnn_mapvistas_0083.h5?download&psid=1 [following]\n",
            "--2020-05-24 12:56:24--  https://mmhp0a.am.files.1drv.com/y4m2Y0MS0VbG4QBeaf_vSDk6P-Nu-wBOwtrdEtkLtd7NP7G_2INQ28DZ_lNX4ewOmpoqvpagLc8b69pbQPrUyYihlKvTi6SJx9Vb5rnFfb4Crx9oUdifJIaXsSLgJhx4ehT4nOq9TrJ36skVLIgcoGERlZO1QDoyTBunhexJocGH9F0z_3wdHY9OzmAWamWa1DAm-jHHNVh7My87qKmkUgi1A/mask_rcnn_mapvistas_0083.h5?download&psid=1\n",
            "Resolving mmhp0a.am.files.1drv.com (mmhp0a.am.files.1drv.com)... 13.107.42.12\n",
            "Connecting to mmhp0a.am.files.1drv.com (mmhp0a.am.files.1drv.com)|13.107.42.12|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 256204312 (244M) [application/octet-stream]\n",
            "Saving to: ‘mapillary_prelim.h5’\n",
            "\n",
            "mapillary_prelim.h5 100%[===================>] 244.33M  23.0MB/s    in 12s     \n",
            "\n",
            "2020-05-24 12:56:36 (20.9 MB/s) - ‘mapillary_prelim.h5’ saved [256204312/256204312]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nhJZTIzZpRW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!unzip -qq /content/mapillary_vistas.zip 'mapillary_vistas/validation/*' -d /content"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoNjvU1NcD-J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!unzip -qq /content/mapillary_vistas.zip 'mapillary_vistas/config.json' -d /content"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdvT1vzBK6hV",
        "colab_type": "code",
        "outputId": "e4d26d2d-768d-48f5-cb12-406351567e80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "!pip install imgaug\n",
        "!pip install Cython\n",
        "!pip install pycocotools"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: imgaug in /usr/local/lib/python3.6/dist-packages (0.2.9)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.6/dist-packages (from imgaug) (1.7.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from imgaug) (1.12.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from imgaug) (4.1.2.30)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from imgaug) (1.4.1)\n",
            "Requirement already satisfied: scikit-image>=0.11.0 in /usr/local/lib/python3.6/dist-packages (from imgaug) (0.16.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from imgaug) (7.0.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from imgaug) (1.18.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from imgaug) (3.2.1)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.6/dist-packages (from imgaug) (2.4.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug) (1.1.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug) (2.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug) (2.4.7)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.11.0->imgaug) (4.4.2)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (0.29.18)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.6/dist-packages (2.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meGMIONOKySt",
        "colab_type": "code",
        "outputId": "2034e8e7-5c87-4482-d3a8-bccb6a9f9c01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import os\n",
        "os.chdir('/content/semantic_features_detection/samples/mapillary/cytools')\n",
        "!python setup.py build_ext --inplace\n",
        "os.chdir('/content/semantic_features_detection/Notebook')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "running build_ext\n",
            "copying build/lib.linux-x86_64-3.6/mask_tools.cpython-36m-x86_64-linux-gnu.so -> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viP6_e5JPNXO",
        "colab_type": "code",
        "outputId": "6ee4bc25-4b30-4c7a-a936-ed4e799bdacb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "import skimage.io\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import imageio\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "# Root directory of the project\n",
        "ROOT_DIR = os.path.abspath(\"../\")\n",
        "# Ignore Warnings\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
        "\n",
        "# Import Mask RCNN\n",
        "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
        "print(ROOT_DIR)\n",
        "from mrcnn import utils\n",
        "import mrcnn.model_felix as modellib\n",
        "from mrcnn import visualize\n",
        "# Import COCO config\n",
        "sys.path.append(os.path.join(ROOT_DIR, \"samples/mapillary/\"))  # To find local version\n",
        "import mapillary_felix\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "# Directory to save logs and trained model\n",
        "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
        "print(MODEL_DIR)\n",
        "\n",
        "# Local path to trained weights file\n",
        "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
        "# Download COCO trained weights from Releases if needed\n",
        "if not os.path.exists(COCO_MODEL_PATH):\n",
        "    utils.download_trained_weights(COCO_MODEL_PATH)\n",
        "\n",
        "# Directory of images to run detection on\n",
        "IMAGE_DIR = os.path.join(ROOT_DIR, \"images\")\n",
        "print('finished')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "/content/semantic_features_detection\n",
            "/content/semantic_features_detection/logs\n",
            "finished\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXAqClvqXsLK",
        "colab_type": "code",
        "outputId": "555d745b-ddd2-4673-e39c-43cf6ce871b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "class_names= ['Unlabeled', 'Bird', 'Ground Animal', 'Curb', 'Fence', 'Guard Rail', \n",
        "              'Barrier', 'Wall', 'Bike Lane', 'Crosswalk - Plain', 'Curb Cut', 'Parking', \n",
        "              'Pedestrian Area', 'Rail Track', 'Road', 'Service Lane', 'Sidewalk', 'Bridge', \n",
        "              'Building', 'Tunnel', 'Person', 'Bicyclist', 'Motorcyclist', 'Other Rider', \n",
        "              'Lane Marking - Crosswalk', 'Lane Marking - General', 'Mountain', 'Sand', \n",
        "              'Sky', 'Snow', 'Terrain', 'Vegetation', 'Water', 'Banner', 'Bench', 'Bike Rack',\n",
        "              'Billboard', 'Catch Basin', 'CCTV Camera', 'Fire Hydrant', 'Junction Box', 'Mailbox',\n",
        "              'Manhole', 'Phone Booth', 'Pothole', 'Street Light', 'Pole', 'Traffic Sign Frame', \n",
        "              'Utility Pole', 'Traffic Light', 'Traffic Sign (Back)', 'Traffic Sign (Front)',\n",
        "              'Trash Can', 'Bicycle', 'Boat', 'Bus', 'Car', 'Caravan', 'Motorcycle', 'On Rails',\n",
        "              'Other Vehicle', 'Trailer', 'Truck', 'Wheeled Slow', 'Car Mount', 'Ego Vehicle']\n",
        "selected_classes = [34, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52]\n",
        "print(len(selected_classes))\n",
        "for class_num in selected_classes:\n",
        "    print(class_names[class_num])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "17\n",
            "Bench\n",
            "Billboard\n",
            "Catch Basin\n",
            "CCTV Camera\n",
            "Fire Hydrant\n",
            "Junction Box\n",
            "Mailbox\n",
            "Manhole\n",
            "Phone Booth\n",
            "Street Light\n",
            "Pole\n",
            "Traffic Sign Frame\n",
            "Utility Pole\n",
            "Traffic Light\n",
            "Traffic Sign (Back)\n",
            "Traffic Sign (Front)\n",
            "Trash Can\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVW7e7R1UWAZ",
        "colab_type": "code",
        "outputId": "88134f4c-b060-4305-aef9-6804cd5220a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        }
      },
      "source": [
        "class InferenceConfig(mapillary_felix.mapvistas):\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "    DETECTION_MIN_CONFIDENCE = 0\n",
        "    NUM_CLASSES = len(selected_classes) + 1\n",
        "config = InferenceConfig()\n",
        "config.display()\n",
        "batch_size = config.BATCH_SIZE"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Configurations:\n",
            "BACKBONE                       resnet101\n",
            "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
            "BATCH_SIZE                     1\n",
            "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
            "COMPUTE_BACKBONE_SHAPE         None\n",
            "DETECTION_MAX_INSTANCES        100\n",
            "DETECTION_MIN_CONFIDENCE       0\n",
            "DETECTION_NMS_THRESHOLD        0.3\n",
            "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
            "GPU_COUNT                      1\n",
            "GRADIENT_CLIP_NORM             5.0\n",
            "IMAGES_PER_GPU                 1\n",
            "IMAGE_CHANNEL_COUNT            3\n",
            "IMAGE_MAX_DIM                  640\n",
            "IMAGE_META_SIZE                30\n",
            "IMAGE_MIN_DIM                  640\n",
            "IMAGE_MIN_SCALE                0\n",
            "IMAGE_RESIZE_MODE              square\n",
            "IMAGE_SHAPE                    [640 640   3]\n",
            "LEARNING_MOMENTUM              0.9\n",
            "LEARNING_RATE                  0.001\n",
            "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
            "MASK_POOL_SIZE                 14\n",
            "MASK_SHAPE                     [28, 28]\n",
            "MAX_GT_INSTANCES               100\n",
            "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
            "MINI_MASK_SHAPE                (56, 56)\n",
            "NAME                           mapvistas\n",
            "NUM_CLASSES                    18\n",
            "POOL_SIZE                      7\n",
            "POST_NMS_ROIS_INFERENCE        1000\n",
            "POST_NMS_ROIS_TRAINING         2000\n",
            "PRE_NMS_LIMIT                  6000\n",
            "ROI_POSITIVE_RATIO             0.33\n",
            "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
            "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
            "RPN_ANCHOR_STRIDE              1\n",
            "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
            "RPN_NMS_THRESHOLD              0.7\n",
            "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
            "STEPS_PER_EPOCH                1000\n",
            "TOP_DOWN_PYRAMID_SIZE          256\n",
            "TRAIN_BN                       False\n",
            "TRAIN_ROIS_PER_IMAGE           200\n",
            "USE_MINI_MASK                  True\n",
            "USE_RPN_ROIS                   True\n",
            "VALIDATION_STEPS               50\n",
            "WEIGHT_DECAY                   0.0001\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHcm09WTUa4a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "f9fa0d26-1fb3-4012-b180-9e87570addc3"
      },
      "source": [
        "# TRAIN_DIR = '/content/mapillary_vistas'\n",
        "# # Training dataset\n",
        "# dataset_train = mapillary.MapillaryDataset()\n",
        "# dataset_train.load_vistas(dataset_dir=TRAIN_DIR, subset='training', class_ids=selected_classes)\n",
        "# dataset_train.prepare()\n",
        "\n",
        "# Validation dataset\n",
        "VAL_DIR = '/content/drive/My Drive/mapillary_vistas/mapillary_vistas'\n",
        "\n",
        "dataset_val = mapillary_felix.MapillaryDataset()\n",
        "dataset_val.load_vistas(dataset_dir=VAL_DIR, subset='validation', config=config, class_ids=selected_classes)\n",
        "dataset_val.prepare()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "class_id, class_name: 1, Bench\n",
            "class_id, class_name: 2, Billboard\n",
            "class_id, class_name: 3, Catch Basin\n",
            "class_id, class_name: 4, CCTV Camera\n",
            "class_id, class_name: 5, Fire Hydrant\n",
            "class_id, class_name: 6, Junction Box\n",
            "class_id, class_name: 7, Mailbox\n",
            "class_id, class_name: 8, Manhole\n",
            "class_id, class_name: 9, Phone Booth\n",
            "class_id, class_name: 10, Street Light\n",
            "class_id, class_name: 11, Pole\n",
            "class_id, class_name: 12, Traffic Sign Frame\n",
            "class_id, class_name: 13, Utility Pole\n",
            "class_id, class_name: 14, Traffic Light\n",
            "class_id, class_name: 15, Traffic Sign (Back)\n",
            "class_id, class_name: 16, Traffic Sign (Front)\n",
            "class_id, class_name: 17, Trash Can\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JErJmgXPns8L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cde51967-0028-44c8-96f7-5514a829e1d2"
      },
      "source": [
        "print(len(dataset_val.class_names))\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P81V1BRHUYu1",
        "colab_type": "code",
        "outputId": "8e116517-c4af-4aae-814c-fdf79ca7300c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "# Create model in training mode\n",
        "model = modellib.MaskRCNN(mode=\"inference\", config=config,\n",
        "                          model_dir=MODEL_DIR)\n",
        "model_path = '/content/mapillary_prelim.h5'\n",
        "model.load_weights(model_path, by_name=True)\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/semantic_features_detection/mrcnn/model_felix.py:341: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/semantic_features_detection/mrcnn/model_felix.py:399: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/semantic_features_detection/mrcnn/model_felix.py:423: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "WARNING:tensorflow:From /content/semantic_features_detection/mrcnn/model_felix.py:758: The name tf.sets.set_intersection is deprecated. Please use tf.sets.intersection instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/semantic_features_detection/mrcnn/model_felix.py:760: The name tf.sparse_tensor_to_dense is deprecated. Please use tf.sparse.to_dense instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/semantic_features_detection/mrcnn/model_felix.py:772: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtMGD9UDXzIS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_overlaps_masks(masks1, masks2):\n",
        "    \"\"\"Computes IoU overlaps between two sets of masks.\n",
        "    masks1, masks2: [Height, Width, instances]\n",
        "    \"\"\"\n",
        "    \n",
        "    # If either set of masks is empty return empty result\n",
        "    if masks1.shape[-1] == 0 or masks2.shape[-1] == 0:\n",
        "        return np.zeros((masks1.shape[-1], masks2.shape[-1]))\n",
        "    # flatten masks and compute their areas\n",
        "    masks1 = np.reshape(masks1 > .5, (-1, masks1.shape[-1])).astype(np.float32)\n",
        "    masks2 = np.reshape(masks2 > .5, (-1, masks2.shape[-1])).astype(np.float32)\n",
        "    area1 = np.sum(masks1, axis=0)\n",
        "    area2 = np.sum(masks2, axis=0)\n",
        "\n",
        "    # intersections and union\n",
        "    intersections = np.dot(masks1.T, masks2)\n",
        "    union = area1[:, None] + area2[None, :] - intersections\n",
        "    overlaps = intersections / union\n",
        "\n",
        "    return overlaps\n",
        "\n",
        "def trim_zeros(x):\n",
        "    \"\"\"It's common to have tensors larger than the available data and\n",
        "    pad with zeros. This function removes rows that are all zeros.\n",
        "\n",
        "    x: [rows, columns].\n",
        "    \"\"\"\n",
        "    assert len(x.shape) == 2\n",
        "    return x[~np.all(x == 0, axis=1)]\n",
        "\n",
        "\n",
        "def compute_matches(gt_boxes, gt_class_ids, gt_masks,\n",
        "                    pred_boxes, pred_class_ids, pred_scores, pred_masks,\n",
        "                    iou_threshold=0.5, score_threshold=0.0):\n",
        "    \"\"\"Finds matches between prediction and ground truth instances.\n",
        "\n",
        "    Returns:\n",
        "        gt_match: 1-D array. For each GT box it has the index of the matched\n",
        "                  predicted box.\n",
        "        pred_match: 1-D array. For each predicted box, it has the index of\n",
        "                    the matched ground truth box.\n",
        "        overlaps: [pred_boxes, gt_boxes] IoU overlaps.\n",
        "    \"\"\"\n",
        "    # Trim zero padding\n",
        "    # TODO: cleaner to do zero unpadding upstream\n",
        "    gt_boxes = trim_zeros(gt_boxes)\n",
        "    gt_masks = gt_masks[..., :gt_boxes.shape[0]]\n",
        "    pred_boxes = trim_zeros(pred_boxes)\n",
        "    pred_scores = pred_scores[:pred_boxes.shape[0]]\n",
        "    # Sort predictions by score from high to low\n",
        "    indices = np.argsort(pred_scores)[::-1]\n",
        "    pred_boxes = pred_boxes[indices]\n",
        "    pred_class_ids = pred_class_ids[indices]\n",
        "    pred_scores = pred_scores[indices]\n",
        "    pred_masks = pred_masks[..., indices]\n",
        "\n",
        "    # Compute IoU overlaps [pred_masks, gt_masks]\n",
        "    overlaps = compute_overlaps_masks(pred_masks, gt_masks)\n",
        "\n",
        "    # Loop through predictions and find matching ground truth boxes\n",
        "    match_count = 0\n",
        "    pred_match = -1 * np.ones([pred_boxes.shape[0]])\n",
        "    gt_match = -1 * np.ones([gt_boxes.shape[0]])\n",
        "    for i in range(len(pred_boxes)):\n",
        "        # Find best matching ground truth box\n",
        "        # 1. Sort matches by score\n",
        "        sorted_ixs = np.argsort(overlaps[i])[::-1]\n",
        "        # 2. Remove low scores\n",
        "        low_score_idx = np.where(overlaps[i, sorted_ixs] < score_threshold)[0]\n",
        "        if low_score_idx.size > 0:\n",
        "            sorted_ixs = sorted_ixs[:low_score_idx[0]]\n",
        "        # 3. Find the match\n",
        "        for j in sorted_ixs:\n",
        "            # If ground truth box is already matched, go to next one\n",
        "            if gt_match[j] > -1:\n",
        "                continue\n",
        "            # If we reach IoU smaller than the threshold, end the loop\n",
        "            iou = overlaps[i, j]\n",
        "            if iou < iou_threshold:\n",
        "                break\n",
        "            # Do we have a match?\n",
        "            \n",
        "            match_count += 1\n",
        "            gt_match[j] = i\n",
        "            pred_match[i] = j\n",
        "            break\n",
        "\n",
        "    return gt_match, pred_match, overlaps"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0RZ4wxeQbBu",
        "colab_type": "code",
        "outputId": "058e3407-4bf7-4041-d0e1-d96a4bd7968a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "class_names = ['BG'] + dataset_val.class_names[2:]\n",
        "\n",
        "\n",
        "image_ids = np.random.choice(dataset_val.image_ids, 2000)\n",
        "class_PMF = np.zeros((len(selected_classes), (len(selected_classes))))\n",
        "for image_id in image_ids:\n",
        "    image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "          modellib.load_image_gt(dataset_val, config,\n",
        "                                image_id, use_mini_mask=False)\n",
        "    results = model.detect([image], verbose=0)\n",
        "    r = results[0]\n",
        "    # visualize.display_instances(image, boxes=r['rois'], masks=r['masks'], class_ids=r['class_ids'], class_names=class_names, scores=r['scores'])\n",
        "    gt_match, pred_match, overlaps = compute_matches(gt_boxes=gt_bbox, gt_class_ids=gt_class_id, gt_masks=gt_mask, pred_boxes=r['rois'], \n",
        "                          pred_class_ids=r['class_ids'], pred_scores=r['scores'], pred_masks=r['masks'], iou_threshold=0.5)\n",
        "    \n",
        "    gt_match = list(map(int, gt_match))\n",
        "    \n",
        "    for i, matched_pred in enumerate(gt_match):\n",
        "        if matched_pred == -1:  \n",
        "            class_PMF[gt_class_id[i], 0] += 1 \n",
        "        else:\n",
        "            class_PMF[gt_class_id[i], r['class_ids'][matched_pred]] += 1 \n",
        "\n",
        "    for i, matched_gt in enumerate(pred_match):\n",
        "        if matched_gt == -1:\n",
        "            class_PMF[0, r['class_ids'][i]] += 1 \n",
        "for i, class_Pr in enumerate(class_PMF):\n",
        "    summed = class_Pr.sum()\n",
        "    if summed > 0:\n",
        "        class_PMF[i,:] = class_PMF[i,:]/summed\n",
        "print(class_PMF)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:You are using the default load_mask(), maybe you need to define your own one.\n",
            "WARNING:root:You are using the default load_mask(), maybe you need to define your own one.\n",
            "WARNING:root:You are using the default load_mask(), maybe you need to define your own one.\n",
            "WARNING:root:You are using the default load_mask(), maybe you need to define your own one.\n",
            "WARNING:root:You are using the default load_mask(), maybe you need to define your own one.\n",
            "WARNING:root:You are using the default load_mask(), maybe you need to define your own one.\n",
            "WARNING:root:You are using the default load_mask(), maybe you need to define your own one.\n",
            "WARNING:root:You are using the default load_mask(), maybe you need to define your own one.\n",
            "WARNING:root:You are using the default load_mask(), maybe you need to define your own one.\n",
            "WARNING:root:You are using the default load_mask(), maybe you need to define your own one.\n",
            "WARNING:root:You are using the default load_mask(), maybe you need to define your own one.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[0.000e+00 4.244e+03 1.540e+02 3.900e+01 1.320e+02 3.300e+02 1.200e+01\n",
            "  4.170e+02 0.000e+00 8.020e+02 9.622e+03 2.500e+02 2.716e+03 1.598e+03\n",
            "  1.148e+03 2.529e+03 3.570e+02]\n",
            " [2.543e+03 1.524e+03 0.000e+00 0.000e+00 0.000e+00 6.000e+00 0.000e+00\n",
            "  0.000e+00 0.000e+00 1.100e+01 6.000e+00 0.000e+00 0.000e+00 2.700e+01\n",
            "  3.900e+01 2.920e+02 1.200e+01]\n",
            " [2.100e+02 0.000e+00 5.200e+01 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
            "  1.400e+01 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
            "  0.000e+00 0.000e+00 0.000e+00]\n",
            " [2.200e+01 0.000e+00 0.000e+00 2.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
            "  0.000e+00 0.000e+00 4.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
            "  0.000e+00 0.000e+00 0.000e+00]\n",
            " [2.700e+01 0.000e+00 0.000e+00 0.000e+00 2.600e+01 0.000e+00 0.000e+00\n",
            "  0.000e+00 0.000e+00 0.000e+00 8.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
            "  0.000e+00 1.000e+00 0.000e+00]\n",
            " [2.390e+02 2.000e+01 0.000e+00 1.000e+00 2.000e+00 8.800e+01 0.000e+00\n",
            "  0.000e+00 0.000e+00 4.000e+00 0.000e+00 0.000e+00 0.000e+00 7.000e+00\n",
            "  2.100e+01 8.000e+00 2.400e+01]\n",
            " [2.600e+01 6.000e+00 0.000e+00 0.000e+00 1.000e+00 2.000e+00 3.000e+00\n",
            "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
            "  1.000e+00 3.000e+00 1.000e+00]\n",
            " [3.370e+02 0.000e+00 1.700e+01 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
            "  2.190e+02 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
            "  0.000e+00 0.000e+00 0.000e+00]\n",
            " [2.300e+01 1.000e+00 0.000e+00 0.000e+00 0.000e+00 2.000e+00 0.000e+00\n",
            "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
            "  0.000e+00 2.000e+00 1.000e+00]\n",
            " [3.790e+02 1.000e+00 0.000e+00 3.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
            "  0.000e+00 0.000e+00 6.000e+02 0.000e+00 0.000e+00 0.000e+00 4.000e+00\n",
            "  3.000e+00 3.000e+00 0.000e+00]\n",
            " [5.680e+03 2.000e+00 0.000e+00 0.000e+00 6.000e+00 0.000e+00 0.000e+00\n",
            "  1.000e+00 0.000e+00 1.000e+00 2.892e+03 0.000e+00 1.800e+02 0.000e+00\n",
            "  3.000e+00 2.000e+00 5.000e+00]\n",
            " [2.200e+02 3.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
            "  0.000e+00 0.000e+00 0.000e+00 6.000e+00 5.000e+00 2.000e+00 0.000e+00\n",
            "  1.000e+00 0.000e+00 0.000e+00]\n",
            " [2.003e+03 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
            "  0.000e+00 0.000e+00 4.000e+00 2.900e+02 0.000e+00 9.480e+02 0.000e+00\n",
            "  0.000e+00 0.000e+00 0.000e+00]\n",
            " [9.090e+02 1.000e+01 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
            "  0.000e+00 0.000e+00 1.300e+01 0.000e+00 0.000e+00 0.000e+00 1.741e+03\n",
            "  3.600e+01 4.200e+01 0.000e+00]\n",
            " [6.180e+02 1.900e+01 0.000e+00 0.000e+00 1.000e+00 6.000e+00 0.000e+00\n",
            "  0.000e+00 0.000e+00 5.000e+00 0.000e+00 0.000e+00 0.000e+00 1.700e+01\n",
            "  3.240e+02 3.800e+01 0.000e+00]\n",
            " [1.330e+03 3.030e+02 0.000e+00 0.000e+00 2.000e+00 0.000e+00 0.000e+00\n",
            "  0.000e+00 0.000e+00 6.000e+00 5.000e+00 0.000e+00 0.000e+00 4.400e+01\n",
            "  4.400e+01 2.532e+03 0.000e+00]\n",
            " [3.120e+02 1.300e+01 0.000e+00 0.000e+00 1.000e+00 1.700e+01 0.000e+00\n",
            "  0.000e+00 0.000e+00 0.000e+00 8.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
            "  0.000e+00 2.000e+00 1.350e+02]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szdZSoKQLI0z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dfe9056f-2076-4855-c018-9e0388392898"
      },
      "source": [
        "for i, class_Pr in enumerate(class_PMF):\n",
        "    summed = class_Pr.sum()\n",
        "    if summed > 0:\n",
        "        class_PMF[i,:] = class_PMF[i,:]/summed\n",
        "print(class_PMF)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.00000000e+00 1.74291581e-01 6.32443532e-03 1.60164271e-03\n",
            "  5.42094456e-03 1.35523614e-02 4.92813142e-04 1.71252567e-02\n",
            "  0.00000000e+00 3.29363450e-02 3.95154004e-01 1.02669405e-02\n",
            "  1.11540041e-01 6.56262834e-02 4.71457906e-02 1.03860370e-01\n",
            "  1.46611910e-02]\n",
            " [5.70179372e-01 3.41704036e-01 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 1.34529148e-03 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 2.46636771e-03 1.34529148e-03 0.00000000e+00\n",
            "  0.00000000e+00 6.05381166e-03 8.74439462e-03 6.54708520e-02\n",
            "  2.69058296e-03]\n",
            " [7.60869565e-01 0.00000000e+00 1.88405797e-01 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 5.07246377e-02\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00]\n",
            " [7.85714286e-01 0.00000000e+00 0.00000000e+00 7.14285714e-02\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 1.42857143e-01 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00]\n",
            " [4.35483871e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  4.19354839e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 1.29032258e-01 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 1.61290323e-02\n",
            "  0.00000000e+00]\n",
            " [5.77294686e-01 4.83091787e-02 0.00000000e+00 2.41545894e-03\n",
            "  4.83091787e-03 2.12560386e-01 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 9.66183575e-03 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 1.69082126e-02 5.07246377e-02 1.93236715e-02\n",
            "  5.79710145e-02]\n",
            " [6.04651163e-01 1.39534884e-01 0.00000000e+00 0.00000000e+00\n",
            "  2.32558140e-02 4.65116279e-02 6.97674419e-02 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 2.32558140e-02 6.97674419e-02\n",
            "  2.32558140e-02]\n",
            " [5.88132635e-01 0.00000000e+00 2.96684119e-02 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 3.82198953e-01\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00]\n",
            " [7.93103448e-01 3.44827586e-02 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 6.89655172e-02 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 6.89655172e-02\n",
            "  3.44827586e-02]\n",
            " [3.81671702e-01 1.00704935e-03 0.00000000e+00 3.02114804e-03\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 6.04229607e-01 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 4.02819738e-03 3.02114804e-03 3.02114804e-03\n",
            "  0.00000000e+00]\n",
            " [6.47514820e-01 2.27998176e-04 0.00000000e+00 0.00000000e+00\n",
            "  6.83994528e-04 0.00000000e+00 0.00000000e+00 1.13999088e-04\n",
            "  0.00000000e+00 1.13999088e-04 3.29685363e-01 0.00000000e+00\n",
            "  2.05198358e-02 0.00000000e+00 3.41997264e-04 2.27998176e-04\n",
            "  5.69995440e-04]\n",
            " [9.28270042e-01 1.26582278e-02 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 2.53164557e-02 2.10970464e-02\n",
            "  8.43881857e-03 0.00000000e+00 4.21940928e-03 0.00000000e+00\n",
            "  0.00000000e+00]\n",
            " [6.17257319e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 1.23266564e-03 8.93682589e-02 0.00000000e+00\n",
            "  2.92141757e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00]\n",
            " [3.30425300e-01 3.63504180e-03 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 4.72555434e-03 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 6.32860778e-01 1.30861505e-02 1.52671756e-02\n",
            "  0.00000000e+00]\n",
            " [6.01167315e-01 1.84824903e-02 0.00000000e+00 0.00000000e+00\n",
            "  9.72762646e-04 5.83657588e-03 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 4.86381323e-03 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 1.65369650e-02 3.15175097e-01 3.69649805e-02\n",
            "  0.00000000e+00]\n",
            " [3.11767464e-01 7.10267229e-02 0.00000000e+00 0.00000000e+00\n",
            "  4.68823254e-04 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 1.40646976e-03 1.17205813e-03 0.00000000e+00\n",
            "  0.00000000e+00 1.03141116e-02 1.03141116e-02 5.93530239e-01\n",
            "  0.00000000e+00]\n",
            " [6.39344262e-01 2.66393443e-02 0.00000000e+00 0.00000000e+00\n",
            "  2.04918033e-03 3.48360656e-02 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 1.63934426e-02 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 4.09836066e-03\n",
            "  2.76639344e-01]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hboqg2TzpNSD",
        "colab_type": "code",
        "outputId": "415e397d-7e50-4870-e705-4f192e5fa402",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "class_names = ['BG'] + dataset_val.class_names[2:]\n",
        "print(len(class_names))\n",
        "PMF_dict = {}\n",
        "for i, class_Pr in enumerate(class_PMF):\n",
        "    PMF_dict[class_names[i]] = list(class_Pr)\n",
        "print(PMF_dict)\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "17\n",
            "{'BG': [0.0, 0.17429158110882956, 0.006324435318275154, 0.0016016427104722792, 0.00542094455852156, 0.013552361396303902, 0.0004928131416837782, 0.017125256673511294, 0.0, 0.03293634496919918, 0.3951540041067762, 0.01026694045174538, 0.1115400410677618, 0.06562628336755646, 0.047145790554414785, 0.10386036960985626, 0.014661190965092403], 'Billboard': [0.5701793721973094, 0.3417040358744395, 0.0, 0.0, 0.0, 0.0013452914798206279, 0.0, 0.0, 0.0, 0.002466367713004484, 0.0013452914798206279, 0.0, 0.0, 0.006053811659192825, 0.00874439461883408, 0.06547085201793722, 0.0026905829596412557], 'Catch Basin': [0.7608695652173914, 0.0, 0.18840579710144928, 0.0, 0.0, 0.0, 0.0, 0.050724637681159424, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'CCTV Camera': [0.7857142857142857, 0.0, 0.0, 0.07142857142857142, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14285714285714285, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'Fire Hydrant': [0.43548387096774194, 0.0, 0.0, 0.0, 0.41935483870967744, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12903225806451613, 0.0, 0.0, 0.0, 0.0, 0.016129032258064516, 0.0], 'Junction Box': [0.5772946859903382, 0.04830917874396135, 0.0, 0.0024154589371980675, 0.004830917874396135, 0.21256038647342995, 0.0, 0.0, 0.0, 0.00966183574879227, 0.0, 0.0, 0.0, 0.016908212560386472, 0.050724637681159424, 0.01932367149758454, 0.057971014492753624], 'Mailbox': [0.6046511627906976, 0.13953488372093023, 0.0, 0.0, 0.023255813953488372, 0.046511627906976744, 0.06976744186046512, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.023255813953488372, 0.06976744186046512, 0.023255813953488372], 'Manhole': [0.5881326352530541, 0.0, 0.029668411867364748, 0.0, 0.0, 0.0, 0.0, 0.38219895287958117, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'Phone Booth': [0.7931034482758621, 0.034482758620689655, 0.0, 0.0, 0.0, 0.06896551724137931, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06896551724137931, 0.034482758620689655], 'Street Light': [0.3816717019133938, 0.0010070493454179255, 0.0, 0.0030211480362537764, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6042296072507553, 0.0, 0.0, 0.0, 0.004028197381671702, 0.0030211480362537764, 0.0030211480362537764, 0.0], 'Pole': [0.647514819881441, 0.00022799817601459188, 0.0, 0.0, 0.0006839945280437756, 0.0, 0.0, 0.00011399908800729594, 0.0, 0.00011399908800729594, 0.32968536251709984, 0.0, 0.02051983584131327, 0.0, 0.0003419972640218878, 0.00022799817601459188, 0.0005699954400364797], 'Traffic Sign Frame': [0.9282700421940928, 0.012658227848101266, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02531645569620253, 0.02109704641350211, 0.008438818565400843, 0.0, 0.004219409282700422, 0.0, 0.0], 'Utility Pole': [0.6172573189522342, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0012326656394453005, 0.08936825885978428, 0.0, 0.2921417565485362, 0.0, 0.0, 0.0, 0.0], 'Traffic Light': [0.33042529989094876, 0.0036350418029807343, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004725554343874954, 0.0, 0.0, 0.0, 0.6328607778989458, 0.013086150490730643, 0.015267175572519083, 0.0], 'Traffic Sign (Back)': [0.6011673151750972, 0.01848249027237354, 0.0, 0.0, 0.0009727626459143969, 0.005836575875486381, 0.0, 0.0, 0.0, 0.0048638132295719845, 0.0, 0.0, 0.0, 0.016536964980544747, 0.3151750972762646, 0.03696498054474708, 0.0], 'Traffic Sign (Front)': [0.31176746366619784, 0.0710267229254571, 0.0, 0.0, 0.00046882325363338024, 0.0, 0.0, 0.0, 0.0, 0.0014064697609001407, 0.0011720581340834506, 0.0, 0.0, 0.010314111579934365, 0.010314111579934365, 0.5935302390998594, 0.0], 'Trash Can': [0.639344262295082, 0.02663934426229508, 0.0, 0.0, 0.0020491803278688526, 0.03483606557377049, 0.0, 0.0, 0.0, 0.0, 0.01639344262295082, 0.0, 0.0, 0.0, 0.0, 0.004098360655737705, 0.2766393442622951]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F93H_fRrpzpK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "with open('/content/PMFs.json', 'w') as outfile:\n",
        "    json.dump(PMF_dict, outfile)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rz7MKxWOm9JY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def compute_batch_ap(image_ids):\n",
        "#     APs = []\n",
        "#     for image_id in image_ids:\n",
        "#         # Load image\n",
        "#         image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "#             modellib.load_image_gt(dataset_val, config,\n",
        "#                                    image_id, use_mini_mask=False)\n",
        "#         # Run object detection\n",
        "#         results = model.detect([image], verbose=0)\n",
        "#         # Compute AP\n",
        "#         r = results[0]\n",
        "#         AP, precisions, recalls, overlaps =\\\n",
        "#             utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
        "#                               r['rois'], r['class_ids'], r['scores'], r['masks'])\n",
        "#         APs.append(AP)\n",
        "#     return APs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQ1Rt7ClnBa8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# image_ids = np.random.choice(dataset_val.image_ids, 300)\n",
        "# APs = compute_batch_ap(image_ids)\n",
        "# print(\"mAP @ IoU=50: \", np.mean(APs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iVmvf40nDek",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_batch_ap_classwise(image_ids):\n",
        "    mAPs = np.zeros([len(selected_classes)])\n",
        "    numAPs = np.zeros([len(selected_classes)])\n",
        "    for image_id in image_ids:\n",
        "        # Load image\n",
        "        image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "            modellib.load_image_gt(dataset_val, config,\n",
        "                                  image_id, use_mini_mask=False)\n",
        "        # Run object detection\n",
        "        results = model.detect([image], verbose=0)\n",
        "        # Compute AP\n",
        "        r = results[0]\n",
        "        # visualize.display_instances(image, boxes=r['rois'], masks=r['masks'], class_ids=r['class_ids'], class_names=dataset_val.class_names[1:], scores=r['scores'])\n",
        "        # visualize.display_instances(image, boxes=gt_bbox, masks=gt_mask, class_ids=gt_class_id, class_names=dataset_val.class_names[1:])\n",
        "\n",
        "        for i, class_id in enumerate(range(17)):\n",
        "            # Select one class\n",
        "            mask = np.where(gt_class_id == class_id, True, False)\n",
        "            gt_class_id_sel = gt_class_id[mask]\n",
        "\n",
        "            gt_bbox_sel = gt_bbox[mask,:]\n",
        "            gt_mask_sel = gt_mask[:,:,mask]\n",
        "                            \n",
        "            # Select one class\n",
        "            mask = np.where(r['class_ids'] == class_id, True, False)\n",
        "            r_rois_sel = r['rois'][mask,:]\n",
        "            r_class_ids_sel = r['class_ids'][mask]\n",
        "            r_scores_sel = r['scores'][mask]\n",
        "            r_masks_sel = r['masks'][:,:,mask] \n",
        "            if len(gt_class_id_sel) != 0:\n",
        "                AP, precisions, recalls, overlaps =\\\n",
        "                    utils.compute_ap(gt_bbox_sel, gt_class_id_sel, gt_mask_sel,\n",
        "                                      r_rois_sel, r_class_ids_sel, r_scores_sel, r_masks_sel)\n",
        "                print(\"precisions: {}\".format(precisions))\n",
        "                mAPs[i] = mAPs[i] + AP\n",
        "                # print(\"mAPs: {}\".format(mAPs))\n",
        "                numAPs[i] += 1\n",
        "                # print(\"numAPs: {}\".format(numAPs))\n",
        "\n",
        "    # print(\"mAPs: {}\".format(mAPs))\n",
        "    # print(\"numAPs: {}\".format(numAPs))\n",
        "    mAPs = mAPs / numAPs\n",
        "    return mAPs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzxXBPn-liLM",
        "colab_type": "code",
        "outputId": "a8f34ba2-805d-4ca7-970e-4a812f1f2b86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "image_ids = np.random.choice(dataset_val.image_ids,2)\n",
        "# image_ids = [50]\n",
        "APs = compute_batch_ap_classwise(image_ids)\n",
        "print(\"mAP @ IoU=50: \", APs)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "precisions: [1. 1. 0.]\n",
            "precisions: [0.5        0.5        0.5        0.33333333 0.25       0.2\n",
            " 0.        ]\n",
            "precisions: [1. 1. 0.]\n",
            "precisions: [1. 1. 0.]\n",
            "precisions: [1. 1. 0.]\n",
            "precisions: [0.33333333 0.33333333 0.33333333 0.33333333 0.25       0.2\n",
            " 0.16666667 0.14285714 0.        ]\n",
            "mAP @ IoU=50:  [       nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 1.         0.29166667        nan\n",
            " 0.5               nan        nan 0.5               nan]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:40: RuntimeWarning: invalid value encountered in true_divide\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-Y2WsirPlAN",
        "colab_type": "code",
        "outputId": "cf64f905-76b2-4488-ca77-6e3b37fc388b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "mAP_opt = 0\n",
        "thresh_opt = 0\n",
        "class_id = 9\n",
        "image_ids = np.random.choice(dataset_val.image_ids,500)\n",
        "\n",
        "for thresh in range(20):\n",
        "    thresh = thresh/20\n",
        "    mAP = compute_batch_ap_classwise_thresh(image_ids, class_id, thresh)\n",
        "    print(mAP)\n",
        "    print(thresh)\n",
        "    if mAP > mAP_opt:\n",
        "        mAP_opt = mAP\n",
        "        thresh_opt = thresh"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-373f78049779>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthresh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mthresh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthresh\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mmAP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_batch_ap_classwise_thresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmAP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthresh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'compute_batch_ap_classwise_thresh' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9muJiFvwYxKS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(mAP_opt)\n",
        "print(thresh_opt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yloSiIQpCYcQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SAVE_DIR = '/content/Results'\n",
        "image_ids = np.random.choice(dataset_val.image_ids,4)\n",
        "for image_id in image_ids:\n",
        "    image = dataset_val.load_image(image_id)\n",
        "    results = model.detect([image], verbose=0)\n",
        "    r = results[0]\n",
        "    visualize.save_image(image = image[:,:,::-1], image_name=image_id, boxes=r['rois'], masks=r['masks'], class_ids=r['class_ids'], class_names=class_names, scores=r['scores'], save_dir=SAVE_DIR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGnyg_JypZGo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_names = ['Bench', 'Billboard', 'Catch Basin', 'CCTV Camera', 'Fire Hydrant', 'Junction Box', 'Mailbox',\n",
        "               'Manhole', 'Phone Booth', 'Street Light', 'Pole', 'Traffic Sign Frame', 'Utility Pole',\n",
        "               'Traffic Light', 'Traffic Sign (Back)', 'Traffic Sign (Front)', 'Trash Can']\n",
        "print(dataset_val.class_names[1:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHgMrQYDBpVd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(APs)):\n",
        "    print(\"class name: {}: mAP: {}\".format(class_names[i], APs[i]))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itQiOK_GOR0U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_batch_ap_classwise_thresh(image_ids, class_id, thresh):\n",
        "    mPs = 0\n",
        "    numPs = 0\n",
        "    for image_id in image_ids:\n",
        "        # Load image\n",
        "        image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "            modellib.load_image_gt(dataset_val, config,\n",
        "                                  image_id, use_mini_mask=False)\n",
        "        # Run object detection\n",
        "        results = model.detect([image], verbose=0)\n",
        "        # Compute AP\n",
        "        r = results[0]\n",
        "        # visualize.display_instances(image, boxes=r['rois'], masks=r['masks'], class_ids=r['class_ids'], class_names=dataset_val.class_names[1:], scores=r['scores'])\n",
        "        # visualize.display_instances(image, boxes=gt_bbox, masks=gt_mask, class_ids=gt_class_id, class_names=dataset_val.class_names[1:])\n",
        "\n",
        "    \n",
        "        # Select one class\n",
        "        mask = np.where(gt_class_id == class_id, True, False)\n",
        "        gt_class_id_sel = gt_class_id[mask]\n",
        "\n",
        "        gt_bbox_sel = gt_bbox[mask,:]\n",
        "        gt_mask_sel = gt_mask[:,:,mask]\n",
        "                        \n",
        "        # Select class and scores higher than threshold\n",
        "        mask = np.where(np.logical_and(r['class_ids'] == class_id, r['scores'] > thresh), True, False)\n",
        "        r_rois_sel = r['rois'][mask,:]\n",
        "        r_class_ids_sel = r['class_ids'][mask]\n",
        "        r_scores_sel = r['scores'][mask]\n",
        "        r_masks_sel = r['masks'][:,:,mask] \n",
        "        if len(r_class_ids_sel) != 0:\n",
        "            AP, precisions, recalls, overlaps =\\\n",
        "                utils.compute_ap(gt_bbox_sel, gt_class_id_sel, gt_mask_sel,\n",
        "                                  r_rois_sel, r_class_ids_sel, r_scores_sel, r_masks_sel)\n",
        "            mPs = mPs + precisions[-2]\n",
        "            numPs += 1\n",
        "\n",
        "    print(\"numPs: {}\".format(numPs))\n",
        "    mPs = mPs / numPs\n",
        "    return mPs"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}