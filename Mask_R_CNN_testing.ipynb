{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mask-R-CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "https://github.com/juliuserbach/Semantic-Features/blob/master/Mask_R_CNN_testing.ipynb",
      "authorship_tag": "ABX9TyOzwxd9Qvvzn4+M+IZVLgY+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juliuserbach/Semantic-Features/blob/master/Mask_R_CNN_testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqs13ramKg_K",
        "colab_type": "code",
        "outputId": "bd0e7eb7-4bd1-4585-f6c6-7bbcb3565e7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!git clone https://github.com/ftaubner/semantic_features_detection.git"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'semantic_features_detection' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMkSQoH1ZGYA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!wget --no-check-certificate \"https://onedrive.live.com/download?cid=EA356294C6263A37&resid=EA356294C6263A37%21100024&authkey=ADLJzehr2ENRggw\" -O mapillary_vistas.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrMxy5HqSm-f",
        "colab_type": "code",
        "outputId": "5808428a-c8b8-42f7-9a88-4f97a849a84d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "!wget --no-check-certificate \"https://onedrive.live.com/download?cid=EA356294C6263A37&resid=EA356294C6263A37%21101634&authkey=ABTiTiHVXMI06vU\"  -O mapillary_prelim.h5"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-22 17:19:22--  https://onedrive.live.com/download?cid=EA356294C6263A37&resid=EA356294C6263A37%21101634&authkey=ABTiTiHVXMI06vU\n",
            "Resolving onedrive.live.com (onedrive.live.com)... 13.107.42.13\n",
            "Connecting to onedrive.live.com (onedrive.live.com)|13.107.42.13|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://mmhp0a.am.files.1drv.com/y4mY-K1IgzETm4YVAGoVFpRoGzhoiw0zfjpauVP0yUhYPSmk6eG4eg-T_5PF_M-J4tMVCUKSneD5aDgeFyPYjwv_mqm3hCVT5kICPtefvaMOL-j9w-Eg_qLoJZ2l6p0Er1aWzRBWppH_hrMztu-YKNxslBH0YpciW17lLJEBsgJLw5B3LMHUHFXf9v5m21Q6WJyw8MHGjZQaOM6HjY0WKusJQ/mask_rcnn_mapvistas_0083.h5?download&psid=1 [following]\n",
            "--2020-05-22 17:19:23--  https://mmhp0a.am.files.1drv.com/y4mY-K1IgzETm4YVAGoVFpRoGzhoiw0zfjpauVP0yUhYPSmk6eG4eg-T_5PF_M-J4tMVCUKSneD5aDgeFyPYjwv_mqm3hCVT5kICPtefvaMOL-j9w-Eg_qLoJZ2l6p0Er1aWzRBWppH_hrMztu-YKNxslBH0YpciW17lLJEBsgJLw5B3LMHUHFXf9v5m21Q6WJyw8MHGjZQaOM6HjY0WKusJQ/mask_rcnn_mapvistas_0083.h5?download&psid=1\n",
            "Resolving mmhp0a.am.files.1drv.com (mmhp0a.am.files.1drv.com)... 13.107.42.12\n",
            "Connecting to mmhp0a.am.files.1drv.com (mmhp0a.am.files.1drv.com)|13.107.42.12|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 256204312 (244M) [application/octet-stream]\n",
            "Saving to: ‘mapillary_prelim.h5’\n",
            "\n",
            "mapillary_prelim.h5 100%[===================>] 244.33M  32.6MB/s    in 8.2s    \n",
            "\n",
            "2020-05-22 17:19:32 (29.9 MB/s) - ‘mapillary_prelim.h5’ saved [256204312/256204312]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nhJZTIzZpRW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!unzip -qq /content/mapillary_vistas.zip 'mapillary_vistas/validation/*' -d /content"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoNjvU1NcD-J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!unzip -qq /content/mapillary_vistas.zip 'mapillary_vistas/config.json' -d /content"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdvT1vzBK6hV",
        "colab_type": "code",
        "outputId": "c97a674d-cda8-4f45-ec12-84f3fe30ff09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "!pip install imgaug\n",
        "!pip install Cython\n",
        "!pip install pycocotools"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: imgaug in /usr/local/lib/python3.6/dist-packages (0.2.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from imgaug) (1.12.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from imgaug) (4.1.2.30)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.6/dist-packages (from imgaug) (2.4.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from imgaug) (1.4.1)\n",
            "Requirement already satisfied: scikit-image>=0.11.0 in /usr/local/lib/python3.6/dist-packages (from imgaug) (0.16.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from imgaug) (7.0.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from imgaug) (1.18.4)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.6/dist-packages (from imgaug) (1.7.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from imgaug) (3.2.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug) (1.1.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug) (2.4)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug) (2.4.7)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.11.0->imgaug) (4.4.2)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (0.29.18)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.6/dist-packages (2.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meGMIONOKySt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "b768cda2-fd04-456f-e4ea-40955a961e09"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/semantic_features_detection/samples/mapillary/cytools')\n",
        "!python setup.py build_ext --inplace\n",
        "os.chdir('/content/semantic_features_detection/Notebook')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "running build_ext\n",
            "building 'mask_tools' extension\n",
            "creating build\n",
            "creating build/temp.linux-x86_64-3.6\n",
            "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/numpy/core/include -I/usr/include/python3.6m -c mask_tools.c -o build/temp.linux-x86_64-3.6/mask_tools.o\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/ndarraytypes.h:1832:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kmask_tools.c:613\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\n",
            " #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\n",
            "  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "creating build/lib.linux-x86_64-3.6\n",
            "x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/mask_tools.o -o build/lib.linux-x86_64-3.6/mask_tools.cpython-36m-x86_64-linux-gnu.so\n",
            "copying build/lib.linux-x86_64-3.6/mask_tools.cpython-36m-x86_64-linux-gnu.so -> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viP6_e5JPNXO",
        "colab_type": "code",
        "outputId": "932086a8-3802-4be0-ccf9-12a5f8db103c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "import skimage.io\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import imageio\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "# Root directory of the project\n",
        "ROOT_DIR = os.path.abspath(\"../\")\n",
        "# Ignore Warnings\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
        "\n",
        "# Import Mask RCNN\n",
        "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
        "print(ROOT_DIR)\n",
        "from mrcnn import utils\n",
        "import mrcnn.model as modellib\n",
        "from mrcnn import visualize\n",
        "# Import COCO config\n",
        "sys.path.append(os.path.join(ROOT_DIR, \"samples/mapillary/\"))  # To find local version\n",
        "import mapillary_felix\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "# Directory to save logs and trained model\n",
        "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
        "print(MODEL_DIR)\n",
        "\n",
        "# Local path to trained weights file\n",
        "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
        "# Download COCO trained weights from Releases if needed\n",
        "if not os.path.exists(COCO_MODEL_PATH):\n",
        "    utils.download_trained_weights(COCO_MODEL_PATH)\n",
        "\n",
        "# Directory of images to run detection on\n",
        "IMAGE_DIR = os.path.join(ROOT_DIR, \"images\")\n",
        "print('finished')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/semantic_features_detection\n",
            "/content/semantic_features_detection/logs\n",
            "Downloading pretrained model to /content/semantic_features_detection/mask_rcnn_coco.h5 ...\n",
            "... done downloading pretrained model!\n",
            "finished\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXAqClvqXsLK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_names= ['Unlabeled', 'Bird', 'Ground Animal', 'Curb', 'Fence', 'Guard Rail', \n",
        "              'Barrier', 'Wall', 'Bike Lane', 'Crosswalk - Plain', 'Curb Cut', 'Parking', \n",
        "              'Pedestrian Area', 'Rail Track', 'Road', 'Service Lane', 'Sidewalk', 'Bridge', \n",
        "              'Building', 'Tunnel', 'Person', 'Bicyclist', 'Motorcyclist', 'Other Rider', \n",
        "              'Lane Marking - Crosswalk', 'Lane Marking - General', 'Mountain', 'Sand', \n",
        "              'Sky', 'Snow', 'Terrain', 'Vegetation', 'Water', 'Banner', 'Bench', 'Bike Rack',\n",
        "              'Billboard', 'Catch Basin', 'CCTV Camera', 'Fire Hydrant', 'Junction Box', 'Mailbox',\n",
        "              'Manhole', 'Phone Booth', 'Pothole', 'Street Light', 'Pole', 'Traffic Sign Frame', \n",
        "              'Utility Pole', 'Traffic Light', 'Traffic Sign (Back)', 'Traffic Sign (Front)',\n",
        "              'Trash Can', 'Bicycle', 'Boat', 'Bus', 'Car', 'Caravan', 'Motorcycle', 'On Rails',\n",
        "              'Other Vehicle', 'Trailer', 'Truck', 'Wheeled Slow', 'Car Mount', 'Ego Vehicle']\n",
        "selected_classes = [34, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52]\n",
        "\n",
        "print(selected_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHcm09WTUa4a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TRAIN_DIR = '/content/mapillary_vistas'\n",
        "# # Training dataset\n",
        "# dataset_train = mapillary.MapillaryDataset()\n",
        "# dataset_train.load_vistas(dataset_dir=TRAIN_DIR, subset='training', class_ids=selected_classes)\n",
        "# dataset_train.prepare()\n",
        "\n",
        "# Validation dataset\n",
        "VAL_DIR = '/content/drive/My Drive/mapillary_vistas/mapillary_vistas'\n",
        "\n",
        "dataset_val = mapillary.MapillaryDataset()\n",
        "dataset_val.load_vistas(dataset_dir=VAL_DIR, subset='validation', class_ids=selected_classes)\n",
        "dataset_val.prepare()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_a_fCrQWyvA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_ids = np.random.choice(dataset_val.image_ids, 4)\n",
        "for image_id in image_ids:\n",
        "    image = dataset_val.load_image(image_id)\n",
        "    print(dataset_val.class_names)\n",
        "    mask, class_ids = dataset_val.load_mask(image_id)\n",
        "    visualize.display_top_masks(image, mask, class_ids, dataset_val.class_names[1:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVW7e7R1UWAZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class InferenceConfig(mapillary.mapvistas):\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "    DETECTION_MIN_CONFIDENCE = 0\n",
        "    NUM_CLASSES = len(selected_classes) + 1\n",
        "config = InferenceConfig()\n",
        "config.display()\n",
        "batch_size = config.BATCH_SIZE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P81V1BRHUYu1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create model in training mode\n",
        "model = modellib.MaskRCNN(mode=\"inference\", config=config,\n",
        "                          model_dir=MODEL_DIR)\n",
        "model_path = '/content/mapillary_prelim.h5'\n",
        "model.load_weights(model_path, by_name=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rz7MKxWOm9JY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def compute_batch_ap(image_ids):\n",
        "#     APs = []\n",
        "#     for image_id in image_ids:\n",
        "#         # Load image\n",
        "#         image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "#             modellib.load_image_gt(dataset_val, config,\n",
        "#                                    image_id, use_mini_mask=False)\n",
        "#         # Run object detection\n",
        "#         results = model.detect([image], verbose=0)\n",
        "#         # Compute AP\n",
        "#         r = results[0]\n",
        "#         AP, precisions, recalls, overlaps =\\\n",
        "#             utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
        "#                               r['rois'], r['class_ids'], r['scores'], r['masks'])\n",
        "#         APs.append(AP)\n",
        "#     return APs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQ1Rt7ClnBa8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# image_ids = np.random.choice(dataset_val.image_ids, 300)\n",
        "# APs = compute_batch_ap(image_ids)\n",
        "# print(\"mAP @ IoU=50: \", np.mean(APs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iVmvf40nDek",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_batch_ap_classwise(image_ids):\n",
        "    mAPs = np.zeros([len(selected_classes)])\n",
        "    numAPs = np.zeros([len(selected_classes)])\n",
        "    for image_id in image_ids:\n",
        "        # Load image\n",
        "        image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "            modellib.load_image_gt(dataset_val, config,\n",
        "                                  image_id, use_mini_mask=False)\n",
        "        # Run object detection\n",
        "        results = model.detect([image], verbose=0)\n",
        "        # Compute AP\n",
        "        r = results[0]\n",
        "        # visualize.display_instances(image, boxes=r['rois'], masks=r['masks'], class_ids=r['class_ids'], class_names=dataset_val.class_names[1:], scores=r['scores'])\n",
        "        # visualize.display_instances(image, boxes=gt_bbox, masks=gt_mask, class_ids=gt_class_id, class_names=dataset_val.class_names[1:])\n",
        "\n",
        "        for i, class_id in enumerate(range(17)):\n",
        "            # Select one class\n",
        "            mask = np.where(gt_class_id == class_id, True, False)\n",
        "            gt_class_id_sel = gt_class_id[mask]\n",
        "\n",
        "            gt_bbox_sel = gt_bbox[mask,:]\n",
        "            gt_mask_sel = gt_mask[:,:,mask]\n",
        "                            \n",
        "            # Select one class\n",
        "            mask = np.where(r['class_ids'] == class_id, True, False)\n",
        "            r_rois_sel = r['rois'][mask,:]\n",
        "            r_class_ids_sel = r['class_ids'][mask]\n",
        "            r_scores_sel = r['scores'][mask]\n",
        "            r_masks_sel = r['masks'][:,:,mask] \n",
        "            if len(gt_class_id_sel) != 0:\n",
        "                AP, precisions, recalls, overlaps =\\\n",
        "                    utils.compute_ap(gt_bbox_sel, gt_class_id_sel, gt_mask_sel,\n",
        "                                      r_rois_sel, r_class_ids_sel, r_scores_sel, r_masks_sel)\n",
        "                print(\"precisions: {}\".format(precisions))\n",
        "                mAPs[i] = mAPs[i] + AP\n",
        "                # print(\"mAPs: {}\".format(mAPs))\n",
        "                numAPs[i] += 1\n",
        "                # print(\"numAPs: {}\".format(numAPs))\n",
        "\n",
        "    # print(\"mAPs: {}\".format(mAPs))\n",
        "    # print(\"numAPs: {}\".format(numAPs))\n",
        "    mAPs = mAPs / numAPs\n",
        "    return mAPs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzxXBPn-liLM",
        "colab_type": "code",
        "outputId": "e99095d1-cf0e-4822-e21f-564fbaae021d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "image_ids = np.random.choice(dataset_val.image_ids,2)\n",
        "# image_ids = [50]\n",
        "APs = compute_batch_ap_classwise(image_ids)\n",
        "print(\"mAP @ IoU=50: \", APs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "precisions: [1.  1.  0.5 0. ]\n",
            "precisions: [1.  1.  0.5 0. ]\n",
            "precisions: [0.5        0.5        0.5        0.5        0.5        0.4\n",
            " 0.33333333 0.        ]\n",
            "precisions: [0. 0.]\n",
            "precisions: [0.33333333 0.33333333 0.33333333 0.33333333 0.25       0.2\n",
            " 0.16666667 0.14285714 0.125      0.11111111 0.        ]\n",
            "precisions: [1.         1.         0.5        0.33333333 0.25       0.2\n",
            " 0.        ]\n",
            "precisions: [1. 1. 0.]\n",
            "precisions: [0. 0. 0.]\n",
            "precisions: [0. 0. 0.]\n",
            "precisions: [1. 1. 0.]\n",
            "mAP @ IoU=50:  [       nan 0.0625            nan        nan        nan 0.\n",
            "        nan        nan        nan        nan 0.25925926        nan\n",
            " 0.06666667 0.16666667 0.         0.25       1.        ]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:40: RuntimeWarning: invalid value encountered in true_divide\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itQiOK_GOR0U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_batch_ap_classwise_thresh(image_ids, class_id, thresh):\n",
        "    mPs = 0\n",
        "    numPs = 0\n",
        "    for image_id in image_ids:\n",
        "        # Load image\n",
        "        image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "            modellib.load_image_gt(dataset_val, config,\n",
        "                                  image_id, use_mini_mask=False)\n",
        "        # Run object detection\n",
        "        results = model.detect([image], verbose=0)\n",
        "        # Compute AP\n",
        "        r = results[0]\n",
        "        # visualize.display_instances(image, boxes=r['rois'], masks=r['masks'], class_ids=r['class_ids'], class_names=dataset_val.class_names[1:], scores=r['scores'])\n",
        "        # visualize.display_instances(image, boxes=gt_bbox, masks=gt_mask, class_ids=gt_class_id, class_names=dataset_val.class_names[1:])\n",
        "\n",
        "    \n",
        "        # Select one class\n",
        "        mask = np.where(gt_class_id == class_id, True, False)\n",
        "        gt_class_id_sel = gt_class_id[mask]\n",
        "\n",
        "        gt_bbox_sel = gt_bbox[mask,:]\n",
        "        gt_mask_sel = gt_mask[:,:,mask]\n",
        "                        \n",
        "        # Select class and scores higher than threshold\n",
        "        mask = np.where(np.logical_and(r['class_ids'] == class_id, r['scores'] > thresh), True, False)\n",
        "        r_rois_sel = r['rois'][mask,:]\n",
        "        r_class_ids_sel = r['class_ids'][mask]\n",
        "        r_scores_sel = r['scores'][mask]\n",
        "        r_masks_sel = r['masks'][:,:,mask] \n",
        "        if len(r_class_ids_sel) != 0:\n",
        "            AP, precisions, recalls, overlaps =\\\n",
        "                utils.compute_ap(gt_bbox_sel, gt_class_id_sel, gt_mask_sel,\n",
        "                                  r_rois_sel, r_class_ids_sel, r_scores_sel, r_masks_sel)\n",
        "            mPs = mPs + precisions[-2]\n",
        "            numPs += 1\n",
        "\n",
        "    print(\"numPs: {}\".format(numPs))\n",
        "    mPs = mPs / numPs\n",
        "    return mPs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-Y2WsirPlAN",
        "colab_type": "code",
        "outputId": "7e28c51b-628e-43f0-b94a-2272f4b58af0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "mAP_opt = 0\n",
        "thresh_opt = 0\n",
        "class_id = 9\n",
        "image_ids = np.random.choice(dataset_val.image_ids,500)\n",
        "\n",
        "for thresh in range(20):\n",
        "    thresh = thresh/20\n",
        "    mAP = compute_batch_ap_classwise_thresh(image_ids, class_id, thresh)\n",
        "    print(mAP)\n",
        "    print(thresh)\n",
        "    if mAP > mAP_opt:\n",
        "        mAP_opt = mAP\n",
        "        thresh_opt = thresh"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/semantic_features_detection/mrcnn/utils.py:734: RuntimeWarning: invalid value encountered in true_divide\n",
            "  recalls = np.cumsum(pred_match > -1).astype(np.float32) / len(gt_match)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9muJiFvwYxKS",
        "colab_type": "code",
        "outputId": "3212835b-c1f2-4eea-c638-605b52be0de7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(mAP_opt)\n",
        "print(thresh_opt)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.09761124285445973\n",
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yloSiIQpCYcQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SAVE_DIR = '/content/Results'\n",
        "image_ids = np.random.choice(dataset_val.image_ids,4)\n",
        "for image_id in image_ids:\n",
        "    image = dataset_val.load_image(image_id)\n",
        "    results = model.detect([image], verbose=0)\n",
        "    r = results[0]\n",
        "    visualize.save_image(image = image[:,:,::-1], image_name=image_id, boxes=r['rois'], masks=r['masks'], class_ids=r['class_ids'], class_names=class_names, scores=r['scores'], save_dir=SAVE_DIR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGnyg_JypZGo",
        "colab_type": "code",
        "outputId": "5523403b-b604-4ed0-d26e-855904e1f890",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "class_names = ['Bench', 'Billboard', 'Catch Basin', 'CCTV Camera', 'Fire Hydrant', 'Junction Box', 'Mailbox',\n",
        "               'Manhole', 'Phone Booth', 'Street Light', 'Pole', 'Traffic Sign Frame', 'Utility Pole',\n",
        "               'Traffic Light', 'Traffic Sign (Back)', 'Traffic Sign (Front)', 'Trash Can']\n",
        "print(dataset_val.class_names[1:])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Bench', 'Billboard', 'Catch Basin', 'CCTV Camera', 'Fire Hydrant', 'Junction Box', 'Mailbox', 'Manhole', 'Phone Booth', 'Street Light', 'Pole', 'Traffic Sign Frame', 'Utility Pole', 'Traffic Light', 'Traffic Sign (Back)', 'Traffic Sign (Front)', 'Trash Can']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHgMrQYDBpVd",
        "colab_type": "code",
        "outputId": "9cfca803-b3d3-40ea-a516-f30186023ad5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "for i in range(len(APs)):\n",
        "    print(\"class name: {}: mAP: {}\".format(class_names[i], APs[i]))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "class name: Bench: mAP: nan\n",
            "class name: Billboard: mAP: 0.13378898509652173\n",
            "class name: Catch Basin: mAP: 0.08723088352212927\n",
            "class name: CCTV Camera: mAP: 0.009009009009009009\n",
            "class name: Fire Hydrant: mAP: 0.05945945945945946\n",
            "class name: Junction Box: mAP: 0.018995633194279982\n",
            "class name: Mailbox: mAP: 0.0\n",
            "class name: Manhole: mAP: 0.1898932374137172\n",
            "class name: Phone Booth: mAP: 0.0\n",
            "class name: Street Light: mAP: 0.16076993966647124\n",
            "class name: Pole: mAP: 0.07435044233169\n",
            "class name: Traffic Sign Frame: mAP: 0.0\n",
            "class name: Utility Pole: mAP: 0.10728754850566499\n",
            "class name: Traffic Light: mAP: 0.22378939301032894\n",
            "class name: Traffic Sign (Back): mAP: 0.06839771660148428\n",
            "class name: Traffic Sign (Front): mAP: 0.24776525653562692\n",
            "class name: Trash Can: mAP: 0.06402141058740836\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}