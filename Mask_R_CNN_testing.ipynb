{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mask-R-CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "https://github.com/juliuserbach/Semantic-Features/blob/master/Mask_R_CNN_testing.ipynb",
      "authorship_tag": "ABX9TyMCOgdbulqZJ//CpXfHkfS0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juliuserbach/Semantic-Features/blob/master/Mask_R_CNN_testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqs13ramKg_K",
        "colab_type": "code",
        "outputId": "43542a16-20f4-40d1-bca8-8e0aeae10684",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "!git clone https://github.com/ftaubner/semantic_features_detection.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'semantic_features_detection'...\n",
            "remote: Enumerating objects: 148, done.\u001b[K\n",
            "remote: Counting objects: 100% (148/148), done.\u001b[K\n",
            "remote: Compressing objects: 100% (114/114), done.\u001b[K\n",
            "remote: Total 1540 (delta 101), reused 61 (delta 34), pack-reused 1392\u001b[K\n",
            "Receiving objects: 100% (1540/1540), 114.36 MiB | 37.45 MiB/s, done.\n",
            "Resolving deltas: 100% (953/953), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMkSQoH1ZGYA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!wget --no-check-certificate \"https://onedrive.live.com/download?cid=EA356294C6263A37&resid=EA356294C6263A37%21100024&authkey=ADLJzehr2ENRggw\" -O mapillary_vistas.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrMxy5HqSm-f",
        "colab_type": "code",
        "outputId": "4ec59853-232b-47e3-973e-bf8a8ba2b620",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "!wget --no-check-certificate \"https://onedrive.live.com/download?cid=EA356294C6263A37&resid=EA356294C6263A37%21101634&authkey=ABTiTiHVXMI06vU\"  -O mapillary_prelim.h5"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-23 10:51:43--  https://onedrive.live.com/download?cid=EA356294C6263A37&resid=EA356294C6263A37%21101634&authkey=ABTiTiHVXMI06vU\n",
            "Resolving onedrive.live.com (onedrive.live.com)... 13.107.42.13\n",
            "Connecting to onedrive.live.com (onedrive.live.com)|13.107.42.13|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://mmhp0a.am.files.1drv.com/y4mlNqlNXqGDTpMw6yiVk1IyQdjkMk_jjWSI9ngaEPi_HjfX7Ma3FkcOgtkszJMdLLkr2fFtbiXGhWfzcbYtgUeB1Qi3kAaGzXJp8HAVWIUixcH0Ymw2qDCo5vG5kaE5o2r-MWmkzt0waB3BAsN6ByAspBATfthQyLdsPeXdzl-u9hGoT6HklOOpX83WQPc5A1Uurr-3OkSZ8kIriGpmoUTeA/mask_rcnn_mapvistas_0083.h5?download&psid=1 [following]\n",
            "--2020-05-23 10:51:44--  https://mmhp0a.am.files.1drv.com/y4mlNqlNXqGDTpMw6yiVk1IyQdjkMk_jjWSI9ngaEPi_HjfX7Ma3FkcOgtkszJMdLLkr2fFtbiXGhWfzcbYtgUeB1Qi3kAaGzXJp8HAVWIUixcH0Ymw2qDCo5vG5kaE5o2r-MWmkzt0waB3BAsN6ByAspBATfthQyLdsPeXdzl-u9hGoT6HklOOpX83WQPc5A1Uurr-3OkSZ8kIriGpmoUTeA/mask_rcnn_mapvistas_0083.h5?download&psid=1\n",
            "Resolving mmhp0a.am.files.1drv.com (mmhp0a.am.files.1drv.com)... 13.107.42.12\n",
            "Connecting to mmhp0a.am.files.1drv.com (mmhp0a.am.files.1drv.com)|13.107.42.12|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 256204312 (244M) [application/octet-stream]\n",
            "Saving to: ‘mapillary_prelim.h5’\n",
            "\n",
            "mapillary_prelim.h5 100%[===================>] 244.33M  30.5MB/s    in 11s     \n",
            "\n",
            "2020-05-23 10:51:57 (22.0 MB/s) - ‘mapillary_prelim.h5’ saved [256204312/256204312]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nhJZTIzZpRW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!unzip -qq /content/mapillary_vistas.zip 'mapillary_vistas/validation/*' -d /content"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoNjvU1NcD-J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!unzip -qq /content/mapillary_vistas.zip 'mapillary_vistas/config.json' -d /content"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdvT1vzBK6hV",
        "colab_type": "code",
        "outputId": "242eba71-186a-40b1-dc9f-32b6786e6106",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "!pip install imgaug\n",
        "!pip install Cython\n",
        "!pip install pycocotools"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: imgaug in /usr/local/lib/python3.6/dist-packages (0.2.9)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from imgaug) (7.0.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from imgaug) (3.2.1)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.6/dist-packages (from imgaug) (2.4.1)\n",
            "Requirement already satisfied: scikit-image>=0.11.0 in /usr/local/lib/python3.6/dist-packages (from imgaug) (0.16.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from imgaug) (1.18.4)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.6/dist-packages (from imgaug) (1.7.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from imgaug) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from imgaug) (1.12.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from imgaug) (4.1.2.30)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug) (0.10.0)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug) (1.1.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug) (2.4)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.11.0->imgaug) (4.4.2)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (0.29.18)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.6/dist-packages (2.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meGMIONOKySt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "795a8885-b20a-4bf5-b56f-8150d300290f"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/semantic_features_detection/samples/mapillary/cytools')\n",
        "!python setup.py build_ext --inplace\n",
        "os.chdir('/content/semantic_features_detection/Notebook')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "running build_ext\n",
            "building 'mask_tools' extension\n",
            "creating build\n",
            "creating build/temp.linux-x86_64-3.6\n",
            "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/numpy/core/include -I/usr/include/python3.6m -c mask_tools.c -o build/temp.linux-x86_64-3.6/mask_tools.o\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/ndarraytypes.h:1832:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kmask_tools.c:613\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\n",
            " #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\n",
            "  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "creating build/lib.linux-x86_64-3.6\n",
            "x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/mask_tools.o -o build/lib.linux-x86_64-3.6/mask_tools.cpython-36m-x86_64-linux-gnu.so\n",
            "copying build/lib.linux-x86_64-3.6/mask_tools.cpython-36m-x86_64-linux-gnu.so -> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viP6_e5JPNXO",
        "colab_type": "code",
        "outputId": "3525a6bd-3fb5-44f3-c9ab-1599e8af129a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "import skimage.io\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import imageio\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "# Root directory of the project\n",
        "ROOT_DIR = os.path.abspath(\"../\")\n",
        "# Ignore Warnings\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
        "\n",
        "# Import Mask RCNN\n",
        "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
        "print(ROOT_DIR)\n",
        "from mrcnn import utils\n",
        "import mrcnn.model_felix as modellib\n",
        "from mrcnn import visualize\n",
        "# Import COCO config\n",
        "sys.path.append(os.path.join(ROOT_DIR, \"samples/mapillary/\"))  # To find local version\n",
        "import mapillary_felix\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "# Directory to save logs and trained model\n",
        "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
        "print(MODEL_DIR)\n",
        "\n",
        "# Local path to trained weights file\n",
        "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
        "# Download COCO trained weights from Releases if needed\n",
        "if not os.path.exists(COCO_MODEL_PATH):\n",
        "    utils.download_trained_weights(COCO_MODEL_PATH)\n",
        "\n",
        "# Directory of images to run detection on\n",
        "IMAGE_DIR = os.path.join(ROOT_DIR, \"images\")\n",
        "print('finished')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "/content/semantic_features_detection\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/semantic_features_detection/logs\n",
            "Downloading pretrained model to /content/semantic_features_detection/mask_rcnn_coco.h5 ...\n",
            "... done downloading pretrained model!\n",
            "finished\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXAqClvqXsLK",
        "colab_type": "code",
        "outputId": "51ef258f-69e5-4b25-9ab8-9863e242164c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "class_names= ['Unlabeled', 'Bird', 'Ground Animal', 'Curb', 'Fence', 'Guard Rail', \n",
        "              'Barrier', 'Wall', 'Bike Lane', 'Crosswalk - Plain', 'Curb Cut', 'Parking', \n",
        "              'Pedestrian Area', 'Rail Track', 'Road', 'Service Lane', 'Sidewalk', 'Bridge', \n",
        "              'Building', 'Tunnel', 'Person', 'Bicyclist', 'Motorcyclist', 'Other Rider', \n",
        "              'Lane Marking - Crosswalk', 'Lane Marking - General', 'Mountain', 'Sand', \n",
        "              'Sky', 'Snow', 'Terrain', 'Vegetation', 'Water', 'Banner', 'Bench', 'Bike Rack',\n",
        "              'Billboard', 'Catch Basin', 'CCTV Camera', 'Fire Hydrant', 'Junction Box', 'Mailbox',\n",
        "              'Manhole', 'Phone Booth', 'Pothole', 'Street Light', 'Pole', 'Traffic Sign Frame', \n",
        "              'Utility Pole', 'Traffic Light', 'Traffic Sign (Back)', 'Traffic Sign (Front)',\n",
        "              'Trash Can', 'Bicycle', 'Boat', 'Bus', 'Car', 'Caravan', 'Motorcycle', 'On Rails',\n",
        "              'Other Vehicle', 'Trailer', 'Truck', 'Wheeled Slow', 'Car Mount', 'Ego Vehicle']\n",
        "selected_classes = [34, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52]\n",
        "\n",
        "print(selected_classes)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[34, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVW7e7R1UWAZ",
        "colab_type": "code",
        "outputId": "ed66b683-36d4-4946-f582-49b3beb646a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        }
      },
      "source": [
        "class InferenceConfig(mapillary_felix.mapvistas):\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "    DETECTION_MIN_CONFIDENCE = 0\n",
        "    NUM_CLASSES = len(selected_classes) + 1\n",
        "config = InferenceConfig()\n",
        "config.display()\n",
        "batch_size = config.BATCH_SIZE"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Configurations:\n",
            "BACKBONE                       resnet101\n",
            "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
            "BATCH_SIZE                     1\n",
            "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
            "COMPUTE_BACKBONE_SHAPE         None\n",
            "DETECTION_MAX_INSTANCES        100\n",
            "DETECTION_MIN_CONFIDENCE       0\n",
            "DETECTION_NMS_THRESHOLD        0.3\n",
            "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
            "GPU_COUNT                      1\n",
            "GRADIENT_CLIP_NORM             5.0\n",
            "IMAGES_PER_GPU                 1\n",
            "IMAGE_CHANNEL_COUNT            3\n",
            "IMAGE_MAX_DIM                  640\n",
            "IMAGE_META_SIZE                30\n",
            "IMAGE_MIN_DIM                  640\n",
            "IMAGE_MIN_SCALE                0\n",
            "IMAGE_RESIZE_MODE              square\n",
            "IMAGE_SHAPE                    [640 640   3]\n",
            "LEARNING_MOMENTUM              0.9\n",
            "LEARNING_RATE                  0.001\n",
            "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
            "MASK_POOL_SIZE                 14\n",
            "MASK_SHAPE                     [28, 28]\n",
            "MAX_GT_INSTANCES               100\n",
            "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
            "MINI_MASK_SHAPE                (56, 56)\n",
            "NAME                           mapvistas\n",
            "NUM_CLASSES                    18\n",
            "POOL_SIZE                      7\n",
            "POST_NMS_ROIS_INFERENCE        1000\n",
            "POST_NMS_ROIS_TRAINING         2000\n",
            "PRE_NMS_LIMIT                  6000\n",
            "ROI_POSITIVE_RATIO             0.33\n",
            "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
            "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
            "RPN_ANCHOR_STRIDE              1\n",
            "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
            "RPN_NMS_THRESHOLD              0.7\n",
            "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
            "STEPS_PER_EPOCH                1000\n",
            "TOP_DOWN_PYRAMID_SIZE          256\n",
            "TRAIN_BN                       False\n",
            "TRAIN_ROIS_PER_IMAGE           200\n",
            "USE_MINI_MASK                  True\n",
            "USE_RPN_ROIS                   True\n",
            "VALIDATION_STEPS               50\n",
            "WEIGHT_DECAY                   0.0001\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHcm09WTUa4a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TRAIN_DIR = '/content/mapillary_vistas'\n",
        "# # Training dataset\n",
        "# dataset_train = mapillary.MapillaryDataset()\n",
        "# dataset_train.load_vistas(dataset_dir=TRAIN_DIR, subset='training', class_ids=selected_classes)\n",
        "# dataset_train.prepare()\n",
        "\n",
        "# Validation dataset\n",
        "VAL_DIR = '/content/drive/My Drive/mapillary_vistas/mapillary_vistas'\n",
        "\n",
        "dataset_val = mapillary_felix.MapillaryDataset()\n",
        "dataset_val.load_vistas(dataset_dir=VAL_DIR, subset='validation', config=config, class_ids=selected_classes)\n",
        "dataset_val.prepare()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P81V1BRHUYu1",
        "colab_type": "code",
        "outputId": "1de894f4-5a15-4c11-b7e7-6be7629fe95c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "# Create model in training mode\n",
        "model = modellib.MaskRCNN(mode=\"inference\", config=config,\n",
        "                          model_dir=MODEL_DIR)\n",
        "model_path = '/content/mapillary_prelim.h5'\n",
        "model.load_weights(model_path, by_name=True)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/semantic_features_detection/mrcnn/model_felix.py:341: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/semantic_features_detection/mrcnn/model_felix.py:399: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/semantic_features_detection/mrcnn/model_felix.py:423: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "WARNING:tensorflow:From /content/semantic_features_detection/mrcnn/model_felix.py:758: The name tf.sets.set_intersection is deprecated. Please use tf.sets.intersection instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/semantic_features_detection/mrcnn/model_felix.py:760: The name tf.sparse_tensor_to_dense is deprecated. Please use tf.sparse.to_dense instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/semantic_features_detection/mrcnn/model_felix.py:772: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0RZ4wxeQbBu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "db2703b0-47ce-41e3-fa25-94d073b2209c"
      },
      "source": [
        "image_ids = np.random.choice(dataset_val.image_ids,2000)\n",
        "class_PMF = np.zeros((len(selected_classes), (len(selected_classes) + 1)))\n",
        "for image_id in image_ids:\n",
        "    image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "          modellib.load_image_gt(dataset_val, config,\n",
        "                                image_id, use_mini_mask=False)\n",
        "    results = model.detect([image], verbose=0)\n",
        "    r = results[0]\n",
        "    #visualize.display_instances(image, boxes=r['rois'], masks=r['masks'], class_ids=r['class_ids'], class_names=dataset_val.class_names[1:], scores=r['scores'])\n",
        "    gt_match, pred_match, overlaps = utils.compute_matches(gt_boxes=gt_bbox, gt_class_ids=gt_class_id, gt_masks=gt_mask, pred_boxes=r['rois'], \n",
        "                          pred_class_ids=r['class_ids'], pred_scores=r['scores'], pred_masks=r['masks'], iou_threshold=0.5)\n",
        "    \n",
        "    gt_match = list(map(int, gt_match))\n",
        "    for i, matched_pred in enumerate(gt_match):\n",
        "        if matched_pred == -1:\n",
        "            class_PMF[gt_class_id[i]-1, 0] += 1 \n",
        "        else:\n",
        "            class_PMF[gt_class_id[i]-1, r['class_ids'][matched_pred]] += 1 \n",
        "for i, class_Pr in enumerate(class_PMF):\n",
        "    summed = class_Pr.sum()\n",
        "    if summed > 0:\n",
        "        class_PMF[i,:] = class_PMF[i,:]/summed\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:You are using the default load_mask(), maybe you need to define your own one.\n",
            "WARNING:root:You are using the default load_mask(), maybe you need to define your own one.\n",
            "WARNING:root:You are using the default load_mask(), maybe you need to define your own one.\n",
            "WARNING:root:You are using the default load_mask(), maybe you need to define your own one.\n",
            "WARNING:root:You are using the default load_mask(), maybe you need to define your own one.\n",
            "WARNING:root:You are using the default load_mask(), maybe you need to define your own one.\n",
            "WARNING:root:You are using the default load_mask(), maybe you need to define your own one.\n",
            "WARNING:root:You are using the default load_mask(), maybe you need to define your own one.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hboqg2TzpNSD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "b9afd8c8-a32c-41bf-bb4a-5308e0a1f74c"
      },
      "source": [
        "PMF_dict = {}\n",
        "for i, class_Pr in enumerate(class_PMF):\n",
        "    PMF_dict[dataset_val.class_names[i]] = list(class_Pr)\n",
        "print(PMF_dict)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'BG': [0.6407068062827225, 0.35929319371727747, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'Bench': [0.8020833333333334, 0.0, 0.19791666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'Billboard': [0.9090909090909091, 0.0, 0.0, 0.09090909090909091, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'Catch Basin': [0.391304347826087, 0.0, 0.0, 0.0, 0.6086956521739131, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'CCTV Camera': [0.7893333333333333, 0.0, 0.0, 0.0, 0.0, 0.21066666666666667, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'Fire Hydrant': [0.9642857142857143, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03571428571428571, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'Junction Box': [0.574468085106383, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.425531914893617, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'Mailbox': [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'Manhole': [0.4048309178743961, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5951690821256038, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'Phone Booth': [0.6534321101979396, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34656788980206044, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'Street Light': [0.9875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'Pole': [0.6762749445676275, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3237250554323725, 0.0, 0.0, 0.0, 0.0, 0.0], 'Traffic Sign Frame': [0.3477582846003899, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6522417153996102, 0.0, 0.0, 0.0, 0.0], 'Utility Pole': [0.6746543778801843, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.32534562211981566, 0.0, 0.0, 0.0], 'Traffic Light': [0.4007344503098462, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5992655496901538, 0.0, 0.0], 'Traffic Sign (Back)': [0.7361477572559367, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2638522427440633, 0.0], 'Traffic Sign (Front)': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F93H_fRrpzpK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "with open('/content/PMFs.json', 'w') as outfile:\n",
        "    json.dump(PMF_dict, outfile)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rz7MKxWOm9JY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def compute_batch_ap(image_ids):\n",
        "#     APs = []\n",
        "#     for image_id in image_ids:\n",
        "#         # Load image\n",
        "#         image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "#             modellib.load_image_gt(dataset_val, config,\n",
        "#                                    image_id, use_mini_mask=False)\n",
        "#         # Run object detection\n",
        "#         results = model.detect([image], verbose=0)\n",
        "#         # Compute AP\n",
        "#         r = results[0]\n",
        "#         AP, precisions, recalls, overlaps =\\\n",
        "#             utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
        "#                               r['rois'], r['class_ids'], r['scores'], r['masks'])\n",
        "#         APs.append(AP)\n",
        "#     return APs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQ1Rt7ClnBa8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# image_ids = np.random.choice(dataset_val.image_ids, 300)\n",
        "# APs = compute_batch_ap(image_ids)\n",
        "# print(\"mAP @ IoU=50: \", np.mean(APs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iVmvf40nDek",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_batch_ap_classwise(image_ids):\n",
        "    mAPs = np.zeros([len(selected_classes)])\n",
        "    numAPs = np.zeros([len(selected_classes)])\n",
        "    for image_id in image_ids:\n",
        "        # Load image\n",
        "        image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "            modellib.load_image_gt(dataset_val, config,\n",
        "                                  image_id, use_mini_mask=False)\n",
        "        # Run object detection\n",
        "        results = model.detect([image], verbose=0)\n",
        "        # Compute AP\n",
        "        r = results[0]\n",
        "        # visualize.display_instances(image, boxes=r['rois'], masks=r['masks'], class_ids=r['class_ids'], class_names=dataset_val.class_names[1:], scores=r['scores'])\n",
        "        # visualize.display_instances(image, boxes=gt_bbox, masks=gt_mask, class_ids=gt_class_id, class_names=dataset_val.class_names[1:])\n",
        "\n",
        "        for i, class_id in enumerate(range(17)):\n",
        "            # Select one class\n",
        "            mask = np.where(gt_class_id == class_id, True, False)\n",
        "            gt_class_id_sel = gt_class_id[mask]\n",
        "\n",
        "            gt_bbox_sel = gt_bbox[mask,:]\n",
        "            gt_mask_sel = gt_mask[:,:,mask]\n",
        "                            \n",
        "            # Select one class\n",
        "            mask = np.where(r['class_ids'] == class_id, True, False)\n",
        "            r_rois_sel = r['rois'][mask,:]\n",
        "            r_class_ids_sel = r['class_ids'][mask]\n",
        "            r_scores_sel = r['scores'][mask]\n",
        "            r_masks_sel = r['masks'][:,:,mask] \n",
        "            if len(gt_class_id_sel) != 0:\n",
        "                AP, precisions, recalls, overlaps =\\\n",
        "                    utils.compute_ap(gt_bbox_sel, gt_class_id_sel, gt_mask_sel,\n",
        "                                      r_rois_sel, r_class_ids_sel, r_scores_sel, r_masks_sel)\n",
        "                print(\"precisions: {}\".format(precisions))\n",
        "                mAPs[i] = mAPs[i] + AP\n",
        "                # print(\"mAPs: {}\".format(mAPs))\n",
        "                numAPs[i] += 1\n",
        "                # print(\"numAPs: {}\".format(numAPs))\n",
        "\n",
        "    # print(\"mAPs: {}\".format(mAPs))\n",
        "    # print(\"numAPs: {}\".format(numAPs))\n",
        "    mAPs = mAPs / numAPs\n",
        "    return mAPs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzxXBPn-liLM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_ids = np.random.choice(dataset_val.image_ids,2)\n",
        "# image_ids = [50]\n",
        "APs = compute_batch_ap_classwise(image_ids)\n",
        "print(\"mAP @ IoU=50: \", APs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-Y2WsirPlAN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mAP_opt = 0\n",
        "thresh_opt = 0\n",
        "class_id = 9\n",
        "image_ids = np.random.choice(dataset_val.image_ids,500)\n",
        "\n",
        "for thresh in range(20):\n",
        "    thresh = thresh/20\n",
        "    mAP = compute_batch_ap_classwise_thresh(image_ids, class_id, thresh)\n",
        "    print(mAP)\n",
        "    print(thresh)\n",
        "    if mAP > mAP_opt:\n",
        "        mAP_opt = mAP\n",
        "        thresh_opt = thresh"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9muJiFvwYxKS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(mAP_opt)\n",
        "print(thresh_opt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yloSiIQpCYcQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SAVE_DIR = '/content/Results'\n",
        "image_ids = np.random.choice(dataset_val.image_ids,4)\n",
        "for image_id in image_ids:\n",
        "    image = dataset_val.load_image(image_id)\n",
        "    results = model.detect([image], verbose=0)\n",
        "    r = results[0]\n",
        "    visualize.save_image(image = image[:,:,::-1], image_name=image_id, boxes=r['rois'], masks=r['masks'], class_ids=r['class_ids'], class_names=class_names, scores=r['scores'], save_dir=SAVE_DIR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGnyg_JypZGo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_names = ['Bench', 'Billboard', 'Catch Basin', 'CCTV Camera', 'Fire Hydrant', 'Junction Box', 'Mailbox',\n",
        "               'Manhole', 'Phone Booth', 'Street Light', 'Pole', 'Traffic Sign Frame', 'Utility Pole',\n",
        "               'Traffic Light', 'Traffic Sign (Back)', 'Traffic Sign (Front)', 'Trash Can']\n",
        "print(dataset_val.class_names[1:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHgMrQYDBpVd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(APs)):\n",
        "    print(\"class name: {}: mAP: {}\".format(class_names[i], APs[i]))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itQiOK_GOR0U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_batch_ap_classwise_thresh(image_ids, class_id, thresh):\n",
        "    mPs = 0\n",
        "    numPs = 0\n",
        "    for image_id in image_ids:\n",
        "        # Load image\n",
        "        image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "            modellib.load_image_gt(dataset_val, config,\n",
        "                                  image_id, use_mini_mask=False)\n",
        "        # Run object detection\n",
        "        results = model.detect([image], verbose=0)\n",
        "        # Compute AP\n",
        "        r = results[0]\n",
        "        # visualize.display_instances(image, boxes=r['rois'], masks=r['masks'], class_ids=r['class_ids'], class_names=dataset_val.class_names[1:], scores=r['scores'])\n",
        "        # visualize.display_instances(image, boxes=gt_bbox, masks=gt_mask, class_ids=gt_class_id, class_names=dataset_val.class_names[1:])\n",
        "\n",
        "    \n",
        "        # Select one class\n",
        "        mask = np.where(gt_class_id == class_id, True, False)\n",
        "        gt_class_id_sel = gt_class_id[mask]\n",
        "\n",
        "        gt_bbox_sel = gt_bbox[mask,:]\n",
        "        gt_mask_sel = gt_mask[:,:,mask]\n",
        "                        \n",
        "        # Select class and scores higher than threshold\n",
        "        mask = np.where(np.logical_and(r['class_ids'] == class_id, r['scores'] > thresh), True, False)\n",
        "        r_rois_sel = r['rois'][mask,:]\n",
        "        r_class_ids_sel = r['class_ids'][mask]\n",
        "        r_scores_sel = r['scores'][mask]\n",
        "        r_masks_sel = r['masks'][:,:,mask] \n",
        "        if len(r_class_ids_sel) != 0:\n",
        "            AP, precisions, recalls, overlaps =\\\n",
        "                utils.compute_ap(gt_bbox_sel, gt_class_id_sel, gt_mask_sel,\n",
        "                                  r_rois_sel, r_class_ids_sel, r_scores_sel, r_masks_sel)\n",
        "            mPs = mPs + precisions[-2]\n",
        "            numPs += 1\n",
        "\n",
        "    print(\"numPs: {}\".format(numPs))\n",
        "    mPs = mPs / numPs\n",
        "    return mPs"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}