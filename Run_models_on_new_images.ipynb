{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "Run_models_on_new_images.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juliuserbach/Semantic-Features/blob/master/Run_models_on_new_images.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pcnux916AV0a",
        "colab_type": "text"
      },
      "source": [
        "# Running on new images\n",
        "This notebook will walk you step by step through the process of using a pre-trained model to detect traffic signs in an image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FNh-ksrBrEq",
        "colab_type": "text"
      },
      "source": [
        "Clone repositories:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usaAz3ZpBqSF",
        "colab_type": "code",
        "outputId": "6b1f37a3-272e-4487-a0b9-82bd75aa7329",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "!git clone https://github.com/thtrieu/darkflow.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'darkflow'...\n",
            "remote: Enumerating objects: 2713, done.\u001b[K\n",
            "remote: Total 2713 (delta 0), reused 0 (delta 0), pack-reused 2713\u001b[K\n",
            "Receiving objects: 100% (2713/2713), 32.98 MiB | 21.13 MiB/s, done.\n",
            "Resolving deltas: 100% (1762/1762), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNLrwfAqGF_E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone --quiet https://github.com/tensorflow/models.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1UBxd_xShc2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone --quiet https://github.com/aarcosg/traffic-sign-detection.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAdPakNGAV0e",
        "colab_type": "text"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6ef_zCbmE4N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "811d9050-5bdc-4d04-9ee7-01f9cd53f200"
      },
      "source": [
        "# Load cityscapes\n",
        "# Download and unzip (run only once!).\n",
        "PATH_TO_LEFT_IMAGES = \"leftImg8bit/train_extra/schweinfurt/\"\n",
        "PATH_TO_DISPARITY = \"disparity/train_extra/schweinfurt/\"\n",
        "PATH_TO_CAMERA = \"camera/train_extra/schweinfurt/\"\n",
        "PATH_TO_VEHICLE = \"vehicle/train_extra/schweinfurt/\"\n",
        "\n",
        "# Remove data directory if it is already loaded (if needed).\n",
        "#!rm -r data\n",
        "# Login.\n",
        "!wget --keep-session-cookies --save-cookies=cookies.txt --post-data 'username=ftaubner@ethz.ch&password=semantic_dudes&submit=Login' https://www.cityscapes-dataset.com/login/\n",
        "# Get left camera images. I put it on OneDrive so that only Schweinfurt has to be downloaded.\n",
        "!wget --no-check-certificate \"https://onedrive.live.com/download?cid=EA356294C6263A37&resid=EA356294C6263A37%2199734&authkey=AC5K24PFcrSPFl4\" -O leftImg8bit_trainextra.zip\n",
        "# Alternatively, it can be downloaded from CityScapes website directly:\n",
        "#   (!wget --load-cookies cookies.txt --content-disposition https://www.cityscapes-dataset.com/file-handling/?packageID=4)\n",
        "# Extract.\n",
        "!mkdir data\n",
        "!unzip -qq leftImg8bit_trainextra.zip \"$PATH_TO_LEFT_IMAGES\"* -d data\n",
        "# And delete.\n",
        "!rm leftImg8bit_trainextra.zip\n",
        "\n",
        "# Get disparity maps.\n",
        "!wget --no-check-certificate \"https://onedrive.live.com/download?cid=EA356294C6263A37&resid=EA356294C6263A37%2199735&authkey=AEwGRlH_TySnyPM\" -O disparity_trainextra.zip\n",
        "# Original file:\n",
        "#   (!wget --load-cookies cookies.txt --content-disposition https://www.cityscapes-dataset.com/file-handling/?packageID=22)\n",
        "!unzip -qq disparity_trainextra.zip \"$PATH_TO_DISPARITY\"* -d data\n",
        "!rm disparity_trainextra.zip\n",
        "# Get camera intrinsics. \n",
        "!wget --load-cookies cookies.txt --content-disposition https://www.cityscapes-dataset.com/file-handling/?packageID=9\n",
        "!unzip -qq camera_trainextra.zip \"$PATH_TO_CAMERA\"* -d data\n",
        "!rm camera_trainextra.zip\n",
        "# Get vehicle odometry.\n",
        "!wget --load-cookies cookies.txt --content-disposition https://www.cityscapes-dataset.com/file-handling/?packageID=11\n",
        "!unzip -qq vehicle_trainextra.zip \"$PATH_TO_VEHICLE\"* -d data\n",
        "!rm vehicle_trainextra.zip\n",
        "\n",
        "import os\n",
        "PATH_TO_LEFT_IMAGES = os.path.join(\"data/\", PATH_TO_LEFT_IMAGES)\n",
        "PATH_TO_DISPARITY = os.path.join(\"data/\", PATH_TO_DISPARITY)\n",
        "PATH_TO_CAMERA = os.path.join(\"data/\", PATH_TO_CAMERA)\n",
        "PATH_TO_VEHICLE = os.path.join(\"data/\", PATH_TO_VEHICLE)\n",
        "\n",
        "print(\"Finished unzipping.\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-27 15:44:46--  https://www.cityscapes-dataset.com/login/\n",
            "Resolving www.cityscapes-dataset.com (www.cityscapes-dataset.com)... 139.19.217.8\n",
            "Connecting to www.cityscapes-dataset.com (www.cityscapes-dataset.com)|139.19.217.8|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://www.cityscapes-dataset.com/downloads/ [following]\n",
            "--2020-03-27 15:44:46--  https://www.cityscapes-dataset.com/downloads/\n",
            "Reusing existing connection to www.cityscapes-dataset.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘index.html’\n",
            "\n",
            "index.html              [ <=>                ]  42.77K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-03-27 15:44:48 (369 KB/s) - ‘index.html’ saved [43792]\n",
            "\n",
            "--2020-03-27 15:44:50--  https://onedrive.live.com/download?cid=EA356294C6263A37&resid=EA356294C6263A37%2199734&authkey=AC5K24PFcrSPFl4\n",
            "Resolving onedrive.live.com (onedrive.live.com)... 13.107.42.13\n",
            "Connecting to onedrive.live.com (onedrive.live.com)|13.107.42.13|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://xyibzg.am.files.1drv.com/y4m1w3v_gwje2VL3_Tnvz5Ov7jjLhEZVwgaok3eKnhffeiov4N-Smnlu7FJKo05pCM60LWMvwR2lg8eKExy88-iX5XmR5728ESJFAKR9kV6gwfFyLKjLOtfdtaa-oaOPW-lTGbdpAb3-lgD-iGUorRXSHcKroO22TT5_9azxO-DJ0C74ajNCMMiLMd45rt29ErS1G79TnztiB4__aU3lJbt-Q/leftImg8bit_trainextra.zip?download&psid=1 [following]\n",
            "--2020-03-27 15:44:50--  https://xyibzg.am.files.1drv.com/y4m1w3v_gwje2VL3_Tnvz5Ov7jjLhEZVwgaok3eKnhffeiov4N-Smnlu7FJKo05pCM60LWMvwR2lg8eKExy88-iX5XmR5728ESJFAKR9kV6gwfFyLKjLOtfdtaa-oaOPW-lTGbdpAb3-lgD-iGUorRXSHcKroO22TT5_9azxO-DJ0C74ajNCMMiLMd45rt29ErS1G79TnztiB4__aU3lJbt-Q/leftImg8bit_trainextra.zip?download&psid=1\n",
            "Resolving xyibzg.am.files.1drv.com (xyibzg.am.files.1drv.com)... 13.107.42.12\n",
            "Connecting to xyibzg.am.files.1drv.com (xyibzg.am.files.1drv.com)|13.107.42.12|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1582171242 (1.5G) [application/zip]\n",
            "Saving to: ‘leftImg8bit_trainextra.zip’\n",
            "\n",
            "leftImg8bit_trainex 100%[===================>]   1.47G  35.2MB/s    in 63s     \n",
            "\n",
            "2020-03-27 15:45:54 (23.8 MB/s) - ‘leftImg8bit_trainextra.zip’ saved [1582171242/1582171242]\n",
            "\n",
            "--2020-03-27 15:46:13--  https://onedrive.live.com/download?cid=EA356294C6263A37&resid=EA356294C6263A37%2199735&authkey=AEwGRlH_TySnyPM\n",
            "Resolving onedrive.live.com (onedrive.live.com)... 13.107.42.13\n",
            "Connecting to onedrive.live.com (onedrive.live.com)|13.107.42.13|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://xyiczg.am.files.1drv.com/y4mvO8bnWECY-5bvSGtCM1M5VJJOthLJa_sWechxrOcnY5YlRyAEFEc_aQjjFcVyQKlsmSdJdA8vc0U2yM_PGR6N7zxvZWU6sNzta9P_LlZhfPnXLQM7C34S_UeXGYooZGb7wKJX0sRJDTSpVy-TW7oPrpEtC9UA1ytP_xNkdEy6k1UVBV-PzPHERrxJxk1_5Owrp6KqnFzjLyaEbSF-086hw/disparity_trainextra.zip?download&psid=1 [following]\n",
            "--2020-03-27 15:46:13--  https://xyiczg.am.files.1drv.com/y4mvO8bnWECY-5bvSGtCM1M5VJJOthLJa_sWechxrOcnY5YlRyAEFEc_aQjjFcVyQKlsmSdJdA8vc0U2yM_PGR6N7zxvZWU6sNzta9P_LlZhfPnXLQM7C34S_UeXGYooZGb7wKJX0sRJDTSpVy-TW7oPrpEtC9UA1ytP_xNkdEy6k1UVBV-PzPHERrxJxk1_5Owrp6KqnFzjLyaEbSF-086hw/disparity_trainextra.zip?download&psid=1\n",
            "Resolving xyiczg.am.files.1drv.com (xyiczg.am.files.1drv.com)... 13.107.42.12\n",
            "Connecting to xyiczg.am.files.1drv.com (xyiczg.am.files.1drv.com)|13.107.42.12|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 494420562 (472M) [application/zip]\n",
            "Saving to: ‘disparity_trainextra.zip’\n",
            "\n",
            "disparity_trainextr 100%[===================>] 471.52M  34.0MB/s    in 14s     \n",
            "\n",
            "2020-03-27 15:46:27 (34.5 MB/s) - ‘disparity_trainextra.zip’ saved [494420562/494420562]\n",
            "\n",
            "--2020-03-27 15:46:37--  https://www.cityscapes-dataset.com/file-handling/?packageID=9\n",
            "Resolving www.cityscapes-dataset.com (www.cityscapes-dataset.com)... 139.19.217.8\n",
            "Connecting to www.cityscapes-dataset.com (www.cityscapes-dataset.com)|139.19.217.8|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8160020 (7.8M) [application/octet-stream]\n",
            "Saving to: ‘camera_trainextra.zip’\n",
            "\n",
            "camera_trainextra.z 100%[===================>]   7.78M  45.2MB/s    in 0.2s    \n",
            "\n",
            "2020-03-27 15:46:38 (45.2 MB/s) - ‘camera_trainextra.zip’ saved [8160020/8160020]\n",
            "\n",
            "--2020-03-27 15:46:43--  https://www.cityscapes-dataset.com/file-handling/?packageID=11\n",
            "Resolving www.cityscapes-dataset.com (www.cityscapes-dataset.com)... 139.19.217.8\n",
            "Connecting to www.cityscapes-dataset.com (www.cityscapes-dataset.com)|139.19.217.8|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8007153 (7.6M) [application/octet-stream]\n",
            "Saving to: ‘vehicle_trainextra.zip’\n",
            "\n",
            "vehicle_trainextra. 100%[===================>]   7.64M  43.4MB/s    in 0.2s    \n",
            "\n",
            "2020-03-27 15:46:44 (43.4 MB/s) - ‘vehicle_trainextra.zip’ saved [8007153/8007153]\n",
            "\n",
            "Finished unzipping.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "sq2NzoyoAV0f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import numpy as np\n",
        "import os\n",
        "%tensorflow_version 1.x \n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "import glob as glob\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tP42V9ugDGOu",
        "colab_type": "code",
        "outputId": "8b6f55a5-e1ae-45b4-fed8-4b459c947ab5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 964
        }
      },
      "source": [
        "!pip install --user Cython\n",
        "!pip install --user contextlib2\n",
        "!pip install --user pillow\n",
        "!pip install --user lxml\n",
        "!pip install --user jupyter\n",
        "!pip install --user matplotlib\n",
        "!apt-get install -y -qq protobuf-compiler python-pil python-lxml"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (0.29.15)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.6/dist-packages (0.5.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (7.0.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (4.2.6)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.6/dist-packages (1.0.0)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.6/dist-packages (from jupyter) (5.2.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from jupyter) (5.6.1)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.6/dist-packages (from jupyter) (4.7.1)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.6/dist-packages (from jupyter) (5.2.2)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from jupyter) (4.6.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.6/dist-packages (from jupyter) (7.5.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from jupyter-console->jupyter) (5.5.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from jupyter-console->jupyter) (1.0.18)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from jupyter-console->jupyter) (5.3.4)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from jupyter-console->jupyter) (2.1.3)\n",
            "Requirement already satisfied: nbformat>=4.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter) (5.0.4)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter) (0.8.4)\n",
            "Requirement already satisfied: jinja2>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter) (2.11.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter) (0.3)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter) (0.4.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter) (0.6.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter) (1.4.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter) (3.1.3)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter) (4.6.3)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter) (4.3.3)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter) (0.2.0)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter) (1.9.0)\n",
            "Requirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter) (0.8.3)\n",
            "Requirement already satisfied: tornado>=4 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter) (4.5.3)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jupyter) (3.5.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-console->jupyter) (46.0.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-console->jupyter) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-console->jupyter) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-console->jupyter) (0.8.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-console->jupyter) (4.8.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.0->jupyter-console->jupyter) (0.1.9)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.0->jupyter-console->jupyter) (1.12.0)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->jupyter-console->jupyter) (17.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->jupyter-console->jupyter) (2.8.1)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.4->nbconvert->jupyter) (2.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.4->nbconvert->jupyter) (1.1.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->jupyter) (0.5.1)\n",
            "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.6/dist-packages (from terminado>=0.3.3; sys_platform != \"win32\"->notebook->jupyter) (0.6.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.2.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.18.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib) (46.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcjSnEimGNQ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/models/research/slim')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXuNZdcnDh3-",
        "colab_type": "code",
        "outputId": "11068d13-5560-4001-880d-9b2ed07eb93e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "import os\n",
        "os.chdir('models/research')\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "!pip install ."
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing /content/models/research\n",
            "Requirement already satisfied: Pillow>=1.0 in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (7.0.0)\n",
            "Requirement already satisfied: Matplotlib>=2.1 in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (3.2.1)\n",
            "Requirement already satisfied: Cython>=0.28.1 in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (0.29.15)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from Matplotlib>=2.1->object-detection==0.1) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from Matplotlib>=2.1->object-detection==0.1) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from Matplotlib>=2.1->object-detection==0.1) (2.4.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from Matplotlib>=2.1->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from Matplotlib>=2.1->object-detection==0.1) (1.18.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->Matplotlib>=2.1->object-detection==0.1) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->Matplotlib>=2.1->object-detection==0.1) (46.0.0)\n",
            "Building wheels for collected packages: object-detection\n",
            "  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-cp36-none-any.whl size=1017522 sha256=3f6e63f2c66d46b18e69e0138cf6e133506143abf7116f56e4d03a7d29690e1e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-f7r5l3jb/wheels/94/49/4b/39b051683087a22ef7e80ec52152a27249d1a644ccf4e442ea\n",
            "Successfully built object-detection\n",
            "Installing collected packages: object-detection\n",
            "  Found existing installation: object-detection 0.1\n",
            "    Uninstalling object-detection-0.1:\n",
            "      Successfully uninstalled object-detection-0.1\n",
            "Successfully installed object-detection-0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ks9_iy-KkyK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "faa23492-21ae-49ae-a6f7-5ad332fdf5e1"
      },
      "source": [
        "print(os.path.abspath(''))\n",
        "os.chdir('../../')\n",
        "print(os.path.abspath(''))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGMfyCZRAV0m",
        "colab_type": "code",
        "outputId": "211f9a05-4cfe-4da8-c6d8-46cb6de6c9b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "%matplotlib inline\n",
        "import glob\n",
        "ROOT_DIR = os.path.abspath('')\n",
        "PATH_TO_TENSORFLOW_OBJECT_DETECTION_FOLDER = os.path.join(ROOT_DIR, 'models/research/object_detection')\n",
        "PATH_TO_DARKFLOW_FOLDER = 'content/darkflow'\n",
        "# Append your Tensorflow object detection and darkflow directories to your path\n",
        "sys.path.append(PATH_TO_TENSORFLOW_OBJECT_DETECTION_FOLDER) # ~/tensorflow/models/research/object_detection\n",
        "sys.path.append(PATH_TO_DARKFLOW_FOLDER) # ~/darkflow\n",
        "from utils import label_map_util\n",
        "from utils import visualization_utils as vis_util"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['/content/models/research/object_detection/dockerfiles', '/content/models/research/object_detection/object_detection_tutorial.ipynb', '/content/models/research/object_detection/g3doc', '/content/models/research/object_detection/model_lib.py', '/content/models/research/object_detection/dataset_tools', '/content/models/research/object_detection/model_lib_v2_test.py', '/content/models/research/object_detection/exporter_test.py', '/content/models/research/object_detection/tpu_exporters', '/content/models/research/object_detection/predictors', '/content/models/research/object_detection/inputs.py', '/content/models/research/object_detection/export_inference_graph.py', '/content/models/research/object_detection/model_lib_test.py', '/content/models/research/object_detection/test_images', '/content/models/research/object_detection/utils', '/content/models/research/object_detection/inputs_test.py', '/content/models/research/object_detection/data_decoders', '/content/models/research/object_detection/inference', '/content/models/research/object_detection/eval_util_test.py', '/content/models/research/object_detection/__init__.py', '/content/models/research/object_detection/export_tflite_ssd_graph_lib_test.py', '/content/models/research/object_detection/export_tflite_ssd_graph.py', '/content/models/research/object_detection/builders', '/content/models/research/object_detection/legacy', '/content/models/research/object_detection/anchor_generators', '/content/models/research/object_detection/model_lib_v2.py', '/content/models/research/object_detection/test_data', '/content/models/research/object_detection/core', '/content/models/research/object_detection/matchers', '/content/models/research/object_detection/models', '/content/models/research/object_detection/meta_architectures', '/content/models/research/object_detection/samples', '/content/models/research/object_detection/eval_util.py', '/content/models/research/object_detection/model_main.py', '/content/models/research/object_detection/test_ckpt', '/content/models/research/object_detection/model_tpu_main.py', '/content/models/research/object_detection/export_tflite_ssd_graph_lib.py', '/content/models/research/object_detection/box_coders', '/content/models/research/object_detection/README.md', '/content/models/research/object_detection/model_hparams.py', '/content/models/research/object_detection/metrics', '/content/models/research/object_detection/CONTRIBUTING.md', '/content/models/research/object_detection/exporter.py', '/content/models/research/object_detection/data', '/content/models/research/object_detection/protos']\n",
            "/content/models/research/object_detection\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTP4ewBNAV0t",
        "colab_type": "text"
      },
      "source": [
        "# Tensorflow Object Detection API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5I0rpB2PNVx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "36abc862-31bc-406b-ff9b-5498ef06d617"
      },
      "source": [
        "# Download model\n",
        "!pip install gdown"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.6/dist-packages (3.6.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gdown) (2.21.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gdown) (1.12.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from gdown) (4.38.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (2019.11.28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oe6NqbR8QQ8U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "fd467c3c-19fe-41f2-d529-cd4052e6cc57"
      },
      "source": [
        "# Download faster_rcnn_inception_resnet_v2_atrous.zip\n",
        "!gdown 'https://drive.google.com/uc?id=12vLvA9wyJ9lRuDl9H9Tls0z5jsX0I0Da'\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=12vLvA9wyJ9lRuDl9H9Tls0z5jsX0I0Da\n",
            "To: /content/faster_rcnn_inception_resnet_v2_atrous.zip\n",
            "222MB [00:08, 24.7MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIysLztsQ0zB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "37f37f96-28d1-4eef-bafe-f883b5056b3f"
      },
      "source": [
        "!unzip /content/faster_rcnn_inception_resnet_v2_atrous.zip -d /content/faster_rcnn_inception_resnet_v2_atrous/\n",
        "!rm -r faster_rcnn_inception_resnet_v2_atrous.zip"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/faster_rcnn_inception_resnet_v2_atrous.zip\n",
            "   creating: /content/faster_rcnn_inception_resnet_v2_atrous/inference_graph/\n",
            "  inflating: /content/faster_rcnn_inception_resnet_v2_atrous/inference_graph/frozen_inference_graph.pb  \n",
            "  inflating: /content/faster_rcnn_inception_resnet_v2_atrous/faster_rcnn_inception_resnet_v2_atrous_gtsdb3.config  \n",
            "  inflating: /content/faster_rcnn_inception_resnet_v2_atrous/detections_output_result.pkl  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZC86sKrGAV0w",
        "colab_type": "text"
      },
      "source": [
        "## Model preparation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lkh6r9rIAV0x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MODEL_NAME = 'faster_rcnn_inception_resnet_v2_atrous'\n",
        "# MODEL_NAME = 'faster_rcnn_resnet_101'\n",
        "# MODEL_NAME = 'faster_rcnn_resnet50'\n",
        "# MODEL_NAME = 'faster_rcnn_inception_v2'\n",
        "# MODEL_NAME = 'rfcn_resnet101'\n",
        "# MODEL_NAME = 'ssd_inception_v2'\n",
        "# MODEL_NAME = 'ssd_mobilenet_v1'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ow-h6GTkAV03",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Path to frozen detection graph. This is the actual model that is used for the traffic sign detection.\n",
        "MODEL_PATH = os.path.join(MODEL_NAME)\n",
        "PATH_TO_CKPT = os.path.join(MODEL_PATH,'inference_graph/frozen_inference_graph.pb')\n",
        "\n",
        "# List of the strings that is used to add correct label for each box.\n",
        "PATH_TO_LABELS = os.path.join('/content/traffic-sign-detection/scripts/gtsdb3_label_map.pbtxt')\n",
        "\n",
        "NUM_CLASSES = 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVrS-7qxAV08",
        "colab_type": "text"
      },
      "source": [
        "## Load a (frozen) Tensorflow model into memory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4Orc67-AV1B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "  od_graph_def = tf.GraphDef()\n",
        "  with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
        "    serialized_graph = fid.read()\n",
        "    od_graph_def.ParseFromString(serialized_graph)\n",
        "    tf.import_graph_def(od_graph_def, name='')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKHPkUbjAV1F",
        "colab_type": "text"
      },
      "source": [
        "## Loading label map\n",
        "Label maps map indices to category names, so that when our convolution network predicts `2`, we know that this corresponds to `mandatory`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LMgFwWfAV1H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "e7f354e8-7ab7-4cef-c8f1-865b2c506268"
      },
      "source": [
        "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
        "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
        "category_index = label_map_util.create_category_index(categories)\n",
        "print(label_map)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "item {\n",
            "  name: \"prohibitory\"\n",
            "  id: 1\n",
            "}\n",
            "item {\n",
            "  name: \"mandatory\"\n",
            "  id: 2\n",
            "}\n",
            "item {\n",
            "  name: \"danger\"\n",
            "  id: 3\n",
            "}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGMbB_U1AV1P",
        "colab_type": "text"
      },
      "source": [
        "## Helper code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htoNOqqmAV1Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_image_into_numpy_array(image):\n",
        "    (im_width, im_height) = image.size\n",
        "    return np.array(image.getdata()).reshape((im_height, im_width, 3)).astype(np.uint8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NddOYguAV1Y",
        "colab_type": "text"
      },
      "source": [
        "## Detection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12rkYUciAV1a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For the sake of simplicity we will use only 2 images:\n",
        "# image1.jpg\n",
        "# image2.jpg\n",
        "# If you want to test the code with your images, just add path to the images to the TEST_IMAGE_PATHS.\n",
        "PATH_TO_TEST_IMAGES_DIR = 'data/leftImg8bit/train_extra/schweinfurt'\n",
        "TEST_IMAGE_PATHS = glob.glob(os.path.join(PATH_TO_TEST_IMAGES_DIR, '*.*'))\n",
        "# Size, in inches, of the output images.\n",
        "IMAGE_SIZE = (20, 20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUq6wwZPv7KV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with detection_graph.as_default():\n",
        "  with tf.Session(graph=detection_graph) as sess:\n",
        "    image = Image.open('test.jpg')\n",
        "    # the array based representation of the image will be used later in order to prepare the\n",
        "    # result image with boxes and labels on it.\n",
        "    image_np = load_image_into_numpy_array(image)\n",
        "    plt.imshow(image_np)\n",
        "    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
        "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "    image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
        "    # Each box represents a part of the image where a particular object was detected.\n",
        "    boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
        "    # Each score represent how level of confidence for each of the objects.\n",
        "    # Score is shown on the result image, together with the class label.\n",
        "    scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
        "    classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
        "    num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
        "    # Actual detection.\n",
        "    (boxes, scores, classes, num_detections) = sess.run(\n",
        "      [boxes, scores, classes, num_detections],\n",
        "      feed_dict={image_tensor: image_np_expanded})\n",
        "    # Visualization of the results of a detection.\n",
        "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "        image_np,\n",
        "        np.squeeze(boxes),\n",
        "        np.squeeze(classes).astype(np.int32),\n",
        "        np.squeeze(scores),\n",
        "        category_index,\n",
        "        use_normalized_coordinates=True,\n",
        "        line_thickness=6)\n",
        "    plt.figure(idx, figsize=IMAGE_SIZE)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(image_np)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "887NeAQbAV1e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "outputId": "ede390b0-cb9c-4553-8231-44d5ad1c62fc"
      },
      "source": [
        "with detection_graph.as_default():\n",
        "    with tf.Session(graph=detection_graph) as sess:\n",
        "        for idx, image_path in enumerate(TEST_IMAGE_PATHS):\n",
        "            image = Image.open(image_path)\n",
        "            # the array based representation of the image will be used later in order to prepare the\n",
        "            # result image with boxes and labels on it.\n",
        "            image_np = load_image_into_numpy_array(image)\n",
        "            plt.imshow(image_np)\n",
        "            # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
        "            image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "            image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
        "            # Each box represents a part of the image where a particular object was detected.\n",
        "            boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
        "            # Each score represent how level of confidence for each of the objects.\n",
        "            # Score is shown on the result image, together with the class label.\n",
        "            scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
        "            classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
        "            num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
        "            # Actual detection.\n",
        "            (boxes, scores, classes, num_detections) = sess.run(\n",
        "              [boxes, scores, classes, num_detections],\n",
        "              feed_dict={image_tensor: image_np_expanded})\n",
        "            # Visualization of the results of a detection.\n",
        "            vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "                image_np,\n",
        "                np.squeeze(boxes),\n",
        "                np.squeeze(classes).astype(np.int32),\n",
        "                np.squeeze(scores),\n",
        "                category_index,\n",
        "                use_normalized_coordinates=True,\n",
        "                line_thickness=6)\n",
        "            plt.figure(idx, figsize=IMAGE_SIZE)\n",
        "            plt.axis('off')\n",
        "            plt.imshow(image_np)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ERROR! Session/line number was not unique in database. History logging moved to new session 61\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-021069425c00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m             (boxes, scores, classes, num_detections) = sess.run(\n\u001b[1;32m     21\u001b[0m               \u001b[0;34m[\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_detections\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m               feed_dict={image_tensor: image_np_expanded})\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0;31m# Visualization of the results of a detection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             vis_util.visualize_boxes_and_labels_on_image_array(\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2sFYJ0fAV1j",
        "colab_type": "text"
      },
      "source": [
        "## Model preparation "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cbr8Kb18AV1q",
        "colab_type": "text"
      },
      "source": [
        "## Helper code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAli4gpMAV1r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_rectangle(bbox, ax, class_name, edgecolor, confidence=None):\n",
        "    xmin = bbox[0]\n",
        "    ymin = bbox[1]\n",
        "    xmax = bbox[2]\n",
        "    ymax = bbox[3]\n",
        "    left = xmin\n",
        "    right = xmax\n",
        "    top = ymin\n",
        "    bot = ymax\n",
        "    ax.add_patch(\n",
        "        plt.Rectangle((left, top),\n",
        "                      right-left,\n",
        "                      bot-top, fill=False,\n",
        "                      edgecolor=edgecolor, linewidth=3.5)\n",
        "        )\n",
        "    label = '{:s}'.format(class_name)\n",
        "    label_pos_y = top-10\n",
        "    if confidence:\n",
        "        label += ' {0:.2f}'.format(confidence)\n",
        "        label_pos_y = bot+20\n",
        "    ax.text(left, label_pos_y,label,\n",
        "            bbox=dict(facecolor=edgecolor, alpha=0.5),\n",
        "            fontsize=14, color='white')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fX2qkiThAV1y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_label_id(label_name):\n",
        "    for category in categories:\n",
        "        if category['name'] == label_name:\n",
        "            return category['id']"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}