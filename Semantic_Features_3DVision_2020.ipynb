{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Semantic_Features_3DVision_2020.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juliuserbach/Semantic-Features/blob/master/Semantic_Features_3DVision_2020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KERvIJ-nkskO",
        "colab_type": "text"
      },
      "source": [
        "Our mapping pipeline is of the following structure:\n",
        "\n",
        "1.   Detection of objects of certain object classes (e.g. traffic sign). Output: object bounding boxes\n",
        "2.   Triangulation of objects. Output: object position relative to pose\n",
        "3.   Creating map of objects. (And refining with filter, BA, etc.) Output: List of objects and their corresponding positions\n",
        "4.   Visualizing map.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1TSOFcEnsjx",
        "colab_type": "text"
      },
      "source": [
        "We start by loading the benchmark dataset. The Cityscapes dataset is used. \n",
        "\n",
        "Scripts for analyzing the dataset can be found here: https://github.com/mcordts/cityscapesScripts\n",
        "\n",
        "How to download the zip files directly: https://towardsdatascience.com/download-city-scapes-dataset-with-script-3061f87b20d7\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6ZU2SJr1Ifg",
        "colab_type": "text"
      },
      "source": [
        "Download CityScape files: \n",
        "\n",
        "*   leftImg8bit_trainextra.zip\n",
        "*   disparity_trainextra.zip\n",
        "*   camera_trainextra.zip\n",
        "*   vehicle_trainextra.zip\n",
        "\n",
        "The files are unzipped into data/... respectively.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QM1GyIOSzP06",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f301c455-a0a7-4980-ad15-4d64d908ad42"
      },
      "source": [
        "# Download and unzip (run only once!).\n",
        "PATH_TO_LEFT_IMAGES = \"leftImg8bit/train_extra/schweinfurt/\"\n",
        "PATH_TO_DISPARITY = \"disparity/train_extra/schweinfurt/\"\n",
        "PATH_TO_CAMERA = \"camera/train_extra/schweinfurt/\"\n",
        "PATH_TO_VEHICLE = \"vehicle/train_extra/schweinfurt/\"\n",
        "\n",
        "# Remove data directory if it is already loaded (if needed).\n",
        "#!rm -r data\n",
        "# Login.\n",
        "!wget --keep-session-cookies --save-cookies=cookies.txt --post-data 'username=ftaubner@ethz.ch&password=semantic_dudes&submit=Login' https://www.cityscapes-dataset.com/login/\n",
        "# Get left camera images. I put it on OneDrive so that only Schweinfurt has to be downloaded.\n",
        "!wget --no-check-certificate \"https://onedrive.live.com/download?cid=EA356294C6263A37&resid=EA356294C6263A37%2199734&authkey=AC5K24PFcrSPFl4\" -O leftImg8bit_trainextra.zip\n",
        "# Alternatively, it can be downloaded from CityScapes website directly:\n",
        "#   (!wget --load-cookies cookies.txt --content-disposition https://www.cityscapes-dataset.com/file-handling/?packageID=4)\n",
        "# Extract.\n",
        "!mkdir data\n",
        "!unzip -qq leftImg8bit_trainextra.zip \"$PATH_TO_LEFT_IMAGES\"* -d data\n",
        "# And delete.\n",
        "!rm leftImg8bit_trainextra.zip\n",
        "\n",
        "# Get disparity maps.\n",
        "!wget --no-check-certificate \"https://onedrive.live.com/download?cid=EA356294C6263A37&resid=EA356294C6263A37%2199735&authkey=AEwGRlH_TySnyPM\" -O disparity_trainextra.zip\n",
        "# Original file:\n",
        "#   (!wget --load-cookies cookies.txt --content-disposition https://www.cityscapes-dataset.com/file-handling/?packageID=22)\n",
        "!unzip -qq disparity_trainextra.zip \"$PATH_TO_DISPARITY\"* -d data\n",
        "!rm disparity_trainextra.zip\n",
        "# Get camera intrinsics. \n",
        "!wget --load-cookies cookies.txt --content-disposition https://www.cityscapes-dataset.com/file-handling/?packageID=9\n",
        "!unzip -qq camera_trainextra.zip \"$PATH_TO_CAMERA\"* -d data\n",
        "!rm camera_trainextra.zip\n",
        "# Get vehicle odometry.\n",
        "!wget --load-cookies cookies.txt --content-disposition https://www.cityscapes-dataset.com/file-handling/?packageID=11\n",
        "!unzip -qq vehicle_trainextra.zip \"$PATH_TO_VEHICLE\"* -d data\n",
        "!rm vehicle_trainextra.zip\n",
        "\n",
        "import os\n",
        "PATH_TO_LEFT_IMAGES = os.path.join(\"data/\", PATH_TO_LEFT_IMAGES)\n",
        "PATH_TO_DISPARITY = os.path.join(\"data/\", PATH_TO_DISPARITY)\n",
        "PATH_TO_CAMERA = os.path.join(\"data/\", PATH_TO_CAMERA)\n",
        "PATH_TO_VEHICLE = os.path.join(\"data/\", PATH_TO_VEHICLE)\n",
        "\n",
        "print(\"Finished unzipping.\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-30 13:30:38--  https://www.cityscapes-dataset.com/login/\n",
            "Resolving www.cityscapes-dataset.com (www.cityscapes-dataset.com)... 139.19.217.8\n",
            "Connecting to www.cityscapes-dataset.com (www.cityscapes-dataset.com)|139.19.217.8|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://www.cityscapes-dataset.com/downloads/ [following]\n",
            "--2020-03-30 13:30:40--  https://www.cityscapes-dataset.com/downloads/\n",
            "Reusing existing connection to www.cityscapes-dataset.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘index.html’\n",
            "\n",
            "index.html              [   <=>              ]  42.77K  80.3KB/s    in 0.5s    \n",
            "\n",
            "2020-03-30 13:30:43 (80.3 KB/s) - ‘index.html’ saved [43792]\n",
            "\n",
            "--2020-03-30 13:30:44--  https://onedrive.live.com/download?cid=EA356294C6263A37&resid=EA356294C6263A37%2199734&authkey=AC5K24PFcrSPFl4\n",
            "Resolving onedrive.live.com (onedrive.live.com)... 13.107.42.13\n",
            "Connecting to onedrive.live.com (onedrive.live.com)|13.107.42.13|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://xyibzg.am.files.1drv.com/y4mO2lnUT4TNrbEDE-4Qf60MWHjh8ySMbWKSZsli0ruYoel-9mguVbfExZDCf3znTveP5PRlFk9smyLjhZnK52JIDJiy-dP9-mmZLaF1AaRmv4bqoFNX5D2Q9KtzZLHpoEG3XJl-YtQtdJnO3M-vWJctV6x4qRpr90vu3LRJQb6dEoeg9tlKHaafHggfLK9RTgLLWIJU5-xjOTFTIF_30TtUA/leftImg8bit_trainextra.zip?download&psid=1 [following]\n",
            "--2020-03-30 13:30:45--  https://xyibzg.am.files.1drv.com/y4mO2lnUT4TNrbEDE-4Qf60MWHjh8ySMbWKSZsli0ruYoel-9mguVbfExZDCf3znTveP5PRlFk9smyLjhZnK52JIDJiy-dP9-mmZLaF1AaRmv4bqoFNX5D2Q9KtzZLHpoEG3XJl-YtQtdJnO3M-vWJctV6x4qRpr90vu3LRJQb6dEoeg9tlKHaafHggfLK9RTgLLWIJU5-xjOTFTIF_30TtUA/leftImg8bit_trainextra.zip?download&psid=1\n",
            "Resolving xyibzg.am.files.1drv.com (xyibzg.am.files.1drv.com)... 13.107.42.12\n",
            "Connecting to xyibzg.am.files.1drv.com (xyibzg.am.files.1drv.com)|13.107.42.12|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1582171242 (1.5G) [application/zip]\n",
            "Saving to: ‘leftImg8bit_trainextra.zip’\n",
            "\n",
            "leftImg8bit_trainex 100%[===================>]   1.47G  20.3MB/s    in 93s     \n",
            "\n",
            "2020-03-30 13:32:21 (16.2 MB/s) - ‘leftImg8bit_trainextra.zip’ saved [1582171242/1582171242]\n",
            "\n",
            "--2020-03-30 13:32:37--  https://onedrive.live.com/download?cid=EA356294C6263A37&resid=EA356294C6263A37%2199735&authkey=AEwGRlH_TySnyPM\n",
            "Resolving onedrive.live.com (onedrive.live.com)... 13.107.42.13\n",
            "Connecting to onedrive.live.com (onedrive.live.com)|13.107.42.13|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://xyiczg.am.files.1drv.com/y4mYkkOy1BEFt_OMETGdRdrZcC8OOu3EJHjyo62-1O_gqI2I7aqTff0DrmbdzJjHwW6Woa-x6mwiClOYVryIb2yserSMg_U-lQVoSaxvkY4GYBHY9XCxcPMDxyfwV7tbRMEHyN1Lu4thIq23hEgg88bPTpAYDiYW-IrQnU6HFQfFeOgiNtdyBt2rSho3t1kBDd8ec9bZAdp3RVStjX5_HZGMg/disparity_trainextra.zip?download&psid=1 [following]\n",
            "--2020-03-30 13:32:38--  https://xyiczg.am.files.1drv.com/y4mYkkOy1BEFt_OMETGdRdrZcC8OOu3EJHjyo62-1O_gqI2I7aqTff0DrmbdzJjHwW6Woa-x6mwiClOYVryIb2yserSMg_U-lQVoSaxvkY4GYBHY9XCxcPMDxyfwV7tbRMEHyN1Lu4thIq23hEgg88bPTpAYDiYW-IrQnU6HFQfFeOgiNtdyBt2rSho3t1kBDd8ec9bZAdp3RVStjX5_HZGMg/disparity_trainextra.zip?download&psid=1\n",
            "Resolving xyiczg.am.files.1drv.com (xyiczg.am.files.1drv.com)... 13.107.42.12\n",
            "Connecting to xyiczg.am.files.1drv.com (xyiczg.am.files.1drv.com)|13.107.42.12|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 494420562 (472M) [application/zip]\n",
            "Saving to: ‘disparity_trainextra.zip’\n",
            "\n",
            "disparity_trainextr 100%[===================>] 471.52M  19.3MB/s    in 30s     \n",
            "\n",
            "2020-03-30 13:33:09 (15.6 MB/s) - ‘disparity_trainextra.zip’ saved [494420562/494420562]\n",
            "\n",
            "--2020-03-30 13:33:19--  https://www.cityscapes-dataset.com/file-handling/?packageID=9\n",
            "Resolving www.cityscapes-dataset.com (www.cityscapes-dataset.com)... 139.19.217.8\n",
            "Connecting to www.cityscapes-dataset.com (www.cityscapes-dataset.com)|139.19.217.8|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8160020 (7.8M) [application/octet-stream]\n",
            "Saving to: ‘camera_trainextra.zip’\n",
            "\n",
            "camera_trainextra.z 100%[===================>]   7.78M  3.64MB/s    in 2.1s    \n",
            "\n",
            "2020-03-30 13:33:23 (3.64 MB/s) - ‘camera_trainextra.zip’ saved [8160020/8160020]\n",
            "\n",
            "--2020-03-30 13:33:27--  https://www.cityscapes-dataset.com/file-handling/?packageID=11\n",
            "Resolving www.cityscapes-dataset.com (www.cityscapes-dataset.com)... 139.19.217.8\n",
            "Connecting to www.cityscapes-dataset.com (www.cityscapes-dataset.com)|139.19.217.8|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8007153 (7.6M) [application/octet-stream]\n",
            "Saving to: ‘vehicle_trainextra.zip’\n",
            "\n",
            "vehicle_trainextra. 100%[===================>]   7.64M  3.57MB/s    in 2.1s    \n",
            "\n",
            "2020-03-30 13:33:31 (3.57 MB/s) - ‘vehicle_trainextra.zip’ saved [8007153/8007153]\n",
            "\n",
            "Finished unzipping.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwU_f_b7nH-O",
        "colab_type": "text"
      },
      "source": [
        "We start with the detection of objects of interest. Faster R-CNN is used for this task. (Julius)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qX732O_UCkoo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# COCO Class names\n",
        "# Index of the class in the list is its ID. For example, to get ID of\n",
        "# the teddy bear class, use: class_names.index('teddy bear')\n",
        "class_names = ['BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',\n",
        "               'bus', 'train', 'truck', 'boat', 'traffic light',\n",
        "               'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',\n",
        "               'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',\n",
        "               'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n",
        "               'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
        "               'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
        "               'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',\n",
        "               'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
        "               'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
        "               'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n",
        "               'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
        "               'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',\n",
        "               'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n",
        "               'teddy bear', 'hair drier', 'toothbrush']\n",
        "static_classes = []              "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXh-WMRDzqFe",
        "colab_type": "text"
      },
      "source": [
        "Loading an on COCO pre-trained Faster R-CNN \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gO8ZQm5lzz5s",
        "colab_type": "text"
      },
      "source": [
        "Installing Seamless Scene Segmentation from https://github.com/mapillary/seamseg\n",
        "For Seamless Scene Segmentation a pre-trained version on the Mapillary Dataset exists. Dataloaders for Cityscapes seem to exist, too.\n",
        "\n",
        "It is a network for panoptic segmentation basen on Mask-R-CNN. Alternatively the panoptic variant in the detectron2 reopisitory can also be trained on Cityscapes or Mapillary. Dataloaders seem to exist for both Datasets. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLq9ofO5zzmS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "daca559a-f995-4126-c732-d63bde1d187c"
      },
      "source": [
        "#@title\n",
        "!pip install git+https://github.com/mapillary/seamseg.git\n",
        "#!pip install wget\n",
        "\n",
        "url = 'https://drive.google.com/file/d/1ULhd_CZ24L8FnI9lZ2H6Xuf03n6NA_-Y/view'\n",
        "!wget $url\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/mapillary/seamseg.git\n",
            "  Cloning https://github.com/mapillary/seamseg.git to /tmp/pip-req-build-09g5r_01\n",
            "  Running command git clone -q https://github.com/mapillary/seamseg.git /tmp/pip-req-build-09g5r_01\n",
            "Building wheels for collected packages: seamseg\n",
            "  Building wheel for seamseg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seamseg: filename=seamseg-0.1.dev31+g18e28cc-cp36-cp36m-linux_x86_64.whl size=7065384 sha256=1a57aa396eef1f4fc44010b594f17d44ac0cabb246e145b926a525f7678c2536\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-tg252n9j/wheels/34/ae/9b/f7108b6552df4829b6952190c9af1ec04fc171251cdc5d9ea9\n",
            "Successfully built seamseg\n",
            "Installing collected packages: seamseg\n",
            "Successfully installed seamseg-0.1.dev31+g18e28cc\n",
            "--2020-03-30 13:36:22--  https://drive.google.com/file/d/1ULhd_CZ24L8FnI9lZ2H6Xuf03n6NA_-Y/view\n",
            "Resolving drive.google.com (drive.google.com)... 74.125.203.139, 74.125.203.113, 74.125.203.101, ...\n",
            "Connecting to drive.google.com (drive.google.com)|74.125.203.139|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘view’\n",
            "\n",
            "view                    [ <=>                ]  67.26K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2020-03-30 13:36:22 (1.59 MB/s) - ‘view’ saved [68874]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bjqhrjt8BTs",
        "colab_type": "text"
      },
      "source": [
        "These functions convert a difference in coordinates (lat., long.) to a difference in metric frame (x, y) and vice versa. Both conversions are dependent on the current latitude.\n",
        "Under the assumption that we are in Europe, east of 0°!\n",
        "\n",
        "Approximative conversions:\n",
        "\n",
        "* Latitude: 1 deg = 110.574 km\n",
        "* Longitude: 1 deg = 111.320*cos(latitude) km\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2l9jM1A7_9S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Felix \n",
        "# Helper functions for transformations.\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Calculates the difference between two coordinates in meters (x to east, y to north).\n",
        "# See below for example.\n",
        "def coord_diff_to_metric_diff(d_lat, d_long, lat):\n",
        "  d_y = d_lat * 110574\n",
        "  d_x = d_long * 111320 * np.cos(np.radians(lat))\n",
        "  return d_x, d_y\n",
        "\n",
        "\n",
        "# Converts the metric difference to differences in latitude and longitude.\n",
        "# See below for example.\n",
        "def metric_diff_to_coord_diff(d_x, d_y, lat):\n",
        "  d_lat = d_y / 110574\n",
        "  d_long = d_x / 111320 / np.cos(np.radians(lat))\n",
        "  return d_lat, d_long\n",
        "\n",
        "\n",
        "# Returns the transformation matrix: world frame (-> vehicle frame) -> camera frame\n",
        "# Usage: [x_world; 1] = camera_frame_to_world_transform(args).dot([x_camera_frame; 1])\n",
        "# All angles in radians, distances in meters!\n",
        "# See below for example.\n",
        "def camera_frame_to_world_transform(heading, yaw_ext, pitch_ext, roll_ext, x_ext, y_ext, z_ext):\n",
        "    # Coordinate axis switch for camera.\n",
        "    C_c = np.array([[0., -1.,  0., 0.],\n",
        "                    [0.,  0., -1., 0.],\n",
        "                    [1.,  0.,  0., 0.],\n",
        "                    [0.,  0.,  0., 1.]])\n",
        "    # Vehicle to camera transformation matrix.\n",
        "    c_y = np.cos(yaw_ext)\n",
        "    c_p = np.cos(pitch_ext)\n",
        "    c_r = np.cos(roll_ext)\n",
        "    s_y = np.sin(yaw_ext)\n",
        "    s_p = np.sin(pitch_ext)\n",
        "    s_r = np.sin(roll_ext)\n",
        "    T_v_c = np.array([[c_y*c_p, c_y*s_p*s_r-s_y*c_r, c_y*s_p*c_r+s_y*s_r, x_ext],\n",
        "                      [s_y*c_p, s_y*s_p*s_r+c_y*c_r, s_y*s_p*c_r-c_y*s_r, y_ext],\n",
        "                      [   -s_p,             c_p*s_r,             c_p*c_r, z_ext],\n",
        "                      [     0.,                  0.,                  0.,    1.]])\n",
        "\n",
        "    # World to vehicle transformation matrix.\n",
        "    c_h = np.cos(heading)\n",
        "    s_h = np.sin(heading)\n",
        "    T_w_v = np.array([[c_h, -s_h, 0., 0.],\n",
        "                      [s_h,  c_h, 0., 0.],\n",
        "                      [ 0.,   0., 1., 0.],\n",
        "                      [ 0.,   0., 0., 1.]])\n",
        "\n",
        "    # Return camera space to vehicle transform.\n",
        "    return T_w_v.dot(T_v_c.dot(np.linalg.inv(C_c)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKWwzyVW_ZHa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Testing and example (taken from Johannes' map pic on WhatsApp):\n",
        "# Converting coords into metrics:\n",
        "d_x, d_y = coord_diff_to_metric_diff(48.370-48.369, 10.896-10.894, 48.368)\n",
        "print(\"Delta x in meters: {}\".format(d_x))\n",
        "print(\"Delta y in meters: {}\".format(d_y))\n",
        "\n",
        "# Converting back to coords: should be the same:\n",
        "d_lat, d_long = metric_diff_to_coord_diff(d_x, d_y, 48.368)\n",
        "print(\"Difference in latitude: {}\".format(d_lat))\n",
        "print(\"Difference in longitude: {}\".format(d_long))\n",
        "\n",
        "# Convert a camera frame coordinate to world coordinate:\n",
        "x_example = np.array([[8.1], [0.7], [0.7]])\n",
        "x_world_example = camera_frame_to_world_transform(0.25, 0.0057, 0.055, 0.0, 1.7, -0.1, 1.3).dot(np.vstack((x_example, 1.0)))\n",
        "print(\"Camera coordinate: \")\n",
        "print(x_example)\n",
        "print(\"World coordinate: \")\n",
        "print(x_world_example)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cstG2BrsLQBZ",
        "colab_type": "text"
      },
      "source": [
        "Plotting ground truth trajectory of vehicle. (Map image muss im Moment immer noch manuell gedownloaded und hinzugefügt werden)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crfISE18wU_V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mapping Algorithm Helper Functions\n",
        "\n",
        "import math\n",
        "\n",
        "# Convert degree to radian\n",
        "def degree_to_rad_converter(degree_value):\n",
        "  rad_value = degree_value * math.pi / 180\n",
        "  return rad_value\n",
        "\n",
        "# Calculate real 3D position\n",
        "def pixel_to_3Dposition_converter(x, depth, focal):\n",
        "  x_3D = x * depth / focal\n",
        "  return x_3D\n",
        "\n",
        "# Calculate box center to get average disparity\n",
        "def boundaries_to_box_center(x_1, x_2):\n",
        "  x_center = (x_1 + x_2)/2\n",
        "  return x_center\n",
        "\n",
        "# Get camera focal length and baseline (To be corrected, pixels are NOT quadratic here fx =/= fy)\n",
        "def camera_parameters(fx, fy):\n",
        "  # Take average, which is Bullshit, but not better idea yet\n",
        "  focal = (fx + fy)/2\n",
        "  # Get baseline value from calibration data\n",
        "  baseline = 0.222384\n",
        "  return focal, baseline\n",
        "\n",
        "# Get disparities of all points (pixels)\n",
        "def disparity_catcher(x, y, image_number):\n",
        "  # DATA_DIR=\"data/disparity/train_extra/schweinfurt\"\n",
        "  # im_directory = list(glob.iglob(os.path.join(DATA_DIR, '*.*')))\n",
        "  # n_im = len(im_directory)\n",
        "\n",
        "  disparity_data_path = 'data/disparity/train_extra/schweinfurt/schweinfurt_000000_000'+ str(image_number) + '_disparity.png'\n",
        "\n",
        "  # Load image from path\n",
        "  img = cv2.imread(disparity_data_path, cv2.IMREAD_UNCHANGED)\n",
        "  disp = img[y, x]\n",
        "  if disp != 0:\n",
        "    disp = (disp - 1.) / 256.\n",
        "\n",
        "    # print(disp)\n",
        "  return disp\n",
        "\n",
        "# Convert disparity to actual depth information\n",
        "def disparity_to_depth(disparity_box_center):\n",
        "  if disparity_box_center > 0:\n",
        "    depth_center = baseline * focal / disparity_box_center\n",
        "  else:\n",
        "    depth_center = 100\n",
        "  return depth_center\n",
        "\n",
        "# Transformation to world frame coordinates\n",
        "# _3dImage\t=\tcv.reprojectImageTo3D('data/disparity/train_extra/schweinfurt/schweinfurt_000000_000000_disparity.png', Q)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lc45wu8FLRmP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Johannes Plotting\n",
        "# Loading ground truth data from json file and saving it as pandas array\n",
        "\n",
        "import pandas as pd \n",
        "import os\n",
        "import json\n",
        "import glob\n",
        "from pandas.io.json import json_normalize\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "DATA_DIR=\"data/vehicle/train_extra/schweinfurt\"\n",
        "images_path = list(glob.iglob(os.path.join(DATA_DIR, '*.*')))\n",
        "n_images = len(images_path)\n",
        "i = 0\n",
        "# create space for long at lat\n",
        "gpsLatitude = np.zeros(n_images)\n",
        "gpsLongitude = np.zeros(n_images)\n",
        "\n",
        "for image_path in images_path:\n",
        "  # Load json from path\n",
        "  with open(image_path) as json_file:\n",
        "    data = json.load(json_file)\n",
        "    gpsLatitude[i] = data['gpsLatitude']\n",
        "    gpsLongitude[i] = data['gpsLongitude']\n",
        "    i += 1\n",
        "df = pd.DataFrame({'longitude': gpsLongitude,\n",
        "'latitude': gpsLatitude})\n",
        "BBox = ((df.longitude.min(),   df.longitude.max(),      \n",
        "         df.latitude.min(), df.latitude.max()))\n",
        "\n",
        "longdif = df.longitude.max() - df.longitude.min()\n",
        "latgdif = df.latitude.max() - df.latitude.min()\n",
        "aspectr = longdif/latgdif\n",
        "\n",
        "image = plt.imread('/content/map (4).png')\n",
        "\n",
        "fig, ax = plt.subplots(figsize = (8,7))\n",
        "ax.scatter(df.longitude, df.latitude)\n",
        "ax.set_title('Plotting Trajectiory')\n",
        "ax.set_xlim(BBox[0],BBox[1])\n",
        "ax.set_ylim(BBox[2],BBox[3])\n",
        "ax.imshow(image, zorder=0, extent = BBox)\n",
        "ax.set_aspect(aspect= aspectr)\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaGRTzSON66G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get GPS Data from json files\n",
        "\n",
        "DATA_DIR=\"data/vehicle/train_extra/schweinfurt\"\n",
        "vehicle_datas_path = list(glob.iglob(os.path.join(DATA_DIR, '*.*')))\n",
        "n_images = len(vehicle_datas_path)\n",
        "vehicle_data_path_list = []\n",
        "\n",
        "r = 0\n",
        "i = 0\n",
        "\n",
        "for r in range(n_images):\n",
        "    vehicle_data_path_list.append('data/vehicle/train_extra/schweinfurt/schweinfurt_000000_000'+ str(f\"{r:0>3}\") + '_vehicle.json')\n",
        "\n",
        "# create space for long at lat\n",
        "gpsLatitude_actual = np.zeros(n_images)\n",
        "gpsLongitude_actual = np.zeros(n_images)\n",
        "gpsHeading_actual = np.zeros(n_images)\n",
        "gpsLatitude_delta = np.zeros(n_images)\n",
        "gpsLongitude_delta = np.zeros(n_images)\n",
        "gpsHeading_delta = np.zeros(n_images)\n",
        "gpsHeading_actual_rad = np.zeros(n_images)\n",
        "\n",
        "\n",
        "for vehicle_data in vehicle_data_path_list:\n",
        "  # Load json from path\n",
        "  with open(vehicle_data) as json_file:\n",
        "    data = json.load(json_file)\n",
        "    gpsLatitude_actual[i] = data['gpsLatitude']\n",
        "    gpsLongitude_actual[i] = data['gpsLongitude']\n",
        "    gpsHeading_actual[i] = data['gpsHeading']\n",
        "    gpsHeading_actual_rad[i] = degree_to_rad_converter(gpsHeading_actual[i])\n",
        "    if i > 0:\n",
        "      gpsLatitude_delta[i] = gpsLatitude_actual[i] - gpsLatitude_actual[i-1]\n",
        "      gpsLongitude_delta[i] = gpsLongitude_actual[i] - gpsLongitude_actual[i-1]\n",
        "      gpsHeading_delta[i] = gpsHeading_actual[i] - gpsHeading_actual[i-1]\n",
        "  i+=1\n",
        "\n",
        "# Actual coordinates in x, y starting at 0, 0\n",
        "\n",
        "gps_step_delta_X = np.zeros(n_images)\n",
        "gps_total_delta_X = np.zeros(n_images)\n",
        "gps_step_delta_Y = np.zeros(n_images)\n",
        "gps_total_delta_Y = np.zeros(n_images)\n",
        "gps_total_delta_Heading = np.zeros(n_images)\n",
        "\n",
        "i = 0\n",
        "\n",
        "for image_path in images_path:\n",
        "  if i > 0:\n",
        "    gps_step_delta_X[i], gps_step_delta_Y[i] = coord_diff_to_metric_diff(gpsLatitude_delta[i], gpsLongitude_delta[i], gpsLatitude_actual[i])\n",
        "    gps_total_delta_X[i] = gps_total_delta_X[i-1] + gps_step_delta_X[i]\n",
        "    gps_total_delta_Y[i] = gps_total_delta_Y[i-1] + gps_step_delta_Y[i]\n",
        "    gps_total_delta_Heading[i] = gps_total_delta_Heading[i-1] + gpsHeading_delta[i]\n",
        "  i+=1\n",
        "\n",
        "i = 0\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jjtUpajvkQw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get Camera Calibration Data\n",
        "\n",
        "DATA_DIR=\"data/camera/train_extra/schweinfurt\"\n",
        "cam_datas_path = list(glob.iglob(os.path.join(DATA_DIR, '*.*')))\n",
        "n_images = len(cam_datas_path)\n",
        "cam_data_path_list = []\n",
        "\n",
        "r = 0\n",
        "i = 0\n",
        "\n",
        "for i in range(n_images):\n",
        "    cam_data_path_list.append('data/camera/train_extra/schweinfurt/schweinfurt_000000_000'+ str(f\"{i:0>3}\") + '_camera.json')\n",
        "\n",
        "# create space for long at lat\n",
        "roll  = np.zeros(n_images)\n",
        "pitch = np.zeros(n_images)\n",
        "yaw = np.zeros(n_images)\n",
        "baseline = np.zeros(n_images)\n",
        "offset_x = np.zeros(n_images)\n",
        "offset_y = np.zeros(n_images)\n",
        "offset_z = np.zeros(n_images)\n",
        "f_x = np.zeros(n_images)\n",
        "f_y = np.zeros(n_images)\n",
        "u_0 = np.zeros(n_images)\n",
        "v_0 = np.zeros(n_images)\n",
        "\n",
        "for cam_data_path in cam_data_path_list:\n",
        "  # Load json from path\n",
        "  with open(cam_data_path) as json_file:\n",
        "    data = json.load(json_file)\n",
        "    roll[r] = data['extrinsic']['roll']\n",
        "    pitch[r] = data['extrinsic']['pitch']\n",
        "    yaw[r] = data['extrinsic']['yaw']\n",
        "    baseline[r] = data['extrinsic']['baseline']\n",
        "    offset_x[r] = data['extrinsic']['x']\n",
        "    offset_y[r] = data['extrinsic']['y']\n",
        "    offset_z[r] = data['extrinsic']['z']\n",
        "    f_x[r] = data['intrinsic']['fx']\n",
        "    f_y[r] = data['intrinsic']['fy']\n",
        "    u_0[r] = data['intrinsic']['u0']\n",
        "    v_0[r] = data['intrinsic']['v0']\n",
        "  r+=1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNyZ8vo49N-y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Valid Object Counter -> Counts the number of objects with valid disparity measurements\n",
        "\n",
        "import math\n",
        "import csv\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import glob\n",
        "\n",
        "# Get focal length from calibration data\n",
        "fx = 2273.82\n",
        "fy = 2236.9989965173254\n",
        "# baseline = 0.222384\n",
        "\n",
        "focal, baseline = camera_parameters(fx, fy)\n",
        "\n",
        "DATA_DIR=\"data/camera/train_extra/schweinfurt\"\n",
        "images_path = list(glob.iglob(os.path.join(DATA_DIR, '*.*')))\n",
        "n_images = len(images_path)\n",
        "\n",
        "y = 0 # Current image number\n",
        "b = 0 # Valid object counter\n",
        "count = 0\n",
        "\n",
        "results_directory = 'data/Numerical_Results/results.json'\n",
        "\n",
        "# Load json from path\n",
        "with open(results_directory) as json_file:\n",
        "  data = json.load(json_file)\n",
        "  for i in range(n_images):\n",
        "    n_objects = int(len(data['results'][y]['classes']))\n",
        "    #print(n_objects)\n",
        "    #print(data['results'][k]['boxes'][0][1])\n",
        "    for o in range(n_objects):\n",
        "\n",
        "      # Get image number\n",
        "      image_no = data['results'][y]['image_id'][22:25]\n",
        "      im_no = int(image_no)\n",
        "\n",
        "      # Get coordinates in image frame\n",
        "      u1 = data['results'][y]['boxes'][o][0]\n",
        "      v1 = data['results'][y]['boxes'][o][1]\n",
        "      u2 = data['results'][y]['boxes'][o][2]\n",
        "      v2 = data['results'][y]['boxes'][o][3]\n",
        "\n",
        "      # Calculate center point in image frame\n",
        "      u_cent = int(boundaries_to_box_center(u1, u2))\n",
        "      v_cent = int(boundaries_to_box_center(v1, v2))\n",
        "\n",
        "      # Get and write all disparities 1/10th of box-length around center point in matrix\n",
        "      disp_matrix = np.zeros(shape=(int(abs((u_cent-u1)/5)),int(abs((v_cent-v1)/5))))\n",
        "        \n",
        "      for y_coord in range(int(abs((v_cent-v1)/5))):\n",
        "        for x_coord in range(int(abs((u_cent-u1)/5))):\n",
        "          disp_matrix[x_coord][y_coord] = disparity_catcher(x_coord + int(u_cent) - int(abs(u_cent - u1)/10), y_coord + int(v_cent) - int(abs(v_cent - v1)/10), image_no)\n",
        "        \n",
        "      # Take median of disparity values\n",
        "      med_disp_val = np.median(disp_matrix, axis=None, out=None, overwrite_input=False, keepdims=False)\n",
        "        \n",
        "      if med_disp_val != 0:\n",
        "        count = count + 1\n",
        "        b += 1\n",
        "    y += 1\n",
        "\n",
        "    # if k == N loop incl. break to be removed, only for debugging purposes\n",
        "    if y == 715:\n",
        "      break\n",
        "\n",
        "print(\"Total number of static objects counted\", count)\n",
        "\n",
        "num_objects = count\n",
        "\n",
        "k = 0\n",
        "t = 0\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chKg6l15xzz0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mapping Algorithm -> Associates objects with respective coordinates in world coordinate frame and stores them in vector containing Long, Lat,\n",
        "#                      Height, class and corresponding image ID\n",
        "\n",
        "k = 0 # Images\n",
        "t = 0 # Total valid object number\n",
        "\n",
        "# u1 = np.zeros(num_objects*2)\n",
        "# v1 = np.zeros(num_objects*2)\n",
        "# u2 = np.zeros(num_objects*2)\n",
        "# v2 = np.zeros(num_objects*2)\n",
        "# x1 = np.zeros(num_objects)\n",
        "# y1 = np.zeros(num_objects)\n",
        "# x2 = np.zeros(num_objects)\n",
        "# y2 = np.zeros(num_objects)\n",
        "\n",
        "# Take size 1 for vectors and use append to grow vector for new values\n",
        "\n",
        "x_3D_rel_car = np.zeros(num_objects)\n",
        "y_3D_rel_car = np.zeros(num_objects)\n",
        "z_3D_rel_car = np.zeros(num_objects)\n",
        "obj_vector = np.zeros(shape=(num_objects,5))\n",
        "\n",
        "for x in results_path:\n",
        "  # Load json from path\n",
        "  with open(x) as json_file:\n",
        "    data = json.load(json_file)\n",
        "    for i in images_path:\n",
        "      print(\"Processing image number\", k)\n",
        "      n_objects = int(len(data['results'][k]['classes']))\n",
        "      #print(n_objects)\n",
        "      #print(data['results'][k]['boxes'][0][1])\n",
        "      for o in range(n_objects):\n",
        "\n",
        "        # Get image number\n",
        "        image_no = data['results'][k]['image_id'][22:25]\n",
        "        im_no = int(image_no)\n",
        "\n",
        "        # Get coordinates in image frame\n",
        "        u1 = data['results'][k]['boxes'][o][0]\n",
        "        v1 = data['results'][k]['boxes'][o][1]\n",
        "        u2 = data['results'][k]['boxes'][o][2]\n",
        "        v2 = data['results'][k]['boxes'][o][3]\n",
        "\n",
        "        # Calculate center point in image frame\n",
        "        u_cent = int(boundaries_to_box_center(u1, u2))\n",
        "        v_cent = int(boundaries_to_box_center(v1, v2))\n",
        "\n",
        "        # Get and write all disparities 1/10th of box-length around center point in matrix\n",
        "        disp_matrix = np.zeros(shape=(int(abs((u_cent-u1)/5)),int(abs((v_cent-v1)/5))))\n",
        "        \n",
        "        for y_coord in range(int(abs((v_cent-v1)/5))):\n",
        "          for x_coord in range(int(abs((u_cent-u1)/5))):\n",
        "            disp_matrix[x_coord][y_coord] = disparity_catcher(x_coord + int(u_cent) - int(abs(u_cent - u1)/10), y_coord + int(v_cent) - int(abs(v_cent - v1)/10), image_no)\n",
        "        \n",
        "        # Take median of disparity values\n",
        "        med_disp = np.median(disp_matrix, axis=None, out=None, overwrite_input=False, keepdims=False)\n",
        "\n",
        "        if med_disp != 0:\n",
        "\n",
        "          # Get disparity of center point in image frame\n",
        "          # disp_cent = disparity_catcher(u_cent, v_cent, k)\n",
        "\n",
        "          # Calculate depth from disparity\n",
        "          depth_med = disparity_to_depth(med_disp)\n",
        "\n",
        "          # Transform coordinates from image plane to camera frame\n",
        "          x1 = depth_med * (u1 - u_0[im_no]) / f_x[im_no]\n",
        "          y1 = depth_med * (v1 - v_0[im_no]) / f_y[im_no]\n",
        "          x2 = depth_med * (u2 - u_0[im_no]) / f_x[im_no]\n",
        "          y2 = depth_med * (v2 - v_0[im_no]) / f_y[im_no]\n",
        "\n",
        "          # Calculate box center in camera frame\n",
        "          x_cent = boundaries_to_box_center(x1, x2)\n",
        "          y_cent = boundaries_to_box_center(y1, y2)\n",
        "\n",
        "          # Save object coordinates in camera frame\n",
        "          x_3D_rel_car[t] = x_cent\n",
        "          y_3D_rel_car[t] = y_cent\n",
        "          z_3D_rel_car[t] = depth_med\n",
        "\n",
        "          # Transform object coordinates to world frame\n",
        "          input_vector = np.array([[x_3D_rel_car[t]], [y_3D_rel_car[t]], [z_3D_rel_car[t]]])\n",
        "          output_vector = camera_frame_to_world_transform(gpsHeading_actual_rad[im_no], yaw[im_no], pitch[im_no], roll[im_no], offset_x[im_no], offset_y[im_no], offset_z[im_no]).dot(np.vstack((input_vector, 1.0)))\n",
        "        \n",
        "          # Transform back to Lat / Long and save to vector\n",
        "          new_x = -output_vector[1]\n",
        "          new_y = output_vector[0]\n",
        "          d_lat, d_long = metric_diff_to_coord_diff(new_x, new_y, gpsLatitude_actual[im_no])\n",
        "        \n",
        "          # Save data to vector\n",
        "          obj_vector[t][0] = gpsLatitude_actual[im_no] + d_lat\n",
        "          obj_vector[t][1] = gpsLongitude_actual[im_no] + d_long\n",
        "          obj_vector[t][2] = output_vector[2]\n",
        "          obj_vector[t][3] = data['results'][k]['classes'][o]\n",
        "          obj_vector[t][4] = data['results'][k]['image_id'][22:25]\n",
        "          t += 1\n",
        "      k += 1\n",
        "\n",
        "      # if k == N loop incl. break to be removed, only for debugging purposes\n",
        "      if k == 715:\n",
        "        ## Write to file\n",
        "\n",
        "        # Create DataFrame \n",
        "        # mapping_output_df = pd.DataFrame({'Longitude': obj_vector[:, 1], 'Latitude': obj_vector[:, 0], 'z': obj_vector[:, 2], 'Semantic Label': obj_vector[:, 3]})\n",
        "\n",
        "        # Print the output. \n",
        "        # print(mapping_output_df) \n",
        "\n",
        "        ##\n",
        "        break\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jII6DrcXfVHI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "c33cd204-3d9e-4a7b-ada0-a6e1230d092a"
      },
      "source": [
        "### Writes Data to DataFrame and to csv file\n",
        "\n",
        "# Create DataFrame \n",
        "mapping_output_df = pd.DataFrame({'image ID': obj_vector[:, 4], 'longitude': obj_vector[:, 1], 'latitude': obj_vector[:, 0], 'z': obj_vector[:, 2], 'semanticlabel': obj_vector[:, 3]})\n",
        "\n",
        "# Print the output\n",
        "print(mapping_output_df)\n",
        "\n",
        "# Write output to csv file\n",
        "mapping_output_df.to_csv(r'data/mapping_output.csv', index = False)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     image ID  longitude   latitude         z  semanticlabel\n",
            "0       585.0  10.231669  50.042948  2.891653            1.0\n",
            "1       585.0  10.231342  50.042856  1.297854            5.0\n",
            "2        44.0  10.226271  50.039757  2.972267            1.0\n",
            "3       574.0  10.231102  50.042430  0.935025            3.0\n",
            "4       344.0  10.225686  50.042445  4.352941            1.0\n",
            "..        ...        ...        ...       ...            ...\n",
            "552     195.0  10.209142  50.045738  1.502832            3.0\n",
            "553     604.0  10.233630  50.042668  1.998030            1.0\n",
            "554     202.0  10.208317  50.043881  8.720302            1.0\n",
            "555     275.0  10.222089  50.044658  3.688783            1.0\n",
            "556     275.0  10.222138  50.044652  3.696740            1.0\n",
            "\n",
            "[557 rows x 5 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}