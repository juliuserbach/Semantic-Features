{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Semantic_Features_3DVision_2020.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juliuserbach/Semantic-Features/blob/master/Semantic_Features_3DVision_2020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KERvIJ-nkskO",
        "colab_type": "text"
      },
      "source": [
        "Our mapping pipeline is of the following structure:\n",
        "\n",
        "1.   Detection of objects of certain object classes (e.g. traffic sign). Output: object bounding boxes\n",
        "2.   Triangulation of objects. Output: object position relative to pose\n",
        "3.   Creating map of objects. (And refining with filter, BA, etc.) Output: List of objects and their corresponding positions\n",
        "4.   Visualizing map.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1TSOFcEnsjx",
        "colab_type": "text"
      },
      "source": [
        "We start by loading the benchmark dataset. The Cityscapes dataset is used. \n",
        "\n",
        "Scripts for analyzing the dataset can be found here: https://github.com/mcordts/cityscapesScripts\n",
        "\n",
        "How to download the zip files directly: https://towardsdatascience.com/download-city-scapes-dataset-with-script-3061f87b20d7\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6ZU2SJr1Ifg",
        "colab_type": "text"
      },
      "source": [
        "Download CityScape files: \n",
        "\n",
        "*   leftImg8bit_trainextra.zip\n",
        "*   disparity_trainextra.zip\n",
        "*   camera_trainextra.zip\n",
        "*   vehicle_trainextra.zip\n",
        "\n",
        "The files are unzipped into data/... respectively.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QM1GyIOSzP06",
        "colab_type": "code",
        "outputId": "dc24ffcc-fb87-4b07-99a8-09995ac1b128",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Download and unzip (run only once!).\n",
        "PATH_TO_LEFT_IMAGES = \"leftImg8bit/train_extra/schweinfurt/\"\n",
        "PATH_TO_DISPARITY = \"disparity/train_extra/schweinfurt/\"\n",
        "PATH_TO_CAMERA = \"camera/train_extra/schweinfurt/\"\n",
        "PATH_TO_VEHICLE = \"vehicle/train_extra/schweinfurt/\"\n",
        "\n",
        "# Remove data directory if it is already loaded (if needed).\n",
        "#!rm -r data\n",
        "# Login.\n",
        "!wget --keep-session-cookies --save-cookies=cookies.txt --post-data 'username=ftaubner@ethz.ch&password=semantic_dudes&submit=Login' https://www.cityscapes-dataset.com/login/\n",
        "# Get left camera images. I put it on OneDrive so that only Schweinfurt has to be downloaded.\n",
        "!wget --no-check-certificate \"https://onedrive.live.com/download?cid=EA356294C6263A37&resid=EA356294C6263A37%2199734&authkey=AC5K24PFcrSPFl4\" -O leftImg8bit_trainextra.zip\n",
        "# Alternatively, it can be downloaded from CityScapes website directly:\n",
        "#   (!wget --load-cookies cookies.txt --content-disposition https://www.cityscapes-dataset.com/file-handling/?packageID=4)\n",
        "# Extract.\n",
        "!mkdir data\n",
        "!unzip -qq leftImg8bit_trainextra.zip \"$PATH_TO_LEFT_IMAGES\"* -d data\n",
        "# And delete.\n",
        "!rm leftImg8bit_trainextra.zip\n",
        "\n",
        "# Get disparity maps.\n",
        "!wget --no-check-certificate \"https://onedrive.live.com/download?cid=EA356294C6263A37&resid=EA356294C6263A37%2199735&authkey=AEwGRlH_TySnyPM\" -O disparity_trainextra.zip\n",
        "# Original file:\n",
        "#   (!wget --load-cookies cookies.txt --content-disposition https://www.cityscapes-dataset.com/file-handling/?packageID=22)\n",
        "!unzip -qq disparity_trainextra.zip \"$PATH_TO_DISPARITY\"* -d data\n",
        "!rm disparity_trainextra.zip\n",
        "# Get camera intrinsics. \n",
        "!wget --load-cookies cookies.txt --content-disposition https://www.cityscapes-dataset.com/file-handling/?packageID=9\n",
        "!unzip -qq camera_trainextra.zip \"$PATH_TO_CAMERA\"* -d data\n",
        "!rm camera_trainextra.zip\n",
        "# Get vehicle odometry.\n",
        "!wget --load-cookies cookies.txt --content-disposition https://www.cityscapes-dataset.com/file-handling/?packageID=11\n",
        "!unzip -qq vehicle_trainextra.zip \"$PATH_TO_VEHICLE\"* -d data\n",
        "!rm vehicle_trainextra.zip\n",
        "\n",
        "import os\n",
        "PATH_TO_LEFT_IMAGES = os.path.join(\"data/\", PATH_TO_LEFT_IMAGES)\n",
        "PATH_TO_DISPARITY = os.path.join(\"data/\", PATH_TO_DISPARITY)\n",
        "PATH_TO_CAMERA = os.path.join(\"data/\", PATH_TO_CAMERA)\n",
        "PATH_TO_VEHICLE = os.path.join(\"data/\", PATH_TO_VEHICLE)\n",
        "\n",
        "print(\"Finished unzipping.\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-25 12:39:13--  https://www.cityscapes-dataset.com/login/\n",
            "Resolving www.cityscapes-dataset.com (www.cityscapes-dataset.com)... 139.19.217.8\n",
            "Connecting to www.cityscapes-dataset.com (www.cityscapes-dataset.com)|139.19.217.8|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://www.cityscapes-dataset.com/downloads/ [following]\n",
            "--2020-03-25 12:39:14--  https://www.cityscapes-dataset.com/downloads/\n",
            "Reusing existing connection to www.cityscapes-dataset.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘index.html’\n",
            "\n",
            "index.html              [ <=>                ]  42.77K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-03-25 12:39:16 (361 KB/s) - ‘index.html’ saved [43792]\n",
            "\n",
            "--2020-03-25 12:39:18--  https://onedrive.live.com/download?cid=EA356294C6263A37&resid=EA356294C6263A37%2199734&authkey=AC5K24PFcrSPFl4\n",
            "Resolving onedrive.live.com (onedrive.live.com)... 13.107.42.13\n",
            "Connecting to onedrive.live.com (onedrive.live.com)|13.107.42.13|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://xyibzg.am.files.1drv.com/y4mQmmI52vxW2Z6irUekQ44TGxc09dGjtmNQDIV0bmbsT-HKWNEGjKBBS5apd7iBzqQxMoCSrzJOBYZ6nvTAplFt0ete6yUOAlMRS6BjjUTbStDNHcLZDW6gz3G-QLAvZ61Ze3CsJ4f8zfCE_OAY2amQAw6L7R41jDtMA58Jez9osirl49v5hZUwIJbxFUulkDQELf1MAlnskmeMqBjRW3uLQ/leftImg8bit_trainextra.zip?download&psid=1 [following]\n",
            "--2020-03-25 12:39:19--  https://xyibzg.am.files.1drv.com/y4mQmmI52vxW2Z6irUekQ44TGxc09dGjtmNQDIV0bmbsT-HKWNEGjKBBS5apd7iBzqQxMoCSrzJOBYZ6nvTAplFt0ete6yUOAlMRS6BjjUTbStDNHcLZDW6gz3G-QLAvZ61Ze3CsJ4f8zfCE_OAY2amQAw6L7R41jDtMA58Jez9osirl49v5hZUwIJbxFUulkDQELf1MAlnskmeMqBjRW3uLQ/leftImg8bit_trainextra.zip?download&psid=1\n",
            "Resolving xyibzg.am.files.1drv.com (xyibzg.am.files.1drv.com)... 13.107.43.12\n",
            "Connecting to xyibzg.am.files.1drv.com (xyibzg.am.files.1drv.com)|13.107.43.12|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1582171242 (1.5G) [application/zip]\n",
            "Saving to: ‘leftImg8bit_trainextra.zip’\n",
            "\n",
            "leftImg8bit_trainex 100%[===================>]   1.47G  28.2MB/s    in 60s     \n",
            "\n",
            "2020-03-25 12:40:20 (25.2 MB/s) - ‘leftImg8bit_trainextra.zip’ saved [1582171242/1582171242]\n",
            "\n",
            "--2020-03-25 12:40:37--  https://onedrive.live.com/download?cid=EA356294C6263A37&resid=EA356294C6263A37%2199735&authkey=AEwGRlH_TySnyPM\n",
            "Resolving onedrive.live.com (onedrive.live.com)... 13.107.43.13\n",
            "Connecting to onedrive.live.com (onedrive.live.com)|13.107.43.13|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://xyiczg.am.files.1drv.com/y4mqVHjD1VVrg7OasefrMkKMuc_XkB2K3iUmouVGKkd_7sZWnOmyluuiRsCKDVSrxq-0Dij1HAA5frmprtwTLBv2ar-K1tu0tkm2t9jebqpYVwChE34R1ymRVcCk_jLHYDlemMIilV-dtTBeB-_LgNaQ3G2EiTWr8cVrVZ-YGJQyqDrL9g5jJ4AKbD0Z5zFkV7FhSQzCnSRC5nHnve8p--nDQ/disparity_trainextra.zip?download&psid=1 [following]\n",
            "--2020-03-25 12:40:38--  https://xyiczg.am.files.1drv.com/y4mqVHjD1VVrg7OasefrMkKMuc_XkB2K3iUmouVGKkd_7sZWnOmyluuiRsCKDVSrxq-0Dij1HAA5frmprtwTLBv2ar-K1tu0tkm2t9jebqpYVwChE34R1ymRVcCk_jLHYDlemMIilV-dtTBeB-_LgNaQ3G2EiTWr8cVrVZ-YGJQyqDrL9g5jJ4AKbD0Z5zFkV7FhSQzCnSRC5nHnve8p--nDQ/disparity_trainextra.zip?download&psid=1\n",
            "Resolving xyiczg.am.files.1drv.com (xyiczg.am.files.1drv.com)... 13.107.42.12\n",
            "Connecting to xyiczg.am.files.1drv.com (xyiczg.am.files.1drv.com)|13.107.42.12|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 494420562 (472M) [application/zip]\n",
            "Saving to: ‘disparity_trainextra.zip’\n",
            "\n",
            "disparity_trainextr 100%[===================>] 471.52M  14.9MB/s    in 26s     \n",
            "\n",
            "2020-03-25 12:41:05 (18.2 MB/s) - ‘disparity_trainextra.zip’ saved [494420562/494420562]\n",
            "\n",
            "--2020-03-25 12:41:16--  https://www.cityscapes-dataset.com/file-handling/?packageID=9\n",
            "Resolving www.cityscapes-dataset.com (www.cityscapes-dataset.com)... 139.19.217.8\n",
            "Connecting to www.cityscapes-dataset.com (www.cityscapes-dataset.com)|139.19.217.8|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8160020 (7.8M) [application/octet-stream]\n",
            "Saving to: ‘camera_trainextra.zip’\n",
            "\n",
            "camera_trainextra.z 100%[===================>]   7.78M  44.5MB/s    in 0.2s    \n",
            "\n",
            "2020-03-25 12:41:16 (44.5 MB/s) - ‘camera_trainextra.zip’ saved [8160020/8160020]\n",
            "\n",
            "--2020-03-25 12:41:22--  https://www.cityscapes-dataset.com/file-handling/?packageID=11\n",
            "Resolving www.cityscapes-dataset.com (www.cityscapes-dataset.com)... 139.19.217.8\n",
            "Connecting to www.cityscapes-dataset.com (www.cityscapes-dataset.com)|139.19.217.8|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8007153 (7.6M) [application/octet-stream]\n",
            "Saving to: ‘vehicle_trainextra.zip’\n",
            "\n",
            "vehicle_trainextra. 100%[===================>]   7.64M  40.5MB/s    in 0.2s    \n",
            "\n",
            "2020-03-25 12:41:22 (40.5 MB/s) - ‘vehicle_trainextra.zip’ saved [8007153/8007153]\n",
            "\n",
            "Finished unzipping.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwU_f_b7nH-O",
        "colab_type": "text"
      },
      "source": [
        "We start with the detection of objects of interest. Faster R-CNN is used for this task. (Julius)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qX732O_UCkoo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# COCO Class names\n",
        "# Index of the class in the list is its ID. For example, to get ID of\n",
        "# the teddy bear class, use: class_names.index('teddy bear')\n",
        "class_names = ['BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',\n",
        "               'bus', 'train', 'truck', 'boat', 'traffic light',\n",
        "               'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',\n",
        "               'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',\n",
        "               'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n",
        "               'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
        "               'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
        "               'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',\n",
        "               'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
        "               'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
        "               'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n",
        "               'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
        "               'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',\n",
        "               'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n",
        "               'teddy bear', 'hair drier', 'toothbrush']\n",
        "static_classes = []              "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXh-WMRDzqFe",
        "colab_type": "text"
      },
      "source": [
        "Loading an on COCO pre-trained Faster R-CNN \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gO8ZQm5lzz5s",
        "colab_type": "text"
      },
      "source": [
        "Installing Seamless Scene Segmentation from https://github.com/mapillary/seamseg\n",
        "For Seamless Scene Segmentation a pre-trained version on the Mapillary Dataset exists. Dataloaders for Cityscapes seem to exist, too.\n",
        "\n",
        "It is a network for panoptic segmentation basen on Mask-R-CNN. Alternatively the panoptic variant in the detectron2 reopisitory can also be trained on Cityscapes or Mapillary. Dataloaders seem to exist for both Datasets. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLq9ofO5zzmS",
        "colab_type": "code",
        "outputId": "5e5664a8-9295-437d-ae20-07611ddcb59e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "#@title\n",
        "!pip install git+https://github.com/mapillary/seamseg.git\n",
        "#!pip install wget\n",
        "\n",
        "url = 'https://drive.google.com/file/d/1ULhd_CZ24L8FnI9lZ2H6Xuf03n6NA_-Y/view'\n",
        "!wget $url\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/mapillary/seamseg.git\n",
            "  Cloning https://github.com/mapillary/seamseg.git to /tmp/pip-req-build-kpb8mbuu\n",
            "  Running command git clone -q https://github.com/mapillary/seamseg.git /tmp/pip-req-build-kpb8mbuu\n",
            "Building wheels for collected packages: seamseg\n",
            "  Building wheel for seamseg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seamseg: filename=seamseg-0.1.dev31+g18e28cc-cp36-cp36m-linux_x86_64.whl size=7004851 sha256=d6fd39949aade8d2596ae1f3a7c034f12f1f5149fc078ecd1861e1af1b1fea3f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-vutlpq_8/wheels/34/ae/9b/f7108b6552df4829b6952190c9af1ec04fc171251cdc5d9ea9\n",
            "Successfully built seamseg\n",
            "Installing collected packages: seamseg\n",
            "Successfully installed seamseg-0.1.dev31+g18e28cc\n",
            "--2020-03-25 12:45:09--  https://drive.google.com/file/d/1ULhd_CZ24L8FnI9lZ2H6Xuf03n6NA_-Y/view\n",
            "Resolving drive.google.com (drive.google.com)... 64.233.167.101, 64.233.167.113, 64.233.167.138, ...\n",
            "Connecting to drive.google.com (drive.google.com)|64.233.167.101|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘view’\n",
            "\n",
            "view                    [ <=>                ]  67.26K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2020-03-25 12:45:10 (2.29 MB/s) - ‘view’ saved [68871]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bjqhrjt8BTs",
        "colab_type": "text"
      },
      "source": [
        "These functions convert a difference in coordinates (lat., long.) to a difference in metric frame (x, y) and vice versa. Both conversions are dependent on the current latitude.\n",
        "Under the assumption that we are in Europe, east of 0°!\n",
        "\n",
        "Approximative conversions:\n",
        "\n",
        "* Latitude: 1 deg = 110.574 km\n",
        "* Longitude: 1 deg = 111.320*cos(latitude) km\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2l9jM1A7_9S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Felix \n",
        "# Helper functions for transformations.\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Calculates the difference between two coordinates in meters (x to east, y to north).\n",
        "# See below for example.\n",
        "def coord_diff_to_metric_diff(d_lat, d_long, lat):\n",
        "  d_y = d_lat * 110574\n",
        "  d_x = d_long * 111320 * np.cos(np.radians(lat))\n",
        "  return d_x, d_y\n",
        "\n",
        "\n",
        "# Converts the metric difference to differences in latitude and longitude.\n",
        "# See below for example.\n",
        "def metric_diff_to_coord_diff(d_x, d_y, lat):\n",
        "  d_lat = d_y / 110574\n",
        "  d_long = d_x / 111320 / np.cos(np.radians(lat))\n",
        "  return d_lat, d_long\n",
        "\n",
        "\n",
        "# Returns the transformation matrix: world frame (-> vehicle frame) -> camera frame\n",
        "# Usage: [x_world; 1] = camera_frame_to_world_transform(args).dot([x_camera_frame; 1])\n",
        "# All angles in radians, distances in meters!\n",
        "# See below for example.\n",
        "def camera_frame_to_world_transform(heading, yaw_ext, pitch_ext, roll_ext, x_ext, y_ext, z_ext):\n",
        "    # Coordinate axis switch for camera.\n",
        "    C_c = np.array([[0., -1.,  0., 0.],\n",
        "                    [0.,  0., -1., 0.],\n",
        "                    [1.,  0.,  0., 0.],\n",
        "                    [0.,  0.,  0., 1.]])\n",
        "    # Vehicle to camera transformation matrix.\n",
        "    c_y = np.cos(yaw_ext)\n",
        "    c_p = np.cos(pitch_ext)\n",
        "    c_r = np.cos(roll_ext)\n",
        "    s_y = np.sin(yaw_ext)\n",
        "    s_p = np.sin(pitch_ext)\n",
        "    s_r = np.sin(roll_ext)\n",
        "    T_v_c = np.array([[c_y*c_p, c_y*s_p*s_r-s_y*c_r, c_y*s_p*c_r+s_y*s_r, x_ext],\n",
        "                      [s_y*c_p, s_y*s_p*s_r+c_y*c_r, s_y*s_p*c_r-c_y*s_r, y_ext],\n",
        "                      [   -s_p,             c_p*s_r,             c_p*c_r, z_ext],\n",
        "                      [     0.,                  0.,                  0.,    1.]])\n",
        "\n",
        "    # World to vehicle transformation matrix.\n",
        "    c_h = np.cos(heading)\n",
        "    s_h = np.sin(heading)\n",
        "    T_w_v = np.array([[c_h, -s_h, 0., 0.],\n",
        "                      [s_h,  c_h, 0., 0.],\n",
        "                      [ 0.,   0., 1., 0.],\n",
        "                      [ 0.,   0., 0., 1.]])\n",
        "\n",
        "    # Return camera space to vehicle transform.\n",
        "    return T_w_v.dot(T_v_c.dot(np.linalg.inv(C_c)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKWwzyVW_ZHa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Testing and example (taken from Johannes' map pic on WhatsApp):\n",
        "# Converting coords into metrics:\n",
        "d_x, d_y = coord_diff_to_metric_diff(48.370-48.369, 10.896-10.894, 48.368)\n",
        "print(\"Delta x in meters: {}\".format(d_x))\n",
        "print(\"Delta y in meters: {}\".format(d_y))\n",
        "\n",
        "# Converting back to coords: should be the same:\n",
        "d_lat, d_long = metric_diff_to_coord_diff(d_x, d_y, 48.368)\n",
        "print(\"Difference in latitude: {}\".format(d_lat))\n",
        "print(\"Difference in longitude: {}\".format(d_long))\n",
        "\n",
        "# Convert a camera frame coordinate to world coordinate:\n",
        "x_example = np.array([[8.1], [0.7], [0.7]])\n",
        "x_world_example = camera_frame_to_world_transform(0.25, 0.0057, 0.055, 0.0, 1.7, -0.1, 1.3).dot(np.vstack((x_example, 1.0)))\n",
        "print(\"Camera coordinate: \")\n",
        "print(x_example)\n",
        "print(\"World coordinate: \")\n",
        "print(x_world_example)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TN9kAAMFUHg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading results from json file stored in FEATURE_FILE \n",
        "FEATURE_FILE = \"results.json\"\n",
        "with open(FEATURE_FILE) as json_file:\n",
        "    features = json.load(json_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cstG2BrsLQBZ",
        "colab_type": "text"
      },
      "source": [
        "Plotting ground truth trajectory of vehicle. (Map image muss im Moment immer noch manuell gedownloaded und hinzugefügt werden)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lc45wu8FLRmP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading ground truth data from json file and saving it as pandas array\n",
        "import pandas as pd \n",
        "import os\n",
        "import json\n",
        "import glob\n",
        "from pandas.io.json import json_normalize\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "DATA_DIR=\"data/vehicle/train_extra/schweinfurt\"\n",
        "images_path = list(glob.iglob(os.path.join(DATA_DIR, '*.*')))\n",
        "n_images = len(images_path)\n",
        "i = 0\n",
        "# create space for long at lat\n",
        "gpsLatitude = np.zeros(n_images)\n",
        "gpsLongitude = np.zeros(n_images)\n",
        "\n",
        "for image_path in images_path:\n",
        "  # Load json from path\n",
        "  with open(image_path) as json_file:\n",
        "    data = json.load(json_file)\n",
        "    gpsLatitude[i] = data['gpsLatitude']\n",
        "    gpsLongitude[i] = data['gpsLongitude']\n",
        "    i += 1\n",
        "df = pd.DataFrame({'longitude': gpsLongitude,\n",
        "'latitude': gpsLatitude})\n",
        "BBox = ((df.longitude.min(),   df.longitude.max(),      \n",
        "         df.latitude.min(), df.latitude.max()))\n",
        "\n",
        "longdif = df.longitude.max() - df.longitude.min()\n",
        "latgdif = df.latitude.max() - df.latitude.min()\n",
        "aspectr = longdif/latgdif\n",
        "\n",
        "image = plt.imread('/content/map (4).png')\n",
        "\n",
        "fig, ax = plt.subplots(figsize = (8,7))\n",
        "ax.scatter(df.longitude, df.latitude)\n",
        "ax.set_title('Plotting Trajectiory')\n",
        "ax.set_xlim(BBox[0],BBox[1])\n",
        "ax.set_ylim(BBox[2],BBox[3])\n",
        "ax.imshow(image, zorder=0, extent = BBox)\n",
        "ax.set_aspect(aspect= aspectr)\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaGRTzSON66G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_DIR=\"data/vehicle/train_extra/schweinfurt\"\n",
        "images_path = list(glob.iglob(os.path.join(DATA_DIR, '*.*')))\n",
        "n_images = len(images_path)\n",
        "i = 0\n",
        "\n",
        "# create space for long at lat\n",
        "gpsLatitude_actual = np.zeros(n_images)\n",
        "gpsLongitude_actual = np.zeros(n_images)\n",
        "gpsHeading_actual = np.zeros(n_images)\n",
        "gpsLatitude_delta = np.zeros(n_images)\n",
        "gpsLongitude_delta = np.zeros(n_images)\n",
        "gpsHeading_delta = np.zeros(n_images)\n",
        "\n",
        "\n",
        "for image_path in images_path:\n",
        "  # Load json from path\n",
        "  with open(image_path) as json_file:\n",
        "    data = json.load(json_file)\n",
        "    gpsLatitude_actual[i] = data['gpsLatitude']\n",
        "    gpsLongitude_actual[i] = data['gpsLongitude']\n",
        "    gpsHeading_actual[i] = data['gpsHeading']\n",
        "    if i > 0:\n",
        "      gpsLatitude_delta[i] = gpsLatitude_actual[i] - gpsLatitude_actual[i-1]\n",
        "      gpsLongitude_delta[i] = gpsLongitude_actual[i] - gpsLongitude_actual[i-1]\n",
        "      gpsHeading_delta[i] = gpsHeading_actual[i] - gpsHeading_actual[i-1]\n",
        "  i+=1\n",
        "\n",
        "# Actual coordinates in x, y starting at 0, 0\n",
        "\n",
        "gps_step_delta_X = np.zeros(n_images)\n",
        "gps_total_delta_X = np.zeros(n_images)\n",
        "gps_step_delta_Y = np.zeros(n_images)\n",
        "gps_total_delta_Y = np.zeros(n_images)\n",
        "gps_total_delta_Heading = np.zeros(n_images)\n",
        "\n",
        "i = 0\n",
        "\n",
        "for image_path in images_path:\n",
        "  if i > 0:\n",
        "    gps_step_delta_X[i], gps_step_delta_Y[i] = coord_diff_to_metric_diff(gpsLatitude_delta[i], gpsLongitude_delta[i], gpsLatitude_actual[i])\n",
        "    gps_total_delta_X[i] = gps_total_delta_X[i-1] + gps_step_delta_X[i]\n",
        "    gps_total_delta_Y[i] = gps_total_delta_Y[i-1] + gps_step_delta_Y[i]\n",
        "    gps_total_delta_Heading[i] = gps_total_delta_Heading[i-1] + gpsHeading_delta[i]\n",
        "  i+=1\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jjtUpajvkQw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get Camera Calibration Data\n",
        "\n",
        "DATA_DIR=\"data/camera/train_extra/schweinfurt\"\n",
        "images_path = list(glob.iglob(os.path.join(DATA_DIR, '*.*')))\n",
        "n_images = len(images_path)\n",
        "i = 0\n",
        "\n",
        "# create space for long at lat\n",
        "roll  = np.zeros(n_images)\n",
        "pitch = np.zeros(n_images)\n",
        "yaw = np.zeros(n_images)\n",
        "baseline = np.zeros(n_images)\n",
        "offset_x = np.zeros(n_images)\n",
        "offset_y = np.zeros(n_images)\n",
        "offset_z = np.zeros(n_images)\n",
        "fx = np.zeros(n_images)\n",
        "fy = np.zeros(n_images)\n",
        "\n",
        "for image_path in images_path:\n",
        "  # Load json from path\n",
        "  with open(image_path) as json_file:\n",
        "    data = json.load(json_file)\n",
        "    roll[i] = data['extrinsic']['roll']\n",
        "    pitch[i] = data['extrinsic']['pitch']\n",
        "    yaw[i] = data['extrinsic']['yaw']\n",
        "    baseline[i] = data['extrinsic']['baseline']\n",
        "    offset_x[i] = data['extrinsic']['x']\n",
        "    offset_y[i] = data['extrinsic']['y']\n",
        "    offset_z[i] = data['extrinsic']['z']\n",
        "    fx[i] = data['intrinsic']['fx']\n",
        "    fy[i] = data['intrinsic']['fy']\n",
        "  i+=1\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crfISE18wU_V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calculate real 3D position\n",
        "def pixel_to_3Dposition_converter(x, depth, focal):\n",
        "  x_3D = x * depth / focal\n",
        "  return x_3D\n",
        "\n",
        "# Calculate box center to get average disparity\n",
        "def boundaries_to_box_center(x_1, x_2):\n",
        "  x_center = (x_1 + x_2)/2\n",
        "  return x_center\n",
        "\n",
        "# Get camera focal length and baseline (To be corrected, pixels are NOT quadratic here fx =/= fy)\n",
        "def camera_parameters(fx, fy):\n",
        "  # Take average, which is Bullshit, but not better idea yet\n",
        "  focal = (fx + fy)/2\n",
        "  # Get baseline value from calibration data\n",
        "  baseline = 0.222384\n",
        "  return focal, baseline\n",
        "\n",
        "# Get disparities of all points (pixels)\n",
        "def disparity_catcher(x, y, i):\n",
        "  DATA_DIR=\"data/disparity/train_extra/schweinfurt\"\n",
        "  im_directory = list(glob.iglob(os.path.join(DATA_DIR, '*.*')))\n",
        "  n_im = len(im_directory)\n",
        "  l = 0\n",
        "  disp = 0\n",
        "\n",
        "  for im_number in im_directory:\n",
        "  # Load image from path\n",
        "    img = cv2.imread(im_number, cv2.IMREAD_UNCHANGED)\n",
        "    if l == i:\n",
        "      # Changed to read precise disparity. (Felix)\n",
        "      # x and y values were mixed up! Please take care next time.\n",
        "      #if disp != 0:\n",
        "      disp = (img[y, x] - 1.) / 256.\n",
        "\n",
        "      print(disp)\n",
        "      return disp\n",
        "    else:\n",
        "      l += 1\n",
        "\n",
        "  # return disp\n",
        "\n",
        "# Get disparity of center point\n",
        "# def box_center_disparity(x_center, y_center):\n",
        "  # disparity_box_center = pix_val_flat[1024 * 2048 * 4 - 2048 * y_center * 4 + x_center * 4]\n",
        "  # return disparity_box_center\n",
        "\n",
        "# Convert disparity to actual depth information\n",
        "def disparity_to_depth(disparity_box_center):\n",
        "  if disparity_box_center > 0:\n",
        "    depth_center = baseline * focal / disparity_box_center\n",
        "  else:\n",
        "    depth_center = 100\n",
        "  return depth_center\n",
        "\n",
        "# Transformation to world frame coordinates\n",
        "# _3dImage\t=\tcv.reprojectImageTo3D('data/disparity/train_extra/schweinfurt/schweinfurt_000000_000000_disparity.png', Q)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkjgYrHHN4dt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import math\n",
        "# import csv\n",
        "# import pandas as pd\n",
        "# import cv2\n",
        "\n",
        "# Get focal length from calibration data\n",
        "# fx = 2273.82\n",
        "# fy = 2236.9989965173254\n",
        "\n",
        "#FEATURE_FILE = 'results.csv'\n",
        "\n",
        "# Read box coordinates from csv file\n",
        "#results_df = pd.read_csv(FEATURE_FILE, sep=';')\n",
        "#print(results_df.head)\n",
        "\n",
        "#obj = results_df.to_numpy()\n",
        "#print(obj[0][2][1:46])\n",
        "#row = obj[0][2][1:46]\n",
        "#print(features[0]['boxes'][0][0])\n",
        "#print(features[0]['boxes'][1][0])\n",
        "\n",
        "#print(features[0].keys())\n",
        "\n",
        "# class objct:\n",
        "  # def __init__(self, category, x1, y1, x2, y2):\n",
        "    # self.category = category\n",
        "    # self.x1 = x1\n",
        "    # self.y1 = y1\n",
        "    # self.x2 = x2\n",
        "    # self.y2 = y2\n",
        "\n",
        "# class im:\n",
        "  # def __init__(self, name, num_obj):\n",
        "    # self.category = category\n",
        "    # self.name = name\n",
        "    # self.num_obj = num_obj\n",
        "\n",
        "# obj1 = obj(2, 100, 200, 400, 300)\n",
        "\n",
        "# print(obj1.category)\n",
        "# print(obj1.x_center)\n",
        "\n",
        "# n_images = len(images_path)\n",
        "\n",
        "# for i in images_path:\n",
        " #  for o in range(len(features[i]['classes'])):\n",
        "   #  x_cent = int(boundaries_to_box_center(features[i]['boxes'][o][0], features[i]['boxes'][o][1]))\n",
        "   #  y_cent = int(boundaries_to_box_center(features[i]['boxes'][o][2], features[i]['boxes'][o][3]))\n",
        "   #  disp_cent = disparity_catcher(x_cent, y_cent, i)\n",
        "   #  depth_cent = disparity_to_depth(disp_cent)\n",
        "   #  x_3D = pixel_to_3Dposition_converter(x_cent, depth_cent, focal)\n",
        "   #  y_3D = pixel_to_3Dposition_converter(y_cent, depth_cent, focal)\n",
        "   #  features[i]['boxes'][o][0] = gps_total_delta_X[i] + x_3D * cos(gps_total_delta_Heading[i]) - y_3D * sin(gps_total_delta_Heading[i])\n",
        "   #  features[i]['boxes'][o][1] = gps_total_delta_Y[i] + x_3D * sin(gps_total_delta_Heading[i]) + y_3D * cos(gps_total_delta_Heading[i])\n",
        "   #  features[i]['boxes'][o][2] = int(0)\n",
        "   #  features[i]['boxes'][o][3] = int(0)\n",
        "\n",
        "#print(features[0]['boxes'][0][0:10])\n",
        "\n",
        "   # (objct(features[i]['classes'][o], features[i]['boxes'][o][0], features[i]['boxes'][o][1], features[i]['boxes'][o][2], features[i]['boxes'][o][3]))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chKg6l15xzz0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "836ec2e7-73a6-447d-90ff-86462ed03709"
      },
      "source": [
        "import math\n",
        "import csv\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import glob\n",
        "\n",
        "# Get focal length from calibration data\n",
        "fx = 2273.82\n",
        "fy = 2236.9989965173254\n",
        "# baseline = 0.222384\n",
        "\n",
        "focal, baseline = camera_parameters(fx, fy)\n",
        "\n",
        "\n",
        "DATA_DIR=\"data/Numerical_Results\"\n",
        "results_path = list(glob.iglob(os.path.join(DATA_DIR, '*.*')))\n",
        "n_images = len(images_path)\n",
        "k = 0 # Images\n",
        "t = 0 # Total object number\n",
        "\n",
        "x1 = np.zeros(30)\n",
        "y1 = np.zeros(30)\n",
        "x2 = np.zeros(30)\n",
        "y2 = np.zeros(30)\n",
        "x_3D_rel_car = np.zeros(30)\n",
        "y_3D_rel_car = np.zeros(30)\n",
        "z_3D_rel_car = np.zeros(30)\n",
        "obj_vector = np.zeros(shape=(30,4))\n",
        "\n",
        "for x in results_path:\n",
        "  # Load json from path\n",
        "  with open(x) as json_file:\n",
        "    data = json.load(json_file)\n",
        "    for i in images_path:\n",
        "      print(\"Processing image number\", k)\n",
        "      n_objects = int(len(data['results'][k]['classes']))\n",
        "      #print(n_objects)\n",
        "      #print(data['results'][k]['boxes'][0][1])\n",
        "      for o in range(n_objects):\n",
        "        x1[t] = data['results'][k]['boxes'][o][0]\n",
        "        y1[t] = data['results'][k]['boxes'][o][1]\n",
        "        x2[t] = data['results'][k]['boxes'][o][2]\n",
        "        y2[t] = data['results'][k]['boxes'][o][3]\n",
        "        x_cent = int(boundaries_to_box_center(x1[t], x2[t]))\n",
        "        y_cent = int(boundaries_to_box_center(y1[t], y2[t]))\n",
        "        disp_cent = disparity_catcher(x_cent, y_cent, k)\n",
        "        depth_cent = disparity_to_depth(disp_cent)\n",
        "        x_3D_rel_car[t] = pixel_to_3Dposition_converter(x_cent, depth_cent, focal)\n",
        "        y_3D_rel_car[t] = pixel_to_3Dposition_converter(y_cent, depth_cent, focal)\n",
        "        z_3D_rel_car[t] = depth_cent\n",
        "        input_vector = np.array([[x_3D_rel_car[t]], [y_3D_rel_car[t]], [z_3D_rel_car[t]]])\n",
        "        output_vector = camera_frame_to_world_transform(gps_total_delta_Heading[k], yaw[k], pitch[k], roll[k], offset_x[k], offset_y[k], offset_z[k]).dot(np.vstack((input_vector, 1.0)))\n",
        "        d_lat, d_long = metric_diff_to_coord_diff(output_vector[0], output_vector[1], gpsLatitude_actual[k])\n",
        "        obj_vector[t][0] = gpsLatitude_actual[k] + d_lat\n",
        "        obj_vector[t][1] = gpsLongitude_actual[k] + d_long\n",
        "        obj_vector[t][2] = output_vector[2]\n",
        "        obj_vector[t][3] = data['results'][k]['classes'][o]\n",
        "        t += 1\n",
        "      k += 1\n",
        "      if k == 3:\n",
        "        ##\n",
        "        \n",
        "        # data_out = {'longitude':[obj_vector[:,1]], 'latitude':[obj_vector[:,0]], 'z':[obj_vector[:,2]], 'semantic label':[obj_vector[:,3]]} \n",
        "        # data_out = {obj_vector} \n",
        "\n",
        "        # Create DataFrame \n",
        "        # mapping_output_df = pd.DataFrame(data_out)\n",
        "        # mapping_output_df = pd.DataFrame(data=obj_vector[:,0,:,1,:2,:3], index=None, columns=['latitude', 'longitude', 'z', 'semantic label'], dtype=None, copy=False)\n",
        "        mapping_output_df = pd.DataFrame({'Longitude': obj_vector[:, 1], 'Latitude': obj_vector[:, 0], 'z': obj_vector[:, 2], 'Semantic Label': obj_vector[:, 3]})\n",
        "\n",
        "        # Print the output. \n",
        "        print(mapping_output_df) \n",
        "\n",
        "        ##\n",
        "        break\n",
        "\n",
        "# mapping_output_df = pd.DataFrame({'longitude': gpsLongitude, 'latitude': gpsLatitude, 'z': obj_vector[t][2], 'semantic label': obj_vector[t][3]})\n",
        "\n",
        "# Python code demonstrate creating  \n",
        "# DataFrame from dict narray / lists  \n",
        "# By default addresses.\n",
        "  \n",
        "# intialise data of lists. \n",
        "# data_out = {'longitude':[obj_vector[:,1]], 'latitude':[obj_vector[:,0]], 'z':[obj_vector[:,2]], 'semantic label':[obj_vector[:,3]]} \n",
        "  \n",
        "# Create DataFrame \n",
        "# mapping_output_df = pd.DataFrame(data_out) \n",
        "  \n",
        "# Print the output. \n",
        "# print(df) "
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing image number 0\n",
            "33.4921875\n",
            "6.98828125\n",
            "10.0\n",
            "5.73046875\n",
            "6.61328125\n",
            "9.12890625\n",
            "5.09375\n",
            "4.02734375\n",
            "Processing image number 1\n",
            "2.3203125\n",
            "28.76171875\n",
            "20.2265625\n",
            "29.63671875\n",
            "26.296875\n",
            "18.9609375\n",
            "18.265625\n",
            "26.9453125\n",
            "15.265625\n",
            "15.8515625\n",
            "22.015625\n",
            "16.05078125\n",
            "17.6640625\n",
            "22.8359375\n",
            "Processing image number 2\n",
            "11.16015625\n",
            "16.234375\n",
            "4.73046875\n",
            "20.51953125\n",
            "11.33203125\n",
            "18.4765625\n",
            "17.5\n",
            "6.984375\n",
            "    Longitude   Latitude          z  Semantic Label\n",
            "0   10.219521  50.044768  -2.420484             2.0\n",
            "1   10.220307  50.044581 -16.276676             2.0\n",
            "2   10.220008  50.044659 -10.938666             2.0\n",
            "3   10.220530  50.044188 -17.577270             7.0\n",
            "4   10.220363  50.044762 -15.628120             9.0\n",
            "5   10.220075  50.044519 -12.471351             7.0\n",
            "6   10.220678  50.044463 -21.985761             7.0\n",
            "7   10.221041  50.044456 -24.733260             9.0\n",
            "8   10.231394  50.045161 -50.967279             0.0\n",
            "9   10.228815  50.043828  -3.024675             0.0\n",
            "10  10.228939  50.043871  -5.135020             2.0\n",
            "11  10.228812  50.043823  -3.241639             1.0\n",
            "12  10.228841  50.043838  -3.446921             0.0\n",
            "13  10.228910  50.043893  -5.271781             0.0\n",
            "14  10.228986  50.043886  -5.789393             2.0\n",
            "15  10.228838  50.043834  -3.654073             1.0\n",
            "16  10.229066  50.043920  -7.109872             2.0\n",
            "17  10.229041  50.043914  -6.883057             2.0\n",
            "18  10.228887  50.043863  -4.410370             0.0\n",
            "19  10.229039  50.043911  -6.767656             2.0\n",
            "20  10.229006  50.043891  -6.081109             2.0\n",
            "21  10.228881  50.043856  -4.380268             1.0\n",
            "22  10.235162  50.033783  -9.129188             2.0\n",
            "23  10.235290  50.033881  -5.910472             2.0\n",
            "24  10.234229  50.033665 -22.506638             7.0\n",
            "25  10.235430  50.033860  -4.404687             2.0\n",
            "26  10.235076  50.033863  -8.657492             7.0\n",
            "27  10.235393  50.033851  -5.011424             2.0\n",
            "28  10.235307  50.033900  -5.389001             2.0\n",
            "29  10.234735  50.033745 -14.951239             7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jII6DrcXfVHI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print x and y coordinates and classes of first 190 objects (code running very slowly afterwards for some reason)\n",
        "\n",
        "print(x_3D_abs[1:400])\n",
        "print(y_3D_abs[1:400])\n",
        "#print(class_type[1:190])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}