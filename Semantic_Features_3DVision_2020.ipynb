{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Semantic_Features_3DVision_2020.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juliuserbach/Semantic-Features/blob/master/Semantic_Features_3DVision_2020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KERvIJ-nkskO",
        "colab_type": "text"
      },
      "source": [
        "Our mapping pipeline is of the following structure:\n",
        "\n",
        "1.   Detection of objects of certain object classes (e.g. traffic sign). Output: object bounding boxes\n",
        "2.   Triangulation of objects. Output: object position relative to pose\n",
        "3.   Creating map of objects. (And refining with filter, BA, etc.) Output: List of objects and their corresponding positions\n",
        "4.   Visualizing map.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1TSOFcEnsjx",
        "colab_type": "text"
      },
      "source": [
        "We start by loading the benchmark dataset. The Cityscapes dataset is used. \n",
        "\n",
        "Scripts for analyzing the dataset can be found here: https://github.com/mcordts/cityscapesScripts\n",
        "\n",
        "How to download the zip files directly: https://towardsdatascience.com/download-city-scapes-dataset-with-script-3061f87b20d7\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6ZU2SJr1Ifg",
        "colab_type": "text"
      },
      "source": [
        "Download CityScape files: \n",
        "\n",
        "*   leftImg8bit_trainextra.zip\n",
        "*   disparity_trainextra.zip\n",
        "*   camera_trainextra.zip\n",
        "*   vehicle_trainextra.zip\n",
        "\n",
        "The files are unzipped into data/... respectively.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QM1GyIOSzP06",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download and unzip (run only once!).\n",
        "PATH_TO_LEFT_IMAGES = \"leftImg8bit/train_extra/schweinfurt/\"\n",
        "PATH_TO_DISPARITY = \"disparity/train_extra/schweinfurt/\"\n",
        "PATH_TO_CAMERA = \"camera/train_extra/schweinfurt/\"\n",
        "PATH_TO_VEHICLE = \"vehicle/train_extra/schweinfurt/\"\n",
        "\n",
        "# Remove data directory if it is already loaded (if needed).\n",
        "#!rm -r data\n",
        "# Login.\n",
        "!wget --keep-session-cookies --save-cookies=cookies.txt --post-data 'username=ftaubner@ethz.ch&password=semantic_dudes&submit=Login' https://www.cityscapes-dataset.com/login/\n",
        "# Get left camera images. I put it on OneDrive so that only Schweinfurt has to be downloaded.\n",
        "!wget --no-check-certificate \"https://onedrive.live.com/download?cid=EA356294C6263A37&resid=EA356294C6263A37%2199734&authkey=AC5K24PFcrSPFl4\" -O leftImg8bit_trainextra.zip\n",
        "# Alternatively, it can be downloaded from CityScapes website directly:\n",
        "#   (!wget --load-cookies cookies.txt --content-disposition https://www.cityscapes-dataset.com/file-handling/?packageID=4)\n",
        "# Extract.\n",
        "!mkdir data\n",
        "!unzip -qq leftImg8bit_trainextra.zip \"$PATH_TO_LEFT_IMAGES\"* -d data\n",
        "# And delete.\n",
        "!rm leftImg8bit_trainextra.zip\n",
        "\n",
        "# Get disparity maps.\n",
        "!wget --no-check-certificate \"https://onedrive.live.com/download?cid=EA356294C6263A37&resid=EA356294C6263A37%2199735&authkey=AEwGRlH_TySnyPM\" -O disparity_trainextra.zip\n",
        "# Original file:\n",
        "#   (!wget --load-cookies cookies.txt --content-disposition https://www.cityscapes-dataset.com/file-handling/?packageID=22)\n",
        "!unzip -qq disparity_trainextra.zip \"$PATH_TO_DISPARITY\"* -d data\n",
        "!rm disparity_trainextra.zip\n",
        "# Get camera intrinsics. \n",
        "!wget --load-cookies cookies.txt --content-disposition https://www.cityscapes-dataset.com/file-handling/?packageID=9\n",
        "!unzip -qq camera_trainextra.zip \"$PATH_TO_CAMERA\"* -d data\n",
        "!rm camera_trainextra.zip\n",
        "# Get vehicle odometry.\n",
        "!wget --load-cookies cookies.txt --content-disposition https://www.cityscapes-dataset.com/file-handling/?packageID=11\n",
        "!unzip -qq vehicle_trainextra.zip \"$PATH_TO_VEHICLE\"* -d data\n",
        "!rm vehicle_trainextra.zip\n",
        "\n",
        "import os\n",
        "PATH_TO_LEFT_IMAGES = os.path.join(\"data/\", PATH_TO_LEFT_IMAGES)\n",
        "PATH_TO_DISPARITY = os.path.join(\"data/\", PATH_TO_DISPARITY)\n",
        "PATH_TO_CAMERA = os.path.join(\"data/\", PATH_TO_CAMERA)\n",
        "PATH_TO_VEHICLE = os.path.join(\"data/\", PATH_TO_VEHICLE)\n",
        "\n",
        "print(\"Finished unzipping.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwU_f_b7nH-O",
        "colab_type": "text"
      },
      "source": [
        "We start with the detection of objects of interest. Faster R-CNN is used for this task. (Julius)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qX732O_UCkoo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# COCO Class names\n",
        "# Index of the class in the list is its ID. For example, to get ID of\n",
        "# the teddy bear class, use: class_names.index('teddy bear')\n",
        "class_names = ['BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',\n",
        "               'bus', 'train', 'truck', 'boat', 'traffic light',\n",
        "               'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',\n",
        "               'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',\n",
        "               'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n",
        "               'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
        "               'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
        "               'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',\n",
        "               'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
        "               'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
        "               'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n",
        "               'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
        "               'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',\n",
        "               'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n",
        "               'teddy bear', 'hair drier', 'toothbrush']\n",
        "static_classes = []              "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXh-WMRDzqFe",
        "colab_type": "text"
      },
      "source": [
        "Loading an on COCO pre-trained Faster R-CNN \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gO8ZQm5lzz5s",
        "colab_type": "text"
      },
      "source": [
        "Installing Seamless Scene Segmentation from https://github.com/mapillary/seamseg\n",
        "For Seamless Scene Segmentation a pre-trained version on the Mapillary Dataset exists. Dataloaders for Cityscapes seem to exist, too.\n",
        "\n",
        "It is a network for panoptic segmentation basen on Mask-R-CNN. Alternatively the panoptic variant in the detectron2 reopisitory can also be trained on Cityscapes or Mapillary. Dataloaders seem to exist for both Datasets. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLq9ofO5zzmS",
        "colab_type": "code",
        "outputId": "4d81515d-1bcc-4772-f54b-288dedfbef22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        }
      },
      "source": [
        "#@title\n",
        "!pip install git+https://github.com/mapillary/seamseg.git\n",
        "#!pip install wget\n",
        "\n",
        "url = 'https://drive.google.com/file/d/1ULhd_CZ24L8FnI9lZ2H6Xuf03n6NA_-Y/view'\n",
        "!wget $url\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/mapillary/seamseg.git\n",
            "  Cloning https://github.com/mapillary/seamseg.git to /tmp/pip-req-build-7d68pw1s\n",
            "  Running command git clone -q https://github.com/mapillary/seamseg.git /tmp/pip-req-build-7d68pw1s\n",
            "Building wheels for collected packages: seamseg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bjqhrjt8BTs",
        "colab_type": "text"
      },
      "source": [
        "These functions convert a difference in coordinates (lat., long.) to a difference in metric frame (x, y) and vice versa. Both conversions are dependent on the current latitude.\n",
        "Under the assumption that we are in Europe, east of 0Â°!\n",
        "\n",
        "Approximative conversions:\n",
        "\n",
        "* Latitude: 1 deg = 110.574 km\n",
        "* Longitude: 1 deg = 111.320*cos(latitude) km\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2l9jM1A7_9S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Calculates the difference between two coordinates in meters (x to east, y to north).\n",
        "def coord_diff_to_metric_diff(d_lat, d_long, lat):\n",
        "  d_y = d_lat * 110574\n",
        "  d_x = d_long * 111320 * np.cos(np.radians(lat))\n",
        "  return d_x, d_y\n",
        "\n",
        "# Converts the metric difference to differences in latitude and longitude.\n",
        "def metric_diff_to_coord_diff(d_x, d_y, lat):\n",
        "  d_lat = d_y / 110574\n",
        "  d_long = d_x / 111320 / np.cos(np.radians(lat))\n",
        "  return d_lat, d_long"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKWwzyVW_ZHa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "10b574c1-94bb-42f9-b9e3-7d9583d44d02"
      },
      "source": [
        "# Testing and example (taken from Johannes' map pic on WhatsApp):\n",
        "# Converting coords into metrics:\n",
        "d_x, d_y = coord_diff_to_metric_diff(48.370-48.369, 10.896-10.894, 48.368)\n",
        "print(\"Delta x in meters: {}\".format(d_x))\n",
        "print(\"Delta y in meters: {}\".format(d_y))\n",
        "\n",
        "# Converting back to coords: should be the same:\n",
        "d_lat, d_long = metric_diff_to_coord_diff(d_x, d_y, 48.368)\n",
        "print(\"Difference in latitude: {}\".format(d_lat))\n",
        "print(\"Difference in longitude: {}\".format(d_long))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Delta x in meters: 147.90949435332325\n",
            "Delta y in meters: 110.5739999997423\n",
            "Difference in latitude: 0.0009999999999976694\n",
            "Difference in longitude: 0.002000000000000668\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TN9kAAMFUHg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading results from json file stored in FEATURE_FILE \n",
        "FEATURE_FILE = \"results.json\"\n",
        "with open(FEATURE_FILE) as json_file:\n",
        "    features = json.load(json_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cstG2BrsLQBZ",
        "colab_type": "text"
      },
      "source": [
        "Plotting ground truth trajectory of vehicle. (Map image muss im Moment immer noch manuell gedownloaded und hinzugefÃ¼gt werden)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lc45wu8FLRmP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "outputId": "2e6b2574-b86d-43e9-ca4c-79429fa60756"
      },
      "source": [
        "# Loading ground truth data from json file and saving it as pandas array\n",
        "import pandas as pd \n",
        "import os\n",
        "import json\n",
        "import glob\n",
        "from pandas.io.json import json_normalize\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "DATA_DIR=\"data/vehicle/train_extra/schweinfurt\"\n",
        "images_path = list(glob.iglob(os.path.join(DATA_DIR, '*.*')))\n",
        "n_images = len(images_path)\n",
        "i = 0\n",
        "# create space for long at lat\n",
        "gpsLatitude = np.zeros(n_images)\n",
        "gpsLongitude = np.zeros(n_images)\n",
        "\n",
        "for image_path in images_path:\n",
        "  # Load json from path\n",
        "  with open(image_path) as json_file:\n",
        "    data = json.load(json_file)\n",
        "    gpsLatitude[i] = data['gpsLatitude']\n",
        "    gpsLongitude[i] = data['gpsLongitude']\n",
        "    i += 1\n",
        "df = pd.DataFrame({'longitude': gpsLongitude,\n",
        "'latitude': gpsLatitude})\n",
        "BBox = ((df.longitude.min(),   df.longitude.max(),      \n",
        "         df.latitude.min(), df.latitude.max()))\n",
        "\n",
        "longdif = df.longitude.max() - df.longitude.min()\n",
        "latgdif = df.latitude.max() - df.latitude.min()\n",
        "aspectr = longdif/latgdif\n",
        "\n",
        "image = plt.imread('/content/map (4).png')\n",
        "\n",
        "fig, ax = plt.subplots(figsize = (8,7))\n",
        "ax.scatter(df.longitude, df.latitude)\n",
        "ax.set_title('Plotting Trajectiory')\n",
        "ax.set_xlim(BBox[0],BBox[1])\n",
        "ax.set_ylim(BBox[2],BBox[3])\n",
        "ax.imshow(image, zorder=0, extent = BBox)\n",
        "ax.set_aspect(aspect= aspectr)\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-95-5e19b1319573>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0maspectr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlongdif\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlatgdif\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/map (4).png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   2059\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mdocstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2060\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2061\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2062\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2063\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   1472\u001b[0m             \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1473\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_png\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_png\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1474\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_file_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_png\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_png\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36mopen_file_cm\u001b[0;34m(path_or_file, mode, encoding)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mopen_file_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[0;34mr\"\"\"Pass through file objects and context-manage `.PathLike`\\s.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m     \u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_filehandle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopened\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36mto_filehandle\u001b[0;34m(fname, flag, return_opened, encoding)\u001b[0m\n\u001b[1;32m    401\u001b[0m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbz2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBZ2File\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m         \u001b[0mopened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'seek'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/map (4).png'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaGRTzSON66G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_DIR=\"data/vehicle/train_extra/schweinfurt\"\n",
        "images_path = list(glob.iglob(os.path.join(DATA_DIR, '*.*')))\n",
        "n_images = len(images_path)\n",
        "i = 0\n",
        "\n",
        "# create space for long at lat\n",
        "gpsLatitude_actual = np.zeros(n_images)\n",
        "gpsLongitude_actual = np.zeros(n_images)\n",
        "gpsHeading_actual = np.zeros(n_images)\n",
        "gpsLatitude_delta = np.zeros(n_images)\n",
        "gpsLongitude_delta = np.zeros(n_images)\n",
        "gpsHeading_delta = np.zeros(n_images)\n",
        "\n",
        "\n",
        "for image_path in images_path:\n",
        "  # Load json from path\n",
        "  with open(image_path) as json_file:\n",
        "    data = json.load(json_file)\n",
        "    gpsLatitude_actual[i] = data['gpsLatitude']\n",
        "    gpsLongitude_actual[i] = data['gpsLongitude']\n",
        "    gpsHeading_actual[i] = data['gpsHeading']\n",
        "    if i > 0:\n",
        "      gpsLatitude_delta[i] = gpsLatitude_actual[i] - gpsLatitude_actual[i-1]\n",
        "      gpsLongitude_delta[i] = gpsLongitude_actual[i] - gpsLongitude_actual[i-1]\n",
        "      gpsHeading_delta[i] = gpsHeading_actual[i] - gpsHeading_actual[i-1]\n",
        "  i+=1\n",
        "\n",
        "# Actual coordinates in x, y starting at 0, 0\n",
        "\n",
        "gps_step_delta_X = np.zeros(n_images)\n",
        "gps_total_delta_X = np.zeros(n_images)\n",
        "gps_step_delta_Y = np.zeros(n_images)\n",
        "gps_total_delta_Y = np.zeros(n_images)\n",
        "gps_total_delta_Heading = np.zeros(n_images)\n",
        "\n",
        "i = 0\n",
        "\n",
        "for image_path in images_path:\n",
        "  if i > 0:\n",
        "    gps_step_delta_X[i], gps_step_delta_Y[i] = coord_diff_to_metric_diff(gpsLatitude_delta[i], gpsLongitude_delta[i], gpsLatitude_actual[i])\n",
        "    gps_total_delta_X[i] = gps_total_delta_X[i-1] + gps_step_delta_X[i]\n",
        "    gps_total_delta_Y[i] = gps_total_delta_Y[i-1] + gps_step_delta_Y[i]\n",
        "    gps_total_delta_Heading[i] = gps_total_Heading[i-1] + gps_Heading_delta[i]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crfISE18wU_V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calculate real 3D position\n",
        "def pixel_to_3Dposition_converter(x, depth, focal):\n",
        "  x_3D = x * depth / focal\n",
        "  return x_3D\n",
        "\n",
        "# Calculate box center to get average disparity\n",
        "def boundaries_to_box_center(x_1, x_2):\n",
        "  x_center = (x_1 + x_2)/2\n",
        "  return x_center\n",
        "\n",
        "# Get camera focal length and baseline (To be corrected, pixels are NOT quadratic here fx =/= fy)\n",
        "def camera_parameters(fx, fy):\n",
        "  # Take average, which is Bullshit, but not better idea yet\n",
        "  focal = (fx + fy)/2\n",
        "  # Get baseline value from calibration data\n",
        "  baseline = 0.222384\n",
        "  return focal, baseline\n",
        "\n",
        "# Get disparities of all points (pixels)\n",
        "def disparity_catcher(x, y, i):\n",
        "  DATA_DIR=\"data/disparity/train_extra/schweinfurt\"\n",
        "  images_directory = list(glob.iglob(os.path.join(DATA_DIR, '*.*')))\n",
        "  n_images = len(images_directory)\n",
        "  k = 0\n",
        "\n",
        "  for image_number in images_directory:\n",
        "  # Load image from path\n",
        "    img = cv2.imread(image_number, 0)\n",
        "  if k == i:\n",
        "    disparity = img[y][x]\n",
        "    print(disparity)\n",
        "  k += 1\n",
        "\n",
        "  return disparity\n",
        "\n",
        "# Get disparity of center point\n",
        "# def box_center_disparity(x_center, y_center):\n",
        "  # disparity_box_center = pix_val_flat[1024 * 2048 * 4 - 2048 * y_center * 4 + x_center * 4]\n",
        "  # return disparity_box_center\n",
        "\n",
        "# Convert disparity to actual depth information\n",
        "def disparity_to_depth(disparity_box_center):\n",
        "  depth_center = baseline * focal / disparity_box_center\n",
        "  return depth_center\n",
        "\n",
        "# Transformation to world frame coordinates\n",
        "# _3dImage\t=\tcv.reprojectImageTo3D('data/disparity/train_extra/schweinfurt/schweinfurt_000000_000000_disparity.png', Q)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilTmHPK3N307",
        "colab_type": "code",
        "outputId": "5ac86e77-6def-4a45-ffda-10b4d83f9d57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "camera_parameters(fx, fy)\n",
        "\n",
        "# disparity_catcher(300, 500)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2255.409498258663, 0.222384)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkjgYrHHN4dt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import csv\n",
        "import pandas as pd\n",
        "import cv2\n",
        "\n",
        "# Get focal length from calibration data\n",
        "fx = 2273.82\n",
        "fy = 2236.9989965173254\n",
        "\n",
        "#FEATURE_FILE = 'results.csv'\n",
        "\n",
        "# Read box coordinates from csv file\n",
        "#results_df = pd.read_csv(FEATURE_FILE, sep=';')\n",
        "#print(results_df.head)\n",
        "\n",
        "#obj = results_df.to_numpy()\n",
        "#print(obj[0][2][1:46])\n",
        "#row = obj[0][2][1:46]\n",
        "#print(features[0]['boxes'][0][0])\n",
        "#print(features[0]['boxes'][1][0])\n",
        "\n",
        "#print(features[0].keys())\n",
        "\n",
        "class objct:\n",
        "  def __init__(self, category, x1, y1, x2, y2):\n",
        "    self.category = category\n",
        "    self.x1 = x1\n",
        "    self.y1 = y1\n",
        "    self.x2 = x2\n",
        "    self.y2 = y2\n",
        "\n",
        "# class im:\n",
        "  # def __init__(self, name, num_obj):\n",
        "    # self.category = category\n",
        "    # self.name = name\n",
        "    # self.num_obj = num_obj\n",
        "\n",
        "# obj1 = obj(2, 100, 200, 400, 300)\n",
        "\n",
        "# print(obj1.category)\n",
        "# print(obj1.x_center)\n",
        "\n",
        "# n_images = len(images_path)\n",
        "\n",
        "for i in images_path:\n",
        "  for o in range(len(features[i]['classes'])):\n",
        "    x_cent = int(boundaries_to_box_center(features[i]['boxes'][o][0], features[i]['boxes'][o][1]))\n",
        "    y_cent = int(boundaries_to_box_center(features[i]['boxes'][o][2], features[i]['boxes'][o][3]))\n",
        "    disp_cent = disparity_catcher(x_cent, y_cent, i)\n",
        "    depth_cent = disparity_to_depth(disp_cent)\n",
        "    x_3D = pixel_to_3Dposition_converter(x_cent, depth_cent, focal)\n",
        "    y_3D = pixel_to_3Dposition_converter(y_cent, depth_cent, focal)\n",
        "    features[i]['boxes'][o][0] = gps_total_delta_X[i] + x_3D * cos(gps_total_delta_Heading[i]) - y_3D * sin(gps_total_delta_Heading[i])\n",
        "    features[i]['boxes'][o][1] = gps_total_delta_Y[i] + x_3D * sin(gps_total_delta_Heading[i]) + y_3D * cos(gps_total_delta_Heading[i])\n",
        "    features[i]['boxes'][o][2] = int(0)\n",
        "    features[i]['boxes'][o][3] = int(0)\n",
        "\n",
        "#print(features[0]['boxes'][0][0:10])\n",
        "\n",
        "   # (objct(features[i]['classes'][o], features[i]['boxes'][o][0], features[i]['boxes'][o][1], features[i]['boxes'][o][2], features[i]['boxes'][o][3]))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chKg6l15xzz0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "outputId": "2ab6e193-59d5-4807-8660-ee6c6ea935d6"
      },
      "source": [
        "import math\n",
        "import csv\n",
        "import pandas as pd\n",
        "import cv2\n",
        "\n",
        "# Get focal length from calibration data\n",
        "fx = 2273.82\n",
        "fy = 2236.9989965173254\n",
        "baseline = 0.222384\n",
        "\n",
        "\n",
        "DATA_DIR=\"data/Julius_Results\"\n",
        "results_path = list(glob.iglob(os.path.join(DATA_DIR, '*.*')))\n",
        "n_images = len(images_path)\n",
        "k = 0 # Images\n",
        "t = 0 # Total object number\n",
        "\n",
        "x1 = np.zeros(1000000)\n",
        "y1 = np.zeros(1000000)\n",
        "x2 = np.zeros(1000000)\n",
        "y2 = np.zeros(1000000)\n",
        "x_3D_rel_car = np.zeros(1000000)\n",
        "y_3D_rel_car = np.zeros(1000000)\n",
        "x_3D_abs = np.zeros(1000000)\n",
        "y_3D_abs = np.zeros(1000000)\n",
        "class_type = np.zeros(1000000)\n",
        "\n",
        "for x in results_path:\n",
        "  # Load json from path\n",
        "  with open(x) as json_file:\n",
        "    data = json.load(json_file)\n",
        "    for i in images_path:\n",
        "      n_objects = int(len(data['results'][k]['classes']))\n",
        "      #print(n_objects)\n",
        "      #print(data['results'][k]['boxes'][0][1])\n",
        "      for o in range(n_objects):\n",
        "        class_type[t] = data['results'][k]['classes'][o]\n",
        "        x1[t] = data['results'][k]['boxes'][o][0]\n",
        "        y1[t] = data['results'][k]['boxes'][o][1]\n",
        "        x2[t] = data['results'][k]['boxes'][o][2]\n",
        "        y2[t] = data['results'][k]['boxes'][o][3]\n",
        "        x_cent = int(boundaries_to_box_center(x1[t], x2[t]))\n",
        "        y_cent = int(boundaries_to_box_center(y1[t], y2[t]))\n",
        "        disp_cent = disparity_catcher(x_cent, y_cent, k)\n",
        "        depth_cent = disparity_to_depth(disp_cent)\n",
        "        x_3D_rel_car[t] = pixel_to_3Dposition_converter(x_cent, depth_cent, focal)\n",
        "        y_3D_rel_car[t] = pixel_to_3Dposition_converter(y_cent, depth_cent, focal)\n",
        "        x_3D_abs = gps_total_delta_X[i] + x_3D_rel_car[t] * cos(gps_total_delta_Heading[k]) - y_3D_rel_car[t] * sin(gps_total_delta_Heading[k])\n",
        "        y_3D_abs = gps_total_delta_Y[i] + x_3D_rel_car[t] * sin(gps_total_delta_Heading[k]) + y_3D_rel_car[t] * cos(gps_total_delta_Heading[k])\n",
        "        t += 1\n",
        "      k += 1\n",
        "\n",
        "    "
      ],
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-192-6d7464ebdf2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0my_cent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboundaries_to_box_center\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mdisp_cent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisparity_catcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_cent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_cent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mdepth_cent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisparity_to_depth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisp_cent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mx_3D_rel_car\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpixel_to_3Dposition_converter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_cent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth_cent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfocal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0my_3D_rel_car\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpixel_to_3Dposition_converter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_cent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth_cent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfocal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-97-9587f0a02281>\u001b[0m in \u001b[0;36mdisparity_to_depth\u001b[0;34m(disparity_box_center)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m# Convert disparity to actual depth information\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdisparity_to_depth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisparity_box_center\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m   \u001b[0mdepth_center\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbaseline\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfocal\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdisparity_box_center\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdepth_center\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'focal' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRuKLRT1mpYm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cf0926a4-f75e-4630-f794-34f307d41cac"
      },
      "source": [
        "# install dependencies: (use cu100 because colab is on CUDA 10.0)\n",
        "!pip install -U torch==1.4+cu100 torchvision==0.5+cu100 -f https://download.pytorch.org/whl/torch_stable.html \n",
        "!pip install cython pyyaml==5.1\n",
        "!pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n",
        "import torch, torchvision\n",
        "torch.__version__\n",
        "!gcc --version\n",
        "# opencv is pre-installed on colab\n"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.4+cu100\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu100/torch-1.4.0%2Bcu100-cp36-cp36m-linux_x86_64.whl (723.9MB)\n",
            "\u001b[K     |ââââââââââââââââââââââââââââââââ| 723.9MB 25kB/s \n",
            "\u001b[?25hCollecting torchvision==0.5+cu100\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu100/torchvision-0.5.0%2Bcu100-cp36-cp36m-linux_x86_64.whl (4.0MB)\n",
            "\u001b[K     |ââââââââââââââââââââââââââââââââ| 4.1MB 13.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5+cu100) (7.0.0)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5+cu100) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5+cu100) (1.18.2)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.4.0\n",
            "    Uninstalling torch-1.4.0:\n",
            "      Successfully uninstalled torch-1.4.0\n",
            "  Found existing installation: torchvision 0.5.0\n",
            "    Uninstalling torchvision-0.5.0:\n",
            "      Successfully uninstalled torchvision-0.5.0\n",
            "Successfully installed torch-1.4.0+cu100 torchvision-0.5.0+cu100\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (0.29.15)\n",
            "Collecting pyyaml==5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/2c/9417b5c774792634834e730932745bc09a7d36754ca00acf1ccd1ac2594d/PyYAML-5.1.tar.gz (274kB)\n",
            "\u001b[K     |ââââââââââââââââââââââââââââââââ| 276kB 4.9MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyyaml\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyyaml: filename=PyYAML-5.1-cp36-cp36m-linux_x86_64.whl size=44074 sha256=25f146d0525599f009962b1831c990d82a9a25b8713e5355820e3fe97c6d50cc\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/56/bc/1522f864feb2a358ea6f1a92b4798d69ac783a28e80567a18b\n",
            "Successfully built pyyaml\n",
            "Installing collected packages: pyyaml\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed pyyaml-5.1\n",
            "Collecting git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI\n",
            "  Cloning https://github.com/cocodataset/cocoapi.git to /tmp/pip-req-build-t4fsetf6\n",
            "  Running command git clone -q https://github.com/cocodataset/cocoapi.git /tmp/pip-req-build-t4fsetf6\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=18.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools==2.0) (46.0.0)\n",
            "Requirement already satisfied, skipping upgrade: cython>=0.27.3 in /usr/local/lib/python3.6/dist-packages (from pycocotools==2.0) (0.29.15)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools==2.0) (3.2.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.18.2)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.4.6)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib>=2.1.0->pycocotools==2.0) (1.12.0)\n",
            "Building wheels for collected packages: pycocotools\n",
            "  Building wheel for pycocotools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycocotools: filename=pycocotools-2.0-cp36-cp36m-linux_x86_64.whl size=275356 sha256=4546daf60d5f289a54869836fc21479fc564523e483c5c1c8cc0c520e428a909\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-r3jedtag/wheels/90/51/41/646daf401c3bc408ff10de34ec76587a9b3ebfac8d21ca5c3a\n",
            "Successfully built pycocotools\n",
            "Installing collected packages: pycocotools\n",
            "  Found existing installation: pycocotools 2.0.0\n",
            "    Uninstalling pycocotools-2.0.0:\n",
            "      Successfully uninstalled pycocotools-2.0.0\n",
            "Successfully installed pycocotools-2.0\n",
            "gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "Copyright (C) 2017 Free Software Foundation, Inc.\n",
            "This is free software; see the source for copying conditions.  There is NO\n",
            "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNbSuj4Nmp_N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "outputId": "d5be5823-8332-4111-ba8c-ba0bf36bf01e"
      },
      "source": [
        "\n",
        "# install detectron2:\n",
        "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu100/index.html"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://dl.fbaipublicfiles.com/detectron2/wheels/cu100/index.html\n",
            "Collecting detectron2\n",
            "\u001b[?25l  Downloading https://dl.fbaipublicfiles.com/detectron2/wheels/cu100/detectron2-0.1.1%2Bcu100-cp36-cp36m-linux_x86_64.whl (6.2MB)\n",
            "\u001b[K     |ââââââââââââââââââââââââââââââââ| 6.2MB 1.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.6/dist-packages (from detectron2) (1.1.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from detectron2) (3.2.0)\n",
            "Requirement already satisfied: tensorboard in /tensorflow-1.15.0/python3.6 (from detectron2) (1.15.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from detectron2) (7.0.0)\n",
            "Collecting yacs>=0.1.6\n",
            "  Downloading https://files.pythonhosted.org/packages/2f/51/9d613d67a8561a0cdf696c3909870f157ed85617fea3cff769bb7de09ef7/yacs-0.1.6-py3-none-any.whl\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from detectron2) (0.8.6)\n",
            "Collecting fvcore\n",
            "  Downloading https://files.pythonhosted.org/packages/0e/56/721e88f16d5daeef446d4a8da7f3614d60e7555d05e456b2e2dec7cf423a/fvcore-0.1.dev200324.tar.gz\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.6/dist-packages (from detectron2) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.6/dist-packages (from detectron2) (4.38.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (from detectron2) (1.3.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from detectron2) (0.16.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2) (2.4.6)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2) (1.18.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (0.9.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (0.34.2)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (3.10.0)\n",
            "Requirement already satisfied: grpcio>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (1.24.3)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (1.12.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (3.2.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (46.0.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from yacs>=0.1.6->detectron2) (5.1)\n",
            "Collecting portalocker\n",
            "  Downloading https://files.pythonhosted.org/packages/64/03/9abfb3374d67838daf24f1a388528714bec1debb1d13749f0abd7fb07cfb/portalocker-1.6.0-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: fvcore\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.dev200324-cp36-none-any.whl size=38930 sha256=362ab9060006efc2827eaef9a88b2ec564c428beda386e430159ef30de99a230\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/d3/3d/009ca44849cd91c0b4884a255fbdb79da4d34e7dcf78126973\n",
            "Successfully built fvcore\n",
            "Installing collected packages: yacs, portalocker, fvcore, detectron2\n",
            "Successfully installed detectron2-0.1.1+cu100 fvcore-0.1.dev200324 portalocker-1.6.0 yacs-0.1.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0sxg71Jmrzn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# You may need to restart your runtime prior to this, to let your installation take effect\n",
        "# Some basic setup:\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JHkCYjUmtir",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "29bcb71d-d0b0-42c0-9d46-5b42a719de1c"
      },
      "source": [
        "!mkdir data/Results\n",
        "\n",
        "DATA_DIR=\"data/leftImg8bit/train_extra/schweinfurt\"\n",
        "SAVE_DIR=\"data/Results\"\n",
        "\n",
        "model_file=\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\"\n",
        "cfg = get_cfg()\n",
        "# add project-specific config (e.g., TensorMask) here if you're not running a model in detectron2's core library\n",
        "cfg.merge_from_file(model_zoo.get_config_file(model_file))\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model\n",
        "# Find a model from detectron2's model zoo. You can use the https://dl.fbaipublicfiles... url as well\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(model_file)\n",
        "\n",
        "predictor = DefaultPredictor(cfg)\n",
        "\n",
        "import glob\n",
        "import os\n",
        "import json\n",
        "\n",
        "images_path = list(glob.iglob(os.path.join(DATA_DIR, '*.*')))\n",
        "n_images = len(images_path)\n",
        "i = 0\n",
        "# create empty dictionary \n",
        "features = {}\n",
        "# create empty list of the results\n",
        "features['results'] = []\n",
        "\n",
        "for image_path in images_path:\n",
        "  # Load image from path\n",
        "  image = cv2.imread(image_path)\n",
        "  # Predict bounding boxes and classes\n",
        "  results = predictor(image)\n",
        "  print(\"Image number:{} of {} is beeing processed\".format(i+1, n_images))\n",
        "\n",
        "  # Save visualization in path DATA_DIR/Results with same name as images\n",
        "  v = Visualizer(image[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
        "  v = v.draw_instance_predictions(results[\"instances\"].to(\"cpu\"))\n",
        "  head, tail = os.path.split(image_path)\n",
        "  name = os.path.join(SAVE_DIR,\"{}\".format(tail))\n",
        "  cv2.imwrite(name, v.get_image()[:, :, ::-1])\n",
        "\n",
        "  # export classes and bounding boxes\n",
        "  classes_tensor = results[\"instances\"].pred_classes\n",
        "  boxes_tensor = results[\"instances\"].pred_boxes\n",
        "  classes = classes_tensor.cpu().tolist()\n",
        "  boxes = []\n",
        "  box = boxes_tensor.to(\"cpu\").tensor.tolist()\n",
        "  # put them in a dicitonary to later save them into a json file\n",
        "  features['results'].append({'image_id': tail, 'classes': classes, 'boxes': box})\n",
        "  i +=1"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model_final_f6e8b1.pkl: 243MB [00:03, 67.3MB/s]                           \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Image number:1 of 710 is beeing processed\n",
            "Image number:2 of 710 is beeing processed\n",
            "Image number:3 of 710 is beeing processed\n",
            "Image number:4 of 710 is beeing processed\n",
            "Image number:5 of 710 is beeing processed\n",
            "Image number:6 of 710 is beeing processed\n",
            "Image number:7 of 710 is beeing processed\n",
            "Image number:8 of 710 is beeing processed\n",
            "Image number:9 of 710 is beeing processed\n",
            "Image number:10 of 710 is beeing processed\n",
            "Image number:11 of 710 is beeing processed\n",
            "Image number:12 of 710 is beeing processed\n",
            "Image number:13 of 710 is beeing processed\n",
            "Image number:14 of 710 is beeing processed\n",
            "Image number:15 of 710 is beeing processed\n",
            "Image number:16 of 710 is beeing processed\n",
            "Image number:17 of 710 is beeing processed\n",
            "Image number:18 of 710 is beeing processed\n",
            "Image number:19 of 710 is beeing processed\n",
            "Image number:20 of 710 is beeing processed\n",
            "Image number:21 of 710 is beeing processed\n",
            "Image number:22 of 710 is beeing processed\n",
            "Image number:23 of 710 is beeing processed\n",
            "Image number:24 of 710 is beeing processed\n",
            "Image number:25 of 710 is beeing processed\n",
            "Image number:26 of 710 is beeing processed\n",
            "Image number:27 of 710 is beeing processed\n",
            "Image number:28 of 710 is beeing processed\n",
            "Image number:29 of 710 is beeing processed\n",
            "Image number:30 of 710 is beeing processed\n",
            "Image number:31 of 710 is beeing processed\n",
            "Image number:32 of 710 is beeing processed\n",
            "Image number:33 of 710 is beeing processed\n",
            "Image number:34 of 710 is beeing processed\n",
            "Image number:35 of 710 is beeing processed\n",
            "Image number:36 of 710 is beeing processed\n",
            "Image number:37 of 710 is beeing processed\n",
            "Image number:38 of 710 is beeing processed\n",
            "Image number:39 of 710 is beeing processed\n",
            "Image number:40 of 710 is beeing processed\n",
            "Image number:41 of 710 is beeing processed\n",
            "Image number:42 of 710 is beeing processed\n",
            "Image number:43 of 710 is beeing processed\n",
            "Image number:44 of 710 is beeing processed\n",
            "Image number:45 of 710 is beeing processed\n",
            "Image number:46 of 710 is beeing processed\n",
            "Image number:47 of 710 is beeing processed\n",
            "Image number:48 of 710 is beeing processed\n",
            "Image number:49 of 710 is beeing processed\n",
            "Image number:50 of 710 is beeing processed\n",
            "Image number:51 of 710 is beeing processed\n",
            "Image number:52 of 710 is beeing processed\n",
            "Image number:53 of 710 is beeing processed\n",
            "Image number:54 of 710 is beeing processed\n",
            "Image number:55 of 710 is beeing processed\n",
            "Image number:56 of 710 is beeing processed\n",
            "Image number:57 of 710 is beeing processed\n",
            "Image number:58 of 710 is beeing processed\n",
            "Image number:59 of 710 is beeing processed\n",
            "Image number:60 of 710 is beeing processed\n",
            "Image number:61 of 710 is beeing processed\n",
            "Image number:62 of 710 is beeing processed\n",
            "Image number:63 of 710 is beeing processed\n",
            "Image number:64 of 710 is beeing processed\n",
            "Image number:65 of 710 is beeing processed\n",
            "Image number:66 of 710 is beeing processed\n",
            "Image number:67 of 710 is beeing processed\n",
            "Image number:68 of 710 is beeing processed\n",
            "Image number:69 of 710 is beeing processed\n",
            "Image number:70 of 710 is beeing processed\n",
            "Image number:71 of 710 is beeing processed\n",
            "Image number:72 of 710 is beeing processed\n",
            "Image number:73 of 710 is beeing processed\n",
            "Image number:74 of 710 is beeing processed\n",
            "Image number:75 of 710 is beeing processed\n",
            "Image number:76 of 710 is beeing processed\n",
            "Image number:77 of 710 is beeing processed\n",
            "Image number:78 of 710 is beeing processed\n",
            "Image number:79 of 710 is beeing processed\n",
            "Image number:80 of 710 is beeing processed\n",
            "Image number:81 of 710 is beeing processed\n",
            "Image number:82 of 710 is beeing processed\n",
            "Image number:83 of 710 is beeing processed\n",
            "Image number:84 of 710 is beeing processed\n",
            "Image number:85 of 710 is beeing processed\n",
            "Image number:86 of 710 is beeing processed\n",
            "Image number:87 of 710 is beeing processed\n",
            "Image number:88 of 710 is beeing processed\n",
            "Image number:89 of 710 is beeing processed\n",
            "Image number:90 of 710 is beeing processed\n",
            "Image number:91 of 710 is beeing processed\n",
            "Image number:92 of 710 is beeing processed\n",
            "Image number:93 of 710 is beeing processed\n",
            "Image number:94 of 710 is beeing processed\n",
            "Image number:95 of 710 is beeing processed\n",
            "Image number:96 of 710 is beeing processed\n",
            "Image number:97 of 710 is beeing processed\n",
            "Image number:98 of 710 is beeing processed\n",
            "Image number:99 of 710 is beeing processed\n",
            "Image number:100 of 710 is beeing processed\n",
            "Image number:101 of 710 is beeing processed\n",
            "Image number:102 of 710 is beeing processed\n",
            "Image number:103 of 710 is beeing processed\n",
            "Image number:104 of 710 is beeing processed\n",
            "Image number:105 of 710 is beeing processed\n",
            "Image number:106 of 710 is beeing processed\n",
            "Image number:107 of 710 is beeing processed\n",
            "Image number:108 of 710 is beeing processed\n",
            "Image number:109 of 710 is beeing processed\n",
            "Image number:110 of 710 is beeing processed\n",
            "Image number:111 of 710 is beeing processed\n",
            "Image number:112 of 710 is beeing processed\n",
            "Image number:113 of 710 is beeing processed\n",
            "Image number:114 of 710 is beeing processed\n",
            "Image number:115 of 710 is beeing processed\n",
            "Image number:116 of 710 is beeing processed\n",
            "Image number:117 of 710 is beeing processed\n",
            "Image number:118 of 710 is beeing processed\n",
            "Image number:119 of 710 is beeing processed\n",
            "Image number:120 of 710 is beeing processed\n",
            "Image number:121 of 710 is beeing processed\n",
            "Image number:122 of 710 is beeing processed\n",
            "Image number:123 of 710 is beeing processed\n",
            "Image number:124 of 710 is beeing processed\n",
            "Image number:125 of 710 is beeing processed\n",
            "Image number:126 of 710 is beeing processed\n",
            "Image number:127 of 710 is beeing processed\n",
            "Image number:128 of 710 is beeing processed\n",
            "Image number:129 of 710 is beeing processed\n",
            "Image number:130 of 710 is beeing processed\n",
            "Image number:131 of 710 is beeing processed\n",
            "Image number:132 of 710 is beeing processed\n",
            "Image number:133 of 710 is beeing processed\n",
            "Image number:134 of 710 is beeing processed\n",
            "Image number:135 of 710 is beeing processed\n",
            "Image number:136 of 710 is beeing processed\n",
            "Image number:137 of 710 is beeing processed\n",
            "Image number:138 of 710 is beeing processed\n",
            "Image number:139 of 710 is beeing processed\n",
            "Image number:140 of 710 is beeing processed\n",
            "Image number:141 of 710 is beeing processed\n",
            "Image number:142 of 710 is beeing processed\n",
            "Image number:143 of 710 is beeing processed\n",
            "Image number:144 of 710 is beeing processed\n",
            "Image number:145 of 710 is beeing processed\n",
            "Image number:146 of 710 is beeing processed\n",
            "Image number:147 of 710 is beeing processed\n",
            "Image number:148 of 710 is beeing processed\n",
            "Image number:149 of 710 is beeing processed\n",
            "Image number:150 of 710 is beeing processed\n",
            "Image number:151 of 710 is beeing processed\n",
            "Image number:152 of 710 is beeing processed\n",
            "Image number:153 of 710 is beeing processed\n",
            "Image number:154 of 710 is beeing processed\n",
            "Image number:155 of 710 is beeing processed\n",
            "Image number:156 of 710 is beeing processed\n",
            "Image number:157 of 710 is beeing processed\n",
            "Image number:158 of 710 is beeing processed\n",
            "Image number:159 of 710 is beeing processed\n",
            "Image number:160 of 710 is beeing processed\n",
            "Image number:161 of 710 is beeing processed\n",
            "Image number:162 of 710 is beeing processed\n",
            "Image number:163 of 710 is beeing processed\n",
            "Image number:164 of 710 is beeing processed\n",
            "Image number:165 of 710 is beeing processed\n",
            "Image number:166 of 710 is beeing processed\n",
            "Image number:167 of 710 is beeing processed\n",
            "Image number:168 of 710 is beeing processed\n",
            "Image number:169 of 710 is beeing processed\n",
            "Image number:170 of 710 is beeing processed\n",
            "Image number:171 of 710 is beeing processed\n",
            "Image number:172 of 710 is beeing processed\n",
            "Image number:173 of 710 is beeing processed\n",
            "Image number:174 of 710 is beeing processed\n",
            "Image number:175 of 710 is beeing processed\n",
            "Image number:176 of 710 is beeing processed\n",
            "Image number:177 of 710 is beeing processed\n",
            "Image number:178 of 710 is beeing processed\n",
            "Image number:179 of 710 is beeing processed\n",
            "Image number:180 of 710 is beeing processed\n",
            "Image number:181 of 710 is beeing processed\n",
            "Image number:182 of 710 is beeing processed\n",
            "Image number:183 of 710 is beeing processed\n",
            "Image number:184 of 710 is beeing processed\n",
            "Image number:185 of 710 is beeing processed\n",
            "Image number:186 of 710 is beeing processed\n",
            "Image number:187 of 710 is beeing processed\n",
            "Image number:188 of 710 is beeing processed\n",
            "Image number:189 of 710 is beeing processed\n",
            "Image number:190 of 710 is beeing processed\n",
            "Image number:191 of 710 is beeing processed\n",
            "Image number:192 of 710 is beeing processed\n",
            "Image number:193 of 710 is beeing processed\n",
            "Image number:194 of 710 is beeing processed\n",
            "Image number:195 of 710 is beeing processed\n",
            "Image number:196 of 710 is beeing processed\n",
            "Image number:197 of 710 is beeing processed\n",
            "Image number:198 of 710 is beeing processed\n",
            "Image number:199 of 710 is beeing processed\n",
            "Image number:200 of 710 is beeing processed\n",
            "Image number:201 of 710 is beeing processed\n",
            "Image number:202 of 710 is beeing processed\n",
            "Image number:203 of 710 is beeing processed\n",
            "Image number:204 of 710 is beeing processed\n",
            "Image number:205 of 710 is beeing processed\n",
            "Image number:206 of 710 is beeing processed\n",
            "Image number:207 of 710 is beeing processed\n",
            "Image number:208 of 710 is beeing processed\n",
            "Image number:209 of 710 is beeing processed\n",
            "Image number:210 of 710 is beeing processed\n",
            "Image number:211 of 710 is beeing processed\n",
            "Image number:212 of 710 is beeing processed\n",
            "Image number:213 of 710 is beeing processed\n",
            "Image number:214 of 710 is beeing processed\n",
            "Image number:215 of 710 is beeing processed\n",
            "Image number:216 of 710 is beeing processed\n",
            "Image number:217 of 710 is beeing processed\n",
            "Image number:218 of 710 is beeing processed\n",
            "Image number:219 of 710 is beeing processed\n",
            "Image number:220 of 710 is beeing processed\n",
            "Image number:221 of 710 is beeing processed\n",
            "Image number:222 of 710 is beeing processed\n",
            "Image number:223 of 710 is beeing processed\n",
            "Image number:224 of 710 is beeing processed\n",
            "Image number:225 of 710 is beeing processed\n",
            "Image number:226 of 710 is beeing processed\n",
            "Image number:227 of 710 is beeing processed\n",
            "Image number:228 of 710 is beeing processed\n",
            "Image number:229 of 710 is beeing processed\n",
            "Image number:230 of 710 is beeing processed\n",
            "Image number:231 of 710 is beeing processed\n",
            "Image number:232 of 710 is beeing processed\n",
            "Image number:233 of 710 is beeing processed\n",
            "Image number:234 of 710 is beeing processed\n",
            "Image number:235 of 710 is beeing processed\n",
            "Image number:236 of 710 is beeing processed\n",
            "Image number:237 of 710 is beeing processed\n",
            "Image number:238 of 710 is beeing processed\n",
            "Image number:239 of 710 is beeing processed\n",
            "Image number:240 of 710 is beeing processed\n",
            "Image number:241 of 710 is beeing processed\n",
            "Image number:242 of 710 is beeing processed\n",
            "Image number:243 of 710 is beeing processed\n",
            "Image number:244 of 710 is beeing processed\n",
            "Image number:245 of 710 is beeing processed\n",
            "Image number:246 of 710 is beeing processed\n",
            "Image number:247 of 710 is beeing processed\n",
            "Image number:248 of 710 is beeing processed\n",
            "Image number:249 of 710 is beeing processed\n",
            "Image number:250 of 710 is beeing processed\n",
            "Image number:251 of 710 is beeing processed\n",
            "Image number:252 of 710 is beeing processed\n",
            "Image number:253 of 710 is beeing processed\n",
            "Image number:254 of 710 is beeing processed\n",
            "Image number:255 of 710 is beeing processed\n",
            "Image number:256 of 710 is beeing processed\n",
            "Image number:257 of 710 is beeing processed\n",
            "Image number:258 of 710 is beeing processed\n",
            "Image number:259 of 710 is beeing processed\n",
            "Image number:260 of 710 is beeing processed\n",
            "Image number:261 of 710 is beeing processed\n",
            "Image number:262 of 710 is beeing processed\n",
            "Image number:263 of 710 is beeing processed\n",
            "Image number:264 of 710 is beeing processed\n",
            "Image number:265 of 710 is beeing processed\n",
            "Image number:266 of 710 is beeing processed\n",
            "Image number:267 of 710 is beeing processed\n",
            "Image number:268 of 710 is beeing processed\n",
            "Image number:269 of 710 is beeing processed\n",
            "Image number:270 of 710 is beeing processed\n",
            "Image number:271 of 710 is beeing processed\n",
            "Image number:272 of 710 is beeing processed\n",
            "Image number:273 of 710 is beeing processed\n",
            "Image number:274 of 710 is beeing processed\n",
            "Image number:275 of 710 is beeing processed\n",
            "Image number:276 of 710 is beeing processed\n",
            "Image number:277 of 710 is beeing processed\n",
            "Image number:278 of 710 is beeing processed\n",
            "Image number:279 of 710 is beeing processed\n",
            "Image number:280 of 710 is beeing processed\n",
            "Image number:281 of 710 is beeing processed\n",
            "Image number:282 of 710 is beeing processed\n",
            "Image number:283 of 710 is beeing processed\n",
            "Image number:284 of 710 is beeing processed\n",
            "Image number:285 of 710 is beeing processed\n",
            "Image number:286 of 710 is beeing processed\n",
            "Image number:287 of 710 is beeing processed\n",
            "Image number:288 of 710 is beeing processed\n",
            "Image number:289 of 710 is beeing processed\n",
            "Image number:290 of 710 is beeing processed\n",
            "Image number:291 of 710 is beeing processed\n",
            "Image number:292 of 710 is beeing processed\n",
            "Image number:293 of 710 is beeing processed\n",
            "Image number:294 of 710 is beeing processed\n",
            "Image number:295 of 710 is beeing processed\n",
            "Image number:296 of 710 is beeing processed\n",
            "Image number:297 of 710 is beeing processed\n",
            "Image number:298 of 710 is beeing processed\n",
            "Image number:299 of 710 is beeing processed\n",
            "Image number:300 of 710 is beeing processed\n",
            "Image number:301 of 710 is beeing processed\n",
            "Image number:302 of 710 is beeing processed\n",
            "Image number:303 of 710 is beeing processed\n",
            "Image number:304 of 710 is beeing processed\n",
            "Image number:305 of 710 is beeing processed\n",
            "Image number:306 of 710 is beeing processed\n",
            "Image number:307 of 710 is beeing processed\n",
            "Image number:308 of 710 is beeing processed\n",
            "Image number:309 of 710 is beeing processed\n",
            "Image number:310 of 710 is beeing processed\n",
            "Image number:311 of 710 is beeing processed\n",
            "Image number:312 of 710 is beeing processed\n",
            "Image number:313 of 710 is beeing processed\n",
            "Image number:314 of 710 is beeing processed\n",
            "Image number:315 of 710 is beeing processed\n",
            "Image number:316 of 710 is beeing processed\n",
            "Image number:317 of 710 is beeing processed\n",
            "Image number:318 of 710 is beeing processed\n",
            "Image number:319 of 710 is beeing processed\n",
            "Image number:320 of 710 is beeing processed\n",
            "Image number:321 of 710 is beeing processed\n",
            "Image number:322 of 710 is beeing processed\n",
            "Image number:323 of 710 is beeing processed\n",
            "Image number:324 of 710 is beeing processed\n",
            "Image number:325 of 710 is beeing processed\n",
            "Image number:326 of 710 is beeing processed\n",
            "Image number:327 of 710 is beeing processed\n",
            "Image number:328 of 710 is beeing processed\n",
            "Image number:329 of 710 is beeing processed\n",
            "Image number:330 of 710 is beeing processed\n",
            "Image number:331 of 710 is beeing processed\n",
            "Image number:332 of 710 is beeing processed\n",
            "Image number:333 of 710 is beeing processed\n",
            "Image number:334 of 710 is beeing processed\n",
            "Image number:335 of 710 is beeing processed\n",
            "Image number:336 of 710 is beeing processed\n",
            "Image number:337 of 710 is beeing processed\n",
            "Image number:338 of 710 is beeing processed\n",
            "Image number:339 of 710 is beeing processed\n",
            "Image number:340 of 710 is beeing processed\n",
            "Image number:341 of 710 is beeing processed\n",
            "Image number:342 of 710 is beeing processed\n",
            "Image number:343 of 710 is beeing processed\n",
            "Image number:344 of 710 is beeing processed\n",
            "Image number:345 of 710 is beeing processed\n",
            "Image number:346 of 710 is beeing processed\n",
            "Image number:347 of 710 is beeing processed\n",
            "Image number:348 of 710 is beeing processed\n",
            "Image number:349 of 710 is beeing processed\n",
            "Image number:350 of 710 is beeing processed\n",
            "Image number:351 of 710 is beeing processed\n",
            "Image number:352 of 710 is beeing processed\n",
            "Image number:353 of 710 is beeing processed\n",
            "Image number:354 of 710 is beeing processed\n",
            "Image number:355 of 710 is beeing processed\n",
            "Image number:356 of 710 is beeing processed\n",
            "Image number:357 of 710 is beeing processed\n",
            "Image number:358 of 710 is beeing processed\n",
            "Image number:359 of 710 is beeing processed\n",
            "Image number:360 of 710 is beeing processed\n",
            "Image number:361 of 710 is beeing processed\n",
            "Image number:362 of 710 is beeing processed\n",
            "Image number:363 of 710 is beeing processed\n",
            "Image number:364 of 710 is beeing processed\n",
            "Image number:365 of 710 is beeing processed\n",
            "Image number:366 of 710 is beeing processed\n",
            "Image number:367 of 710 is beeing processed\n",
            "Image number:368 of 710 is beeing processed\n",
            "Image number:369 of 710 is beeing processed\n",
            "Image number:370 of 710 is beeing processed\n",
            "Image number:371 of 710 is beeing processed\n",
            "Image number:372 of 710 is beeing processed\n",
            "Image number:373 of 710 is beeing processed\n",
            "Image number:374 of 710 is beeing processed\n",
            "Image number:375 of 710 is beeing processed\n",
            "Image number:376 of 710 is beeing processed\n",
            "Image number:377 of 710 is beeing processed\n",
            "Image number:378 of 710 is beeing processed\n",
            "Image number:379 of 710 is beeing processed\n",
            "Image number:380 of 710 is beeing processed\n",
            "Image number:381 of 710 is beeing processed\n",
            "Image number:382 of 710 is beeing processed\n",
            "Image number:383 of 710 is beeing processed\n",
            "Image number:384 of 710 is beeing processed\n",
            "Image number:385 of 710 is beeing processed\n",
            "Image number:386 of 710 is beeing processed\n",
            "Image number:387 of 710 is beeing processed\n",
            "Image number:388 of 710 is beeing processed\n",
            "Image number:389 of 710 is beeing processed\n",
            "Image number:390 of 710 is beeing processed\n",
            "Image number:391 of 710 is beeing processed\n",
            "Image number:392 of 710 is beeing processed\n",
            "Image number:393 of 710 is beeing processed\n",
            "Image number:394 of 710 is beeing processed\n",
            "Image number:395 of 710 is beeing processed\n",
            "Image number:396 of 710 is beeing processed\n",
            "Image number:397 of 710 is beeing processed\n",
            "Image number:398 of 710 is beeing processed\n",
            "Image number:399 of 710 is beeing processed\n",
            "Image number:400 of 710 is beeing processed\n",
            "Image number:401 of 710 is beeing processed\n",
            "Image number:402 of 710 is beeing processed\n",
            "Image number:403 of 710 is beeing processed\n",
            "Image number:404 of 710 is beeing processed\n",
            "Image number:405 of 710 is beeing processed\n",
            "Image number:406 of 710 is beeing processed\n",
            "Image number:407 of 710 is beeing processed\n",
            "Image number:408 of 710 is beeing processed\n",
            "Image number:409 of 710 is beeing processed\n",
            "Image number:410 of 710 is beeing processed\n",
            "Image number:411 of 710 is beeing processed\n",
            "Image number:412 of 710 is beeing processed\n",
            "Image number:413 of 710 is beeing processed\n",
            "Image number:414 of 710 is beeing processed\n",
            "Image number:415 of 710 is beeing processed\n",
            "Image number:416 of 710 is beeing processed\n",
            "Image number:417 of 710 is beeing processed\n",
            "Image number:418 of 710 is beeing processed\n",
            "Image number:419 of 710 is beeing processed\n",
            "Image number:420 of 710 is beeing processed\n",
            "Image number:421 of 710 is beeing processed\n",
            "Image number:422 of 710 is beeing processed\n",
            "Image number:423 of 710 is beeing processed\n",
            "Image number:424 of 710 is beeing processed\n",
            "Image number:425 of 710 is beeing processed\n",
            "Image number:426 of 710 is beeing processed\n",
            "Image number:427 of 710 is beeing processed\n",
            "Image number:428 of 710 is beeing processed\n",
            "Image number:429 of 710 is beeing processed\n",
            "Image number:430 of 710 is beeing processed\n",
            "Image number:431 of 710 is beeing processed\n",
            "Image number:432 of 710 is beeing processed\n",
            "Image number:433 of 710 is beeing processed\n",
            "Image number:434 of 710 is beeing processed\n",
            "Image number:435 of 710 is beeing processed\n",
            "Image number:436 of 710 is beeing processed\n",
            "Image number:437 of 710 is beeing processed\n",
            "Image number:438 of 710 is beeing processed\n",
            "Image number:439 of 710 is beeing processed\n",
            "Image number:440 of 710 is beeing processed\n",
            "Image number:441 of 710 is beeing processed\n",
            "Image number:442 of 710 is beeing processed\n",
            "Image number:443 of 710 is beeing processed\n",
            "Image number:444 of 710 is beeing processed\n",
            "Image number:445 of 710 is beeing processed\n",
            "Image number:446 of 710 is beeing processed\n",
            "Image number:447 of 710 is beeing processed\n",
            "Image number:448 of 710 is beeing processed\n",
            "Image number:449 of 710 is beeing processed\n",
            "Image number:450 of 710 is beeing processed\n",
            "Image number:451 of 710 is beeing processed\n",
            "Image number:452 of 710 is beeing processed\n",
            "Image number:453 of 710 is beeing processed\n",
            "Image number:454 of 710 is beeing processed\n",
            "Image number:455 of 710 is beeing processed\n",
            "Image number:456 of 710 is beeing processed\n",
            "Image number:457 of 710 is beeing processed\n",
            "Image number:458 of 710 is beeing processed\n",
            "Image number:459 of 710 is beeing processed\n",
            "Image number:460 of 710 is beeing processed\n",
            "Image number:461 of 710 is beeing processed\n",
            "Image number:462 of 710 is beeing processed\n",
            "Image number:463 of 710 is beeing processed\n",
            "Image number:464 of 710 is beeing processed\n",
            "Image number:465 of 710 is beeing processed\n",
            "Image number:466 of 710 is beeing processed\n",
            "Image number:467 of 710 is beeing processed\n",
            "Image number:468 of 710 is beeing processed\n",
            "Image number:469 of 710 is beeing processed\n",
            "Image number:470 of 710 is beeing processed\n",
            "Image number:471 of 710 is beeing processed\n",
            "Image number:472 of 710 is beeing processed\n",
            "Image number:473 of 710 is beeing processed\n",
            "Image number:474 of 710 is beeing processed\n",
            "Image number:475 of 710 is beeing processed\n",
            "Image number:476 of 710 is beeing processed\n",
            "Image number:477 of 710 is beeing processed\n",
            "Image number:478 of 710 is beeing processed\n",
            "Image number:479 of 710 is beeing processed\n",
            "Image number:480 of 710 is beeing processed\n",
            "Image number:481 of 710 is beeing processed\n",
            "Image number:482 of 710 is beeing processed\n",
            "Image number:483 of 710 is beeing processed\n",
            "Image number:484 of 710 is beeing processed\n",
            "Image number:485 of 710 is beeing processed\n",
            "Image number:486 of 710 is beeing processed\n",
            "Image number:487 of 710 is beeing processed\n",
            "Image number:488 of 710 is beeing processed\n",
            "Image number:489 of 710 is beeing processed\n",
            "Image number:490 of 710 is beeing processed\n",
            "Image number:491 of 710 is beeing processed\n",
            "Image number:492 of 710 is beeing processed\n",
            "Image number:493 of 710 is beeing processed\n",
            "Image number:494 of 710 is beeing processed\n",
            "Image number:495 of 710 is beeing processed\n",
            "Image number:496 of 710 is beeing processed\n",
            "Image number:497 of 710 is beeing processed\n",
            "Image number:498 of 710 is beeing processed\n",
            "Image number:499 of 710 is beeing processed\n",
            "Image number:500 of 710 is beeing processed\n",
            "Image number:501 of 710 is beeing processed\n",
            "Image number:502 of 710 is beeing processed\n",
            "Image number:503 of 710 is beeing processed\n",
            "Image number:504 of 710 is beeing processed\n",
            "Image number:505 of 710 is beeing processed\n",
            "Image number:506 of 710 is beeing processed\n",
            "Image number:507 of 710 is beeing processed\n",
            "Image number:508 of 710 is beeing processed\n",
            "Image number:509 of 710 is beeing processed\n",
            "Image number:510 of 710 is beeing processed\n",
            "Image number:511 of 710 is beeing processed\n",
            "Image number:512 of 710 is beeing processed\n",
            "Image number:513 of 710 is beeing processed\n",
            "Image number:514 of 710 is beeing processed\n",
            "Image number:515 of 710 is beeing processed\n",
            "Image number:516 of 710 is beeing processed\n",
            "Image number:517 of 710 is beeing processed\n",
            "Image number:518 of 710 is beeing processed\n",
            "Image number:519 of 710 is beeing processed\n",
            "Image number:520 of 710 is beeing processed\n",
            "Image number:521 of 710 is beeing processed\n",
            "Image number:522 of 710 is beeing processed\n",
            "Image number:523 of 710 is beeing processed\n",
            "Image number:524 of 710 is beeing processed\n",
            "Image number:525 of 710 is beeing processed\n",
            "Image number:526 of 710 is beeing processed\n",
            "Image number:527 of 710 is beeing processed\n",
            "Image number:528 of 710 is beeing processed\n",
            "Image number:529 of 710 is beeing processed\n",
            "Image number:530 of 710 is beeing processed\n",
            "Image number:531 of 710 is beeing processed\n",
            "Image number:532 of 710 is beeing processed\n",
            "Image number:533 of 710 is beeing processed\n",
            "Image number:534 of 710 is beeing processed\n",
            "Image number:535 of 710 is beeing processed\n",
            "Image number:536 of 710 is beeing processed\n",
            "Image number:537 of 710 is beeing processed\n",
            "Image number:538 of 710 is beeing processed\n",
            "Image number:539 of 710 is beeing processed\n",
            "Image number:540 of 710 is beeing processed\n",
            "Image number:541 of 710 is beeing processed\n",
            "Image number:542 of 710 is beeing processed\n",
            "Image number:543 of 710 is beeing processed\n",
            "Image number:544 of 710 is beeing processed\n",
            "Image number:545 of 710 is beeing processed\n",
            "Image number:546 of 710 is beeing processed\n",
            "Image number:547 of 710 is beeing processed\n",
            "Image number:548 of 710 is beeing processed\n",
            "Image number:549 of 710 is beeing processed\n",
            "Image number:550 of 710 is beeing processed\n",
            "Image number:551 of 710 is beeing processed\n",
            "Image number:552 of 710 is beeing processed\n",
            "Image number:553 of 710 is beeing processed\n",
            "Image number:554 of 710 is beeing processed\n",
            "Image number:555 of 710 is beeing processed\n",
            "Image number:556 of 710 is beeing processed\n",
            "Image number:557 of 710 is beeing processed\n",
            "Image number:558 of 710 is beeing processed\n",
            "Image number:559 of 710 is beeing processed\n",
            "Image number:560 of 710 is beeing processed\n",
            "Image number:561 of 710 is beeing processed\n",
            "Image number:562 of 710 is beeing processed\n",
            "Image number:563 of 710 is beeing processed\n",
            "Image number:564 of 710 is beeing processed\n",
            "Image number:565 of 710 is beeing processed\n",
            "Image number:566 of 710 is beeing processed\n",
            "Image number:567 of 710 is beeing processed\n",
            "Image number:568 of 710 is beeing processed\n",
            "Image number:569 of 710 is beeing processed\n",
            "Image number:570 of 710 is beeing processed\n",
            "Image number:571 of 710 is beeing processed\n",
            "Image number:572 of 710 is beeing processed\n",
            "Image number:573 of 710 is beeing processed\n",
            "Image number:574 of 710 is beeing processed\n",
            "Image number:575 of 710 is beeing processed\n",
            "Image number:576 of 710 is beeing processed\n",
            "Image number:577 of 710 is beeing processed\n",
            "Image number:578 of 710 is beeing processed\n",
            "Image number:579 of 710 is beeing processed\n",
            "Image number:580 of 710 is beeing processed\n",
            "Image number:581 of 710 is beeing processed\n",
            "Image number:582 of 710 is beeing processed\n",
            "Image number:583 of 710 is beeing processed\n",
            "Image number:584 of 710 is beeing processed\n",
            "Image number:585 of 710 is beeing processed\n",
            "Image number:586 of 710 is beeing processed\n",
            "Image number:587 of 710 is beeing processed\n",
            "Image number:588 of 710 is beeing processed\n",
            "Image number:589 of 710 is beeing processed\n",
            "Image number:590 of 710 is beeing processed\n",
            "Image number:591 of 710 is beeing processed\n",
            "Image number:592 of 710 is beeing processed\n",
            "Image number:593 of 710 is beeing processed\n",
            "Image number:594 of 710 is beeing processed\n",
            "Image number:595 of 710 is beeing processed\n",
            "Image number:596 of 710 is beeing processed\n",
            "Image number:597 of 710 is beeing processed\n",
            "Image number:598 of 710 is beeing processed\n",
            "Image number:599 of 710 is beeing processed\n",
            "Image number:600 of 710 is beeing processed\n",
            "Image number:601 of 710 is beeing processed\n",
            "Image number:602 of 710 is beeing processed\n",
            "Image number:603 of 710 is beeing processed\n",
            "Image number:604 of 710 is beeing processed\n",
            "Image number:605 of 710 is beeing processed\n",
            "Image number:606 of 710 is beeing processed\n",
            "Image number:607 of 710 is beeing processed\n",
            "Image number:608 of 710 is beeing processed\n",
            "Image number:609 of 710 is beeing processed\n",
            "Image number:610 of 710 is beeing processed\n",
            "Image number:611 of 710 is beeing processed\n",
            "Image number:612 of 710 is beeing processed\n",
            "Image number:613 of 710 is beeing processed\n",
            "Image number:614 of 710 is beeing processed\n",
            "Image number:615 of 710 is beeing processed\n",
            "Image number:616 of 710 is beeing processed\n",
            "Image number:617 of 710 is beeing processed\n",
            "Image number:618 of 710 is beeing processed\n",
            "Image number:619 of 710 is beeing processed\n",
            "Image number:620 of 710 is beeing processed\n",
            "Image number:621 of 710 is beeing processed\n",
            "Image number:622 of 710 is beeing processed\n",
            "Image number:623 of 710 is beeing processed\n",
            "Image number:624 of 710 is beeing processed\n",
            "Image number:625 of 710 is beeing processed\n",
            "Image number:626 of 710 is beeing processed\n",
            "Image number:627 of 710 is beeing processed\n",
            "Image number:628 of 710 is beeing processed\n",
            "Image number:629 of 710 is beeing processed\n",
            "Image number:630 of 710 is beeing processed\n",
            "Image number:631 of 710 is beeing processed\n",
            "Image number:632 of 710 is beeing processed\n",
            "Image number:633 of 710 is beeing processed\n",
            "Image number:634 of 710 is beeing processed\n",
            "Image number:635 of 710 is beeing processed\n",
            "Image number:636 of 710 is beeing processed\n",
            "Image number:637 of 710 is beeing processed\n",
            "Image number:638 of 710 is beeing processed\n",
            "Image number:639 of 710 is beeing processed\n",
            "Image number:640 of 710 is beeing processed\n",
            "Image number:641 of 710 is beeing processed\n",
            "Image number:642 of 710 is beeing processed\n",
            "Image number:643 of 710 is beeing processed\n",
            "Image number:644 of 710 is beeing processed\n",
            "Image number:645 of 710 is beeing processed\n",
            "Image number:646 of 710 is beeing processed\n",
            "Image number:647 of 710 is beeing processed\n",
            "Image number:648 of 710 is beeing processed\n",
            "Image number:649 of 710 is beeing processed\n",
            "Image number:650 of 710 is beeing processed\n",
            "Image number:651 of 710 is beeing processed\n",
            "Image number:652 of 710 is beeing processed\n",
            "Image number:653 of 710 is beeing processed\n",
            "Image number:654 of 710 is beeing processed\n",
            "Image number:655 of 710 is beeing processed\n",
            "Image number:656 of 710 is beeing processed\n",
            "Image number:657 of 710 is beeing processed\n",
            "Image number:658 of 710 is beeing processed\n",
            "Image number:659 of 710 is beeing processed\n",
            "Image number:660 of 710 is beeing processed\n",
            "Image number:661 of 710 is beeing processed\n",
            "Image number:662 of 710 is beeing processed\n",
            "Image number:663 of 710 is beeing processed\n",
            "Image number:664 of 710 is beeing processed\n",
            "Image number:665 of 710 is beeing processed\n",
            "Image number:666 of 710 is beeing processed\n",
            "Image number:667 of 710 is beeing processed\n",
            "Image number:668 of 710 is beeing processed\n",
            "Image number:669 of 710 is beeing processed\n",
            "Image number:670 of 710 is beeing processed\n",
            "Image number:671 of 710 is beeing processed\n",
            "Image number:672 of 710 is beeing processed\n",
            "Image number:673 of 710 is beeing processed\n",
            "Image number:674 of 710 is beeing processed\n",
            "Image number:675 of 710 is beeing processed\n",
            "Image number:676 of 710 is beeing processed\n",
            "Image number:677 of 710 is beeing processed\n",
            "Image number:678 of 710 is beeing processed\n",
            "Image number:679 of 710 is beeing processed\n",
            "Image number:680 of 710 is beeing processed\n",
            "Image number:681 of 710 is beeing processed\n",
            "Image number:682 of 710 is beeing processed\n",
            "Image number:683 of 710 is beeing processed\n",
            "Image number:684 of 710 is beeing processed\n",
            "Image number:685 of 710 is beeing processed\n",
            "Image number:686 of 710 is beeing processed\n",
            "Image number:687 of 710 is beeing processed\n",
            "Image number:688 of 710 is beeing processed\n",
            "Image number:689 of 710 is beeing processed\n",
            "Image number:690 of 710 is beeing processed\n",
            "Image number:691 of 710 is beeing processed\n",
            "Image number:692 of 710 is beeing processed\n",
            "Image number:693 of 710 is beeing processed\n",
            "Image number:694 of 710 is beeing processed\n",
            "Image number:695 of 710 is beeing processed\n",
            "Image number:696 of 710 is beeing processed\n",
            "Image number:697 of 710 is beeing processed\n",
            "Image number:698 of 710 is beeing processed\n",
            "Image number:699 of 710 is beeing processed\n",
            "Image number:700 of 710 is beeing processed\n",
            "Image number:701 of 710 is beeing processed\n",
            "Image number:702 of 710 is beeing processed\n",
            "Image number:703 of 710 is beeing processed\n",
            "Image number:704 of 710 is beeing processed\n",
            "Image number:705 of 710 is beeing processed\n",
            "Image number:706 of 710 is beeing processed\n",
            "Image number:707 of 710 is beeing processed\n",
            "Image number:708 of 710 is beeing processed\n",
            "Image number:709 of 710 is beeing processed\n",
            "Image number:710 of 710 is beeing processed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHtBkaBjmwVP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Write to json file\n",
        "import json\n",
        "# format: row: image_id , [class_ids], [boxes] , with boxes as x1, y1, x2, \n",
        "FEATURE_FILE = 'results.json'\n",
        "with open(FEATURE_FILE, 'w') as outfile:\n",
        "    json.dump(features, outfile)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}