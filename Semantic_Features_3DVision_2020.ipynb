{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Semantic_Features_3DVision_2020.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juliuserbach/Semantic-Features/blob/master/Semantic_Features_3DVision_2020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KERvIJ-nkskO",
        "colab_type": "text"
      },
      "source": [
        "Our mapping pipeline is of the following structure:\n",
        "\n",
        "1.   Detection of objects of certain object classes (e.g. traffic sign). Output: object bounding boxes\n",
        "2.   Triangulation of objects. Output: object position relative to pose\n",
        "3.   Creating map of objects. (And refining with filter, BA, etc.) Output: List of objects and their corresponding positions\n",
        "4.   Visualizing map.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1TSOFcEnsjx",
        "colab_type": "text"
      },
      "source": [
        "We start by loading the benchmark dataset. The Cityscapes dataset is used. \n",
        "\n",
        "Scripts for analyzing the dataset can be found here: https://github.com/mcordts/cityscapesScripts\n",
        "\n",
        "How to download the zip files directly: https://towardsdatascience.com/download-city-scapes-dataset-with-script-3061f87b20d7\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6ZU2SJr1Ifg",
        "colab_type": "text"
      },
      "source": [
        "Download CityScape files: \n",
        "\n",
        "*   leftImg8bit_trainextra.zip\n",
        "*   disparity_trainextra.zip\n",
        "*   camera_trainextra.zip\n",
        "*   vehicle_trainextra.zip\n",
        "\n",
        "The files are unzipped into data/... respectively.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QM1GyIOSzP06",
        "colab_type": "code",
        "outputId": "b2aa4850-702b-447d-e96d-069742d59400",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 933
        }
      },
      "source": [
        "# Download and unzip (run only once!).\n",
        "PATH_TO_LEFT_IMAGES = \"leftImg8bit/train_extra/schweinfurt/\"\n",
        "PATH_TO_DISPARITY = \"disparity/train_extra/schweinfurt/\"\n",
        "PATH_TO_CAMERA = \"camera/train_extra/schweinfurt/\"\n",
        "PATH_TO_VEHICLE = \"vehicle/train_extra/schweinfurt/\"\n",
        "\n",
        "# Remove data directory if it is already loaded (if needed).\n",
        "#!rm -r data\n",
        "# Login.\n",
        "!wget --keep-session-cookies --save-cookies=cookies.txt --post-data 'username=ftaubner@ethz.ch&password=semantic_dudes&submit=Login' https://www.cityscapes-dataset.com/login/\n",
        "# Get left camera images. I put it on OneDrive so that only Schweinfurt has to be downloaded.\n",
        "!wget --no-check-certificate \"https://onedrive.live.com/download?cid=EA356294C6263A37&resid=EA356294C6263A37%2199734&authkey=AC5K24PFcrSPFl4\" -O leftImg8bit_trainextra.zip\n",
        "# Alternatively, it can be downloaded from CityScapes website directly:\n",
        "#   (!wget --load-cookies cookies.txt --content-disposition https://www.cityscapes-dataset.com/file-handling/?packageID=4)\n",
        "# Extract.\n",
        "!mkdir data\n",
        "!unzip -qq leftImg8bit_trainextra.zip \"$PATH_TO_LEFT_IMAGES\"* -d data\n",
        "# And delete.\n",
        "!rm leftImg8bit_trainextra.zip\n",
        "\n",
        "# Get disparity maps.\n",
        "!wget --no-check-certificate \"https://onedrive.live.com/download?cid=EA356294C6263A37&resid=EA356294C6263A37%2199735&authkey=AEwGRlH_TySnyPM\" -O disparity_trainextra.zip\n",
        "# Original file:\n",
        "#   (!wget --load-cookies cookies.txt --content-disposition https://www.cityscapes-dataset.com/file-handling/?packageID=22)\n",
        "!unzip -qq disparity_trainextra.zip \"$PATH_TO_DISPARITY\"* -d data\n",
        "!rm disparity_trainextra.zip\n",
        "# Get camera intrinsics. \n",
        "!wget --load-cookies cookies.txt --content-disposition https://www.cityscapes-dataset.com/file-handling/?packageID=9\n",
        "!unzip -qq camera_trainextra.zip \"$PATH_TO_CAMERA\"* -d data\n",
        "!rm camera_trainextra.zip\n",
        "# Get vehicle odometry.\n",
        "!wget --load-cookies cookies.txt --content-disposition https://www.cityscapes-dataset.com/file-handling/?packageID=11\n",
        "!unzip -qq vehicle_trainextra.zip \"$PATH_TO_VEHICLE\"* -d data\n",
        "!rm vehicle_trainextra.zip\n",
        "\n",
        "import os\n",
        "PATH_TO_LEFT_IMAGES = os.path.join(\"data/\", PATH_TO_LEFT_IMAGES)\n",
        "PATH_TO_DISPARITY = os.path.join(\"data/\", PATH_TO_DISPARITY)\n",
        "PATH_TO_CAMERA = os.path.join(\"data/\", PATH_TO_CAMERA)\n",
        "PATH_TO_VEHICLE = os.path.join(\"data/\", PATH_TO_VEHICLE)\n",
        "\n",
        "print(\"Finished unzipping.\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-24 17:41:04--  https://www.cityscapes-dataset.com/login/\n",
            "Resolving www.cityscapes-dataset.com (www.cityscapes-dataset.com)... 139.19.217.8\n",
            "Connecting to www.cityscapes-dataset.com (www.cityscapes-dataset.com)|139.19.217.8|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://www.cityscapes-dataset.com/downloads/ [following]\n",
            "--2020-03-24 17:41:06--  https://www.cityscapes-dataset.com/downloads/\n",
            "Reusing existing connection to www.cityscapes-dataset.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘index.html.1’\n",
            "\n",
            "index.html.1            [  <=>               ]  42.77K   146KB/s    in 0.3s    \n",
            "\n",
            "2020-03-24 17:41:08 (146 KB/s) - ‘index.html.1’ saved [43792]\n",
            "\n",
            "--2020-03-24 17:41:09--  https://onedrive.live.com/download?cid=EA356294C6263A37&resid=EA356294C6263A37%2199734&authkey=AC5K24PFcrSPFl4\n",
            "Resolving onedrive.live.com (onedrive.live.com)... 13.107.42.13\n",
            "Connecting to onedrive.live.com (onedrive.live.com)|13.107.42.13|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://xyibzg.am.files.1drv.com/y4mhwjWmTalEstq2JLcmDoqTvoy93llkXh2Pd-cPETMr6dwryufeIT8GhjWDABicu0mDBz2pViokZW45cbZTU-KoODCy0nK7uu6Et3s8K-fOjmDmfIuL58VlP15xcKEqRm7FZOoXe4clWJVahZoJmW5ssofX8acwCDiIpqacLtDZjjEeJOTpxieBrRxSWvrG6ACDfnDSxN6miHieJWq8nNI7A/leftImg8bit_trainextra.zip?download&psid=1 [following]\n",
            "--2020-03-24 17:41:10--  https://xyibzg.am.files.1drv.com/y4mhwjWmTalEstq2JLcmDoqTvoy93llkXh2Pd-cPETMr6dwryufeIT8GhjWDABicu0mDBz2pViokZW45cbZTU-KoODCy0nK7uu6Et3s8K-fOjmDmfIuL58VlP15xcKEqRm7FZOoXe4clWJVahZoJmW5ssofX8acwCDiIpqacLtDZjjEeJOTpxieBrRxSWvrG6ACDfnDSxN6miHieJWq8nNI7A/leftImg8bit_trainextra.zip?download&psid=1\n",
            "Resolving xyibzg.am.files.1drv.com (xyibzg.am.files.1drv.com)... 13.107.42.12\n",
            "Connecting to xyibzg.am.files.1drv.com (xyibzg.am.files.1drv.com)|13.107.42.12|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1582171242 (1.5G) [application/zip]\n",
            "Saving to: ‘leftImg8bit_trainextra.zip’\n",
            "\n",
            "leftImg8bit_trainex 100%[===================>]   1.47G  12.9MB/s    in 1m 56s  \n",
            "\n",
            "2020-03-24 17:43:07 (13.0 MB/s) - ‘leftImg8bit_trainextra.zip’ saved [1582171242/1582171242]\n",
            "\n",
            "mkdir: cannot create directory ‘data’: File exists\n",
            "replace data/leftImg8bit/train_extra/schweinfurt/schweinfurt_000000_000390_leftImg8bit.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "--2020-03-24 18:34:17--  https://onedrive.live.com/download?cid=EA356294C6263A37&resid=EA356294C6263A37%2199735&authkey=AEwGRlH_TySnyPM\n",
            "Resolving onedrive.live.com (onedrive.live.com)... 13.107.42.13\n",
            "Connecting to onedrive.live.com (onedrive.live.com)|13.107.42.13|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://xyiczg.am.files.1drv.com/y4meIpgQm_JEsvNfpPZeL1pXBWcVu3QJuUhDcQqHT7zDs6GQGT1ABMcJX-ftk4yA7r9Qfl8AhqNx6zttba-rTLqfUlQhvRTdk8bq11Zyypr7byJOKNsgzY11qIoH6KRNH6iVWQfjW0En9UXiJ4BZFFY7tf4vl1C7QHC79ovLxdSjpIQXv3PF0Y1shaiWxXA0JeXatksn_1e2UmbX-NAjkTzcA/disparity_trainextra.zip?download&psid=1 [following]\n",
            "--2020-03-24 18:34:19--  https://xyiczg.am.files.1drv.com/y4meIpgQm_JEsvNfpPZeL1pXBWcVu3QJuUhDcQqHT7zDs6GQGT1ABMcJX-ftk4yA7r9Qfl8AhqNx6zttba-rTLqfUlQhvRTdk8bq11Zyypr7byJOKNsgzY11qIoH6KRNH6iVWQfjW0En9UXiJ4BZFFY7tf4vl1C7QHC79ovLxdSjpIQXv3PF0Y1shaiWxXA0JeXatksn_1e2UmbX-NAjkTzcA/disparity_trainextra.zip?download&psid=1\n",
            "Resolving xyiczg.am.files.1drv.com (xyiczg.am.files.1drv.com)... 13.107.42.12\n",
            "Connecting to xyiczg.am.files.1drv.com (xyiczg.am.files.1drv.com)|13.107.42.12|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 494420562 (472M) [application/zip]\n",
            "Saving to: ‘disparity_trainextra.zip’\n",
            "\n",
            "disparity_trainextr 100%[===================>] 471.52M  12.0MB/s    in 48s     \n",
            "\n",
            "2020-03-24 18:35:09 (9.76 MB/s) - ‘disparity_trainextra.zip’ saved [494420562/494420562]\n",
            "\n",
            "replace data/disparity/train_extra/schweinfurt/schweinfurt_000000_000341_disparity.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwU_f_b7nH-O",
        "colab_type": "text"
      },
      "source": [
        "We start with the detection of objects of interest. Faster R-CNN is used for this task. (Julius)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qX732O_UCkoo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# COCO Class names\n",
        "# Index of the class in the list is its ID. For example, to get ID of\n",
        "# the teddy bear class, use: class_names.index('teddy bear')\n",
        "class_names = ['BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',\n",
        "               'bus', 'train', 'truck', 'boat', 'traffic light',\n",
        "               'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',\n",
        "               'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',\n",
        "               'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n",
        "               'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
        "               'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
        "               'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',\n",
        "               'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
        "               'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
        "               'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n",
        "               'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
        "               'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',\n",
        "               'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n",
        "               'teddy bear', 'hair drier', 'toothbrush']\n",
        "static_classes = []              "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXh-WMRDzqFe",
        "colab_type": "text"
      },
      "source": [
        "Loading an on COCO pre-trained Faster R-CNN \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gO8ZQm5lzz5s",
        "colab_type": "text"
      },
      "source": [
        "Installing Seamless Scene Segmentation from https://github.com/mapillary/seamseg\n",
        "For Seamless Scene Segmentation a pre-trained version on the Mapillary Dataset exists. Dataloaders for Cityscapes seem to exist, too.\n",
        "\n",
        "It is a network for panoptic segmentation basen on Mask-R-CNN. Alternatively the panoptic variant in the detectron2 reopisitory can also be trained on Cityscapes or Mapillary. Dataloaders seem to exist for both Datasets. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLq9ofO5zzmS",
        "colab_type": "code",
        "outputId": "a29088ac-1efe-4704-cdf2-146aedafda10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "#@title\n",
        "!pip install git+https://github.com/mapillary/seamseg.git\n",
        "#!pip install wget\n",
        "\n",
        "url = 'https://drive.google.com/file/d/1ULhd_CZ24L8FnI9lZ2H6Xuf03n6NA_-Y/view'\n",
        "!wget $url\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/mapillary/seamseg.git\n",
            "  Cloning https://github.com/mapillary/seamseg.git to /tmp/pip-req-build-buwxbwx1\n",
            "  Running command git clone -q https://github.com/mapillary/seamseg.git /tmp/pip-req-build-buwxbwx1\n",
            "Building wheels for collected packages: seamseg\n",
            "  Building wheel for seamseg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seamseg: filename=seamseg-0.1.dev31+g18e28cc-cp36-cp36m-linux_x86_64.whl size=6879520 sha256=fb5c7fbbd5e876009fa72e6582018f43a320361d51e60fc6ef95c6629824ba6e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-9iqay1dr/wheels/34/ae/9b/f7108b6552df4829b6952190c9af1ec04fc171251cdc5d9ea9\n",
            "Successfully built seamseg\n",
            "Installing collected packages: seamseg\n",
            "Successfully installed seamseg-0.1.dev31+g18e28cc\n",
            "--2020-03-24 19:32:05--  https://drive.google.com/file/d/1ULhd_CZ24L8FnI9lZ2H6Xuf03n6NA_-Y/view\n",
            "Resolving drive.google.com (drive.google.com)... 74.125.23.113, 74.125.23.139, 74.125.23.101, ...\n",
            "Connecting to drive.google.com (drive.google.com)|74.125.23.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘view’\n",
            "\n",
            "view                    [ <=>                ]  67.06K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2020-03-24 19:32:05 (1.61 MB/s) - ‘view’ saved [68668]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bjqhrjt8BTs",
        "colab_type": "text"
      },
      "source": [
        "These functions convert a difference in coordinates (lat., long.) to a difference in metric frame (x, y) and vice versa. Both conversions are dependent on the current latitude.\n",
        "Under the assumption that we are in Europe, east of 0°!\n",
        "\n",
        "Approximative conversions:\n",
        "\n",
        "* Latitude: 1 deg = 110.574 km\n",
        "* Longitude: 1 deg = 111.320*cos(latitude) km\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2l9jM1A7_9S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Felix \n",
        "# Helper functions for transformations.\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Calculates the difference between two coordinates in meters (x to east, y to north).\n",
        "# See below for example.\n",
        "def coord_diff_to_metric_diff(d_lat, d_long, lat):\n",
        "  d_y = d_lat * 110574\n",
        "  d_x = d_long * 111320 * np.cos(np.radians(lat))\n",
        "  return d_x, d_y\n",
        "\n",
        "\n",
        "# Converts the metric difference to differences in latitude and longitude.\n",
        "# See below for example.\n",
        "def metric_diff_to_coord_diff(d_x, d_y, lat):\n",
        "  d_lat = d_y / 110574\n",
        "  d_long = d_x / 111320 / np.cos(np.radians(lat))\n",
        "  return d_lat, d_long\n",
        "\n",
        "\n",
        "# Returns the transformation matrix: world frame (-> vehicle frame) -> camera frame\n",
        "# Usage: [x_world; 1] = camera_frame_to_world_transform(args).dot([x_camera_frame; 1])\n",
        "# All angles in radians, distances in meters!\n",
        "# See below for example.\n",
        "def camera_frame_to_world_transform(heading, yaw_ext, pitch_ext, roll_ext, x_ext, y_ext, z_ext):\n",
        "    # Coordinate axis switch for camera.\n",
        "    C_c = np.array([[0., -1.,  0., 0.],\n",
        "                    [0.,  0., -1., 0.],\n",
        "                    [1.,  0.,  0., 0.],\n",
        "                    [0.,  0.,  0., 1.]])\n",
        "    # Vehicle to camera transformation matrix.\n",
        "    c_y = np.cos(yaw_ext)\n",
        "    c_p = np.cos(pitch_ext)\n",
        "    c_r = np.cos(roll_ext)\n",
        "    s_y = np.sin(yaw_ext)\n",
        "    s_p = np.sin(pitch_ext)\n",
        "    s_r = np.sin(roll_ext)\n",
        "    T_v_c = np.array([[c_y*c_p, c_y*s_p*s_r-s_y*c_r, c_y*s_p*c_r+s_y*s_r, x_ext],\n",
        "                      [s_y*c_p, s_y*s_p*s_r+c_y*c_r, s_y*s_p*c_r-c_y*s_r, y_ext],\n",
        "                      [   -s_p,             c_p*s_r,             c_p*c_r, z_ext],\n",
        "                      [     0.,                  0.,                  0.,    1.]])\n",
        "\n",
        "    # World to vehicle transformation matrix.\n",
        "    c_h = np.cos(heading)\n",
        "    s_h = np.sin(heading)\n",
        "    T_w_v = np.array([[c_h, -s_h, 0., 0.],\n",
        "                      [s_h,  c_h, 0., 0.],\n",
        "                      [ 0.,   0., 1., 0.],\n",
        "                      [ 0.,   0., 0., 1.]])\n",
        "\n",
        "    # Return camera space to vehicle transform.\n",
        "    return T_w_v.dot(T_v_c.dot(np.linalg.inv(C_c)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKWwzyVW_ZHa",
        "colab_type": "code",
        "outputId": "ce7c09ed-b451-4091-bf08-2549c558eaac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# Testing and example (taken from Johannes' map pic on WhatsApp):\n",
        "# Converting coords into metrics:\n",
        "d_x, d_y = coord_diff_to_metric_diff(48.370-48.369, 10.896-10.894, 48.368)\n",
        "print(\"Delta x in meters: {}\".format(d_x))\n",
        "print(\"Delta y in meters: {}\".format(d_y))\n",
        "\n",
        "# Converting back to coords: should be the same:\n",
        "d_lat, d_long = metric_diff_to_coord_diff(d_x, d_y, 48.368)\n",
        "print(\"Difference in latitude: {}\".format(d_lat))\n",
        "print(\"Difference in longitude: {}\".format(d_long))\n",
        "\n",
        "# Convert a camera frame coordinate to world coordinate:\n",
        "x_example = np.array([[8.1], [0.7], [0.7]])\n",
        "x_world_example = camera_frame_to_world_transform(0.25, 0.0057, 0.055, 0.0, 1.7, -0.1, 1.3).dot(np.vstack((x_example, 1.0)))\n",
        "print(\"Camera coordinate: \")\n",
        "print(x_example)\n",
        "print(\"World coordinate: \")\n",
        "print(x_world_example)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Delta x in meters: 147.90949435332325\n",
            "Delta y in meters: 110.5739999997423\n",
            "Difference in latitude: 0.0009999999999976694\n",
            "Difference in longitude: 0.002000000000000668\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TN9kAAMFUHg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading results from json file stored in FEATURE_FILE \n",
        "FEATURE_FILE = \"results.json\"\n",
        "with open(FEATURE_FILE) as json_file:\n",
        "    features = json.load(json_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cstG2BrsLQBZ",
        "colab_type": "text"
      },
      "source": [
        "Plotting ground truth trajectory of vehicle. (Map image muss im Moment immer noch manuell gedownloaded und hinzugefügt werden)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lc45wu8FLRmP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading ground truth data from json file and saving it as pandas array\n",
        "import pandas as pd \n",
        "import os\n",
        "import json\n",
        "import glob\n",
        "from pandas.io.json import json_normalize\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "DATA_DIR=\"data/vehicle/train_extra/schweinfurt\"\n",
        "images_path = list(glob.iglob(os.path.join(DATA_DIR, '*.*')))\n",
        "n_images = len(images_path)\n",
        "i = 0\n",
        "# create space for long at lat\n",
        "gpsLatitude = np.zeros(n_images)\n",
        "gpsLongitude = np.zeros(n_images)\n",
        "\n",
        "for image_path in images_path:\n",
        "  # Load json from path\n",
        "  with open(image_path) as json_file:\n",
        "    data = json.load(json_file)\n",
        "    gpsLatitude[i] = data['gpsLatitude']\n",
        "    gpsLongitude[i] = data['gpsLongitude']\n",
        "    i += 1\n",
        "df = pd.DataFrame({'longitude': gpsLongitude,\n",
        "'latitude': gpsLatitude})\n",
        "BBox = ((df.longitude.min(),   df.longitude.max(),      \n",
        "         df.latitude.min(), df.latitude.max()))\n",
        "\n",
        "longdif = df.longitude.max() - df.longitude.min()\n",
        "latgdif = df.latitude.max() - df.latitude.min()\n",
        "aspectr = longdif/latgdif\n",
        "\n",
        "image = plt.imread('/content/map (4).png')\n",
        "\n",
        "fig, ax = plt.subplots(figsize = (8,7))\n",
        "ax.scatter(df.longitude, df.latitude)\n",
        "ax.set_title('Plotting Trajectiory')\n",
        "ax.set_xlim(BBox[0],BBox[1])\n",
        "ax.set_ylim(BBox[2],BBox[3])\n",
        "ax.imshow(image, zorder=0, extent = BBox)\n",
        "ax.set_aspect(aspect= aspectr)\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaGRTzSON66G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_DIR=\"data/vehicle/train_extra/schweinfurt\"\n",
        "images_path = list(glob.iglob(os.path.join(DATA_DIR, '*.*')))\n",
        "n_images = len(images_path)\n",
        "i = 0\n",
        "\n",
        "# create space for long at lat\n",
        "gpsLatitude_actual = np.zeros(n_images)\n",
        "gpsLongitude_actual = np.zeros(n_images)\n",
        "gpsHeading_actual = np.zeros(n_images)\n",
        "gpsLatitude_delta = np.zeros(n_images)\n",
        "gpsLongitude_delta = np.zeros(n_images)\n",
        "gpsHeading_delta = np.zeros(n_images)\n",
        "\n",
        "\n",
        "for image_path in images_path:\n",
        "  # Load json from path\n",
        "  with open(image_path) as json_file:\n",
        "    data = json.load(json_file)\n",
        "    gpsLatitude_actual[i] = data['gpsLatitude']\n",
        "    gpsLongitude_actual[i] = data['gpsLongitude']\n",
        "    gpsHeading_actual[i] = data['gpsHeading']\n",
        "    if i > 0:\n",
        "      gpsLatitude_delta[i] = gpsLatitude_actual[i] - gpsLatitude_actual[i-1]\n",
        "      gpsLongitude_delta[i] = gpsLongitude_actual[i] - gpsLongitude_actual[i-1]\n",
        "      gpsHeading_delta[i] = gpsHeading_actual[i] - gpsHeading_actual[i-1]\n",
        "  i+=1\n",
        "\n",
        "# Actual coordinates in x, y starting at 0, 0\n",
        "\n",
        "gps_step_delta_X = np.zeros(n_images)\n",
        "gps_total_delta_X = np.zeros(n_images)\n",
        "gps_step_delta_Y = np.zeros(n_images)\n",
        "gps_total_delta_Y = np.zeros(n_images)\n",
        "gps_total_delta_Heading = np.zeros(n_images)\n",
        "\n",
        "i = 0\n",
        "\n",
        "for image_path in images_path:\n",
        "  if i > 0:\n",
        "    gps_step_delta_X[i], gps_step_delta_Y[i] = coord_diff_to_metric_diff(gpsLatitude_delta[i], gpsLongitude_delta[i], gpsLatitude_actual[i])\n",
        "    gps_total_delta_X[i] = gps_total_delta_X[i-1] + gps_step_delta_X[i]\n",
        "    gps_total_delta_Y[i] = gps_total_delta_Y[i-1] + gps_step_delta_Y[i]\n",
        "    gps_total_delta_Heading[i] = gps_total_delta_Heading[i-1] + gpsHeading_delta[i]\n",
        "  i+=1\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crfISE18wU_V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fx = 2273.82\n",
        "# fy = 2236.9989965173254\n",
        "\n",
        "# Calculate real 3D position\n",
        "def pixel_to_3Dposition_converter(x, depth, focal):\n",
        "  x_3D = x * depth / focal\n",
        "  return x_3D\n",
        "\n",
        "# Calculate box center to get average disparity\n",
        "def boundaries_to_box_center(x_1, x_2):\n",
        "  x_center = (x_1 + x_2)/2\n",
        "  return x_center\n",
        "\n",
        "# Get camera focal length and baseline (To be corrected, pixels are NOT quadratic here fx =/= fy)\n",
        "def camera_parameters(fx, fy):\n",
        "  # Take average, which is Bullshit, but not better idea yet\n",
        "  focal = (fx + fy)/2\n",
        "  # Get baseline value from calibration data\n",
        "  baseline = 0.222384\n",
        "  return focal, baseline\n",
        "\n",
        "# Get disparities of all points (pixels)\n",
        "def disparity_catcher(x, y, i):\n",
        "  DATA_DIR=\"data/disparity/train_extra/schweinfurt\"\n",
        "  im_directory = list(glob.iglob(os.path.join(DATA_DIR, '*.*')))\n",
        "  n_im = len(im_directory)\n",
        "  l = 0\n",
        "  disp = 0\n",
        "\n",
        "  for im_number in im_directory:\n",
        "  # Load image from path\n",
        "    img = cv2.imread(im_number, 0)\n",
        "    if l == i:\n",
        "      disp = img[y][x]\n",
        "      print(disp)\n",
        "      return disp\n",
        "    else:\n",
        "      l += 1\n",
        "\n",
        "  # return disp\n",
        "\n",
        "# Get disparity of center point\n",
        "# def box_center_disparity(x_center, y_center):\n",
        "  # disparity_box_center = pix_val_flat[1024 * 2048 * 4 - 2048 * y_center * 4 + x_center * 4]\n",
        "  # return disparity_box_center\n",
        "\n",
        "# Convert disparity to actual depth information\n",
        "def disparity_to_depth(disparity_box_center):\n",
        "  if disparity_box_center > 0:\n",
        "    depth_center = baseline * focal / disparity_box_center\n",
        "  else:\n",
        "    depth_center = 100\n",
        "  return depth_center\n",
        "\n",
        "# Transformation to world frame coordinates\n",
        "# _3dImage\t=\tcv.reprojectImageTo3D('data/disparity/train_extra/schweinfurt/schweinfurt_000000_000000_disparity.png', Q)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkjgYrHHN4dt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import math\n",
        "# import csv\n",
        "# import pandas as pd\n",
        "# import cv2\n",
        "\n",
        "# Get focal length from calibration data\n",
        "# fx = 2273.82\n",
        "# fy = 2236.9989965173254\n",
        "\n",
        "#FEATURE_FILE = 'results.csv'\n",
        "\n",
        "# Read box coordinates from csv file\n",
        "#results_df = pd.read_csv(FEATURE_FILE, sep=';')\n",
        "#print(results_df.head)\n",
        "\n",
        "#obj = results_df.to_numpy()\n",
        "#print(obj[0][2][1:46])\n",
        "#row = obj[0][2][1:46]\n",
        "#print(features[0]['boxes'][0][0])\n",
        "#print(features[0]['boxes'][1][0])\n",
        "\n",
        "#print(features[0].keys())\n",
        "\n",
        "# class objct:\n",
        "  # def __init__(self, category, x1, y1, x2, y2):\n",
        "    # self.category = category\n",
        "    # self.x1 = x1\n",
        "    # self.y1 = y1\n",
        "    # self.x2 = x2\n",
        "    # self.y2 = y2\n",
        "\n",
        "# class im:\n",
        "  # def __init__(self, name, num_obj):\n",
        "    # self.category = category\n",
        "    # self.name = name\n",
        "    # self.num_obj = num_obj\n",
        "\n",
        "# obj1 = obj(2, 100, 200, 400, 300)\n",
        "\n",
        "# print(obj1.category)\n",
        "# print(obj1.x_center)\n",
        "\n",
        "# n_images = len(images_path)\n",
        "\n",
        "# for i in images_path:\n",
        " #  for o in range(len(features[i]['classes'])):\n",
        "   #  x_cent = int(boundaries_to_box_center(features[i]['boxes'][o][0], features[i]['boxes'][o][1]))\n",
        "   #  y_cent = int(boundaries_to_box_center(features[i]['boxes'][o][2], features[i]['boxes'][o][3]))\n",
        "   #  disp_cent = disparity_catcher(x_cent, y_cent, i)\n",
        "   #  depth_cent = disparity_to_depth(disp_cent)\n",
        "   #  x_3D = pixel_to_3Dposition_converter(x_cent, depth_cent, focal)\n",
        "   #  y_3D = pixel_to_3Dposition_converter(y_cent, depth_cent, focal)\n",
        "   #  features[i]['boxes'][o][0] = gps_total_delta_X[i] + x_3D * cos(gps_total_delta_Heading[i]) - y_3D * sin(gps_total_delta_Heading[i])\n",
        "   #  features[i]['boxes'][o][1] = gps_total_delta_Y[i] + x_3D * sin(gps_total_delta_Heading[i]) + y_3D * cos(gps_total_delta_Heading[i])\n",
        "   #  features[i]['boxes'][o][2] = int(0)\n",
        "   #  features[i]['boxes'][o][3] = int(0)\n",
        "\n",
        "#print(features[0]['boxes'][0][0:10])\n",
        "\n",
        "   # (objct(features[i]['classes'][o], features[i]['boxes'][o][0], features[i]['boxes'][o][1], features[i]['boxes'][o][2], features[i]['boxes'][o][3]))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chKg6l15xzz0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import csv\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import glob\n",
        "\n",
        "# Get focal length from calibration data\n",
        "fx = 2273.82\n",
        "fy = 2236.9989965173254\n",
        "# baseline = 0.222384\n",
        "\n",
        "focal, baseline = camera_parameters(fx, fy)\n",
        "\n",
        "\n",
        "DATA_DIR=\"data/Numerical_Results\"\n",
        "results_path = list(glob.iglob(os.path.join(DATA_DIR, '*.*')))\n",
        "n_images = len(images_path)\n",
        "k = 0 # Images\n",
        "t = 0 # Total object number\n",
        "\n",
        "x1 = np.zeros(100000)\n",
        "y1 = np.zeros(100000)\n",
        "x2 = np.zeros(100000)\n",
        "y2 = np.zeros(100000)\n",
        "x_3D_rel_car = np.zeros(100000)\n",
        "y_3D_rel_car = np.zeros(100000)\n",
        "x_3D_abs = np.zeros(100000)\n",
        "y_3D_abs = np.zeros(100000)\n",
        "class_type = np.zeros(100000)\n",
        "\n",
        "for x in results_path:\n",
        "  # Load json from path\n",
        "  with open(x) as json_file:\n",
        "    data = json.load(json_file)\n",
        "    for i in images_path:\n",
        "      n_objects = int(len(data['results'][k]['classes']))\n",
        "      #print(n_objects)\n",
        "      #print(data['results'][k]['boxes'][0][1])\n",
        "      for o in range(n_objects):\n",
        "        class_type[t] = data['results'][k]['classes'][o]\n",
        "        x1[t] = data['results'][k]['boxes'][o][0]\n",
        "        y1[t] = data['results'][k]['boxes'][o][1]\n",
        "        x2[t] = data['results'][k]['boxes'][o][2]\n",
        "        y2[t] = data['results'][k]['boxes'][o][3]\n",
        "        x_cent = int(boundaries_to_box_center(x1[t], x2[t]))\n",
        "        y_cent = int(boundaries_to_box_center(y1[t], y2[t]))\n",
        "        disp_cent = disparity_catcher(x_cent, y_cent, k)\n",
        "        depth_cent = disparity_to_depth(disp_cent)\n",
        "        x_3D_rel_car[t] = pixel_to_3Dposition_converter(x_cent, depth_cent, focal)\n",
        "        y_3D_rel_car[t] = pixel_to_3Dposition_converter(y_cent, depth_cent, focal)\n",
        "        x_3D_abs[t] = gps_total_delta_X[k] + x_3D_rel_car[t] * np.cos(gps_total_delta_Heading[k]) - y_3D_rel_car[t] * np.sin(gps_total_delta_Heading[k])\n",
        "        y_3D_abs[t] = gps_total_delta_Y[k] + x_3D_rel_car[t] * np.sin(gps_total_delta_Heading[k]) + y_3D_rel_car[t] * np.cos(gps_total_delta_Heading[k])\n",
        "        t += 1\n",
        "      print(\"Processing image number\", k)\n",
        "      k += 1\n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jII6DrcXfVHI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print x and y coordinates and classes of first 190 objects (code running very slowly afterwards for some reason)\n",
        "\n",
        "print(x_3D_abs[1:400])\n",
        "print(y_3D_abs[1:400])\n",
        "#print(class_type[1:190])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}